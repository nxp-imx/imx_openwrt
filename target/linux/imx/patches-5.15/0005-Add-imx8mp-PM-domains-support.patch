From 9a0d6deb97a62ab371ce8b8c4ccd261a379b8924 Mon Sep 17 00:00:00 2001
From: Yuantian Tang <andy.tang@nxp.com>
Date: Wed, 4 Jan 2023 11:07:43 +0800
Subject: [PATCH 05/12] Add imx8mp PM domains support

Signed-off-by: shuyang <shuyang.guan@nxp.com>
---
 arch/arm64/Kconfig.platforms                  |   15 +-
 arch/arm64/kernel/cpufeature.c                |   13 +
 drivers/base/power/domain.c                   |  196 ++-
 drivers/clk/clk-bulk.c                        |    3 +-
 drivers/firmware/imx/Kconfig                  |   22 +
 drivers/firmware/imx/Makefile                 |    5 +-
 drivers/firmware/imx/ele_base_msg.c           |  176 +++
 drivers/firmware/imx/ele_mu.c                 |  918 +++++++++++++
 drivers/firmware/imx/ele_mu.h                 |  139 ++
 drivers/firmware/imx/imx-scu-irq.c            |  108 +-
 drivers/firmware/imx/imx-scu-soc.c            |   21 +-
 drivers/firmware/imx/imx-scu.c                |   76 +-
 drivers/firmware/imx/misc.c                   |   25 +
 drivers/firmware/imx/rm.c                     |  162 +++
 drivers/firmware/imx/seco.c                   |  249 ++++
 drivers/firmware/imx/seco_mu.c                | 1210 +++++++++++++++++
 drivers/pinctrl/freescale/pinctrl-imx93.c     |  273 ++++
 drivers/pinctrl/freescale/pinctrl-s32v-core.c |  526 +++++++
 drivers/pinctrl/freescale/pinctrl-s32v.h      |   72 +
 drivers/pinctrl/freescale/pinctrl-s32v234.c   |  251 ++++
 drivers/soc/imx/Kconfig                       |   67 +-
 drivers/soc/imx/Makefile                      |    8 +
 drivers/soc/imx/busfreq-imx8mq.c              |  670 +++++++++
 drivers/soc/imx/gpc.c                         |   34 +-
 drivers/soc/imx/gpcv2.c                       |  634 ++-------
 drivers/soc/imx/imx8m_pm_domains.c            |  243 ++++
 drivers/soc/imx/imx8ulp_lpm.c                 |  167 +++
 drivers/soc/imx/imx93-blk-ctrl.c              |  333 +++++
 drivers/soc/imx/imx93-pd.c                    |  276 ++++
 drivers/soc/imx/mu/Kconfig                    |    4 +
 drivers/soc/imx/mu/Makefile                   |    1 +
 drivers/soc/imx/mu/mx8_mu.c                   |  195 +++
 drivers/soc/imx/rpmsg_life_cycle.c            |  120 ++
 drivers/soc/imx/secvio/Makefile               |    3 +
 drivers/soc/imx/secvio/imx-secvio-audit.c     |   31 +
 drivers/soc/imx/secvio/imx-secvio-debugfs.c   |  283 ++++
 drivers/soc/imx/secvio/imx-secvio-sc-int.h    |   83 ++
 drivers/soc/imx/secvio/imx-secvio-sc.c        |  675 +++++++++
 drivers/soc/imx/soc-imx.c                     |    5 +-
 drivers/soc/imx/soc-imx9.c                    |  146 ++
 include/linux/busfreq-imx.h                   |   77 ++
 include/linux/clk.h                           |    2 +
 include/linux/firmware/imx/ele_base_msg.h     |   40 +
 include/linux/firmware/imx/ele_mu_ioctl.h     |   51 +
 include/linux/firmware/imx/ipc.h              |    4 +-
 include/linux/firmware/imx/s4.h               |   20 +
 include/linux/firmware/imx/sci.h              |   28 +-
 include/linux/firmware/imx/seco_mu_ioctl.h    |   50 +
 include/linux/firmware/imx/svc/misc.h         |    9 +
 include/linux/firmware/imx/svc/seco.h         |   77 ++
 include/linux/mx8_mu.h                        |   48 +
 include/linux/pm_domain.h                     |   15 +
 52 files changed, 8243 insertions(+), 616 deletions(-)
 create mode 100644 drivers/firmware/imx/ele_base_msg.c
 create mode 100644 drivers/firmware/imx/ele_mu.c
 create mode 100644 drivers/firmware/imx/ele_mu.h
 create mode 100644 drivers/firmware/imx/seco.c
 create mode 100644 drivers/firmware/imx/seco_mu.c
 create mode 100644 drivers/pinctrl/freescale/pinctrl-imx93.c
 create mode 100644 drivers/pinctrl/freescale/pinctrl-s32v-core.c
 create mode 100644 drivers/pinctrl/freescale/pinctrl-s32v.h
 create mode 100644 drivers/pinctrl/freescale/pinctrl-s32v234.c
 create mode 100644 drivers/soc/imx/busfreq-imx8mq.c
 create mode 100644 drivers/soc/imx/imx8m_pm_domains.c
 create mode 100644 drivers/soc/imx/imx8ulp_lpm.c
 create mode 100644 drivers/soc/imx/imx93-blk-ctrl.c
 create mode 100644 drivers/soc/imx/imx93-pd.c
 create mode 100644 drivers/soc/imx/mu/Kconfig
 create mode 100644 drivers/soc/imx/mu/Makefile
 create mode 100644 drivers/soc/imx/mu/mx8_mu.c
 create mode 100644 drivers/soc/imx/rpmsg_life_cycle.c
 create mode 100644 drivers/soc/imx/secvio/Makefile
 create mode 100644 drivers/soc/imx/secvio/imx-secvio-audit.c
 create mode 100644 drivers/soc/imx/secvio/imx-secvio-debugfs.c
 create mode 100644 drivers/soc/imx/secvio/imx-secvio-sc-int.h
 create mode 100644 drivers/soc/imx/secvio/imx-secvio-sc.c
 create mode 100644 drivers/soc/imx/soc-imx9.c
 create mode 100644 include/linux/busfreq-imx.h
 create mode 100644 include/linux/firmware/imx/ele_base_msg.h
 create mode 100644 include/linux/firmware/imx/ele_mu_ioctl.h
 create mode 100644 include/linux/firmware/imx/s4.h
 create mode 100644 include/linux/firmware/imx/seco_mu_ioctl.h
 create mode 100644 include/linux/firmware/imx/svc/seco.h
 create mode 100644 include/linux/mx8_mu.h

diff --git a/arch/arm64/Kconfig.platforms b/arch/arm64/Kconfig.platforms
index d7772a4c3..feef620ce 100644
--- a/arch/arm64/Kconfig.platforms
+++ b/arch/arm64/Kconfig.platforms
@@ -201,14 +201,19 @@ config ARCH_MXC
 	select ARM64_ERRATUM_845719 if COMPAT
 	select IMX_GPCV2
 	select IMX_GPCV2_PM_DOMAINS
+	select HAVE_IMX_BUSFREQ
 	select PM
 	select PM_GENERIC_DOMAINS
 	select SOC_BUS
 	select TIMER_IMX_SYS_CTR
+	select CLKSRC_IMX_TPM
 	help
 	  This enables support for the ARMv8 based SoCs in the
 	  NXP i.MX family.
 
+config HAVE_IMX_BUSFREQ
+	bool "i.MX8M busfreq"
+
 config ARCH_QCOM
 	bool "Qualcomm Platforms"
 	select GPIOLIB
@@ -243,9 +248,18 @@ config ARCH_ROCKCHIP
 
 config ARCH_S32
 	bool "NXP S32 SoC Family"
+	select ARCH_S32_CLK
+	select PINCTRL
 	help
 	  This enables support for the NXP S32 family of processors.
 
+if ARCH_S32
+menu "S32 SOC selection"
+	config SOC_S32V234
+		bool "S32V234 SOC"
+endmenu
+endif
+
 config ARCH_SEATTLE
 	bool "AMD Seattle SoC Family"
 	help
@@ -259,7 +273,6 @@ config ARCH_INTEL_SOCFPGA
 
 config ARCH_SYNQUACER
 	bool "Socionext SynQuacer SoC Family"
-	select IRQ_FASTEOI_HIERARCHY_HANDLERS
 
 config ARCH_TEGRA
 	bool "NVIDIA Tegra SoC Family"
diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c
index e71c9cfb4..1e6f01667 100644
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@ -901,9 +901,22 @@ init_cpu_hwcaps_indirect_list_from_array(const struct arm64_cpu_capabilities *ca
 	}
 }
 
+bool TKT340553_SW_WORKAROUND;
 static void __init init_cpu_hwcaps_indirect_list(void)
 {
 	init_cpu_hwcaps_indirect_list_from_array(arm64_features);
+#ifdef CONFIG_ARM64_WORKAROUND_CLEAN_CACHE
+#if	defined(CONFIG_ARM64_ERRATUM_826319) || \
+	defined(CONFIG_ARM64_ERRATUM_827319) || \
+	defined(CONFIG_ARM64_ERRATUM_824069)
+	if (TKT340553_SW_WORKAROUND) {
+		struct midr_range *midr_range_list =
+			(struct midr_range *)(arm64_errata[0].midr_range_list);
+
+		midr_range_list[0].rv_max = MIDR_CPU_VAR_REV(0, 4);
+	}
+#endif
+#endif
 	init_cpu_hwcaps_indirect_list_from_array(arm64_errata);
 }
 
diff --git a/drivers/base/power/domain.c b/drivers/base/power/domain.c
index 0f2e42f36..7bef4b663 100644
--- a/drivers/base/power/domain.c
+++ b/drivers/base/power/domain.c
@@ -252,6 +252,40 @@ static inline void genpd_debug_remove(struct generic_pm_domain *genpd) {}
 static inline void genpd_update_accounting(struct generic_pm_domain *genpd) {}
 #endif
 
+void pm_genpd_disable_clks(struct generic_pm_domain *genpd)
+{
+	if (genpd->flags & GENPD_FLAG_PM_PD_CLK && genpd->num_clks > 0)
+		clk_bulk_disable_unprepare(genpd->num_clks, genpd->clks);
+}
+
+int pm_genpd_enable_clks(struct generic_pm_domain *genpd)
+{
+	int ret;
+
+	if (genpd->flags & GENPD_FLAG_PM_PD_CLK && genpd->num_clks > 0) {
+		ret = clk_bulk_prepare_enable(genpd->num_clks, genpd->clks);
+		if (ret) {
+			dev_err(&genpd->dev, "failed to enable clocks\n");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int pm_genpd_of_add_clks(struct generic_pm_domain *genpd, struct device *dev)
+{
+	if (genpd->flags & GENPD_FLAG_PM_PD_CLK) {
+		genpd->num_clks = devm_clk_bulk_get_all(dev, &genpd->clks);
+		if (genpd->num_clks < 0)
+			return dev_err_probe(&genpd->dev, genpd->num_clks,
+					     "Failed to get domain's clocks\n");
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(pm_genpd_of_add_clks);
+
 static int _genpd_reeval_performance_state(struct generic_pm_domain *genpd,
 					   unsigned int state)
 {
@@ -555,6 +589,9 @@ static int _genpd_power_off(struct generic_pm_domain *genpd, bool timed)
 	if (!genpd->power_off)
 		goto out;
 
+	if (atomic_read(&genpd->sd_count) > 0)
+		return -EBUSY;
+
 	if (!timed) {
 		ret = genpd->power_off(genpd);
 		if (ret)
@@ -624,7 +661,7 @@ static int genpd_power_off(struct generic_pm_domain *genpd, bool one_dev_on,
 	 * (2) System suspend is in progress.
 	 */
 	if (!genpd_status_on(genpd) || genpd->prepared_count > 0)
-		return 0;
+		return -EAGAIN;
 
 	/*
 	 * Abort power off for the PM domain in the following situations:
@@ -664,9 +701,9 @@ static int genpd_power_off(struct generic_pm_domain *genpd, bool one_dev_on,
 	if (!genpd->gov)
 		genpd->state_idx = 0;
 
-	/* Don't power off, if a child domain is waiting to power on. */
-	if (atomic_read(&genpd->sd_count) > 0)
-		return -EBUSY;
+	/* Choose the deepest state if no devices using this domain */
+	if (!genpd->device_count)
+		genpd->state_idx = genpd->state_count - 1;
 
 	ret = _genpd_power_off(genpd, true);
 	if (ret) {
@@ -681,8 +718,10 @@ static int genpd_power_off(struct generic_pm_domain *genpd, bool one_dev_on,
 	list_for_each_entry(link, &genpd->child_links, child_node) {
 		genpd_sd_counter_dec(link->parent);
 		genpd_lock_nested(link->parent, depth + 1);
-		genpd_power_off(link->parent, false, depth + 1);
+		ret = genpd_power_off(link->parent, false, depth + 1);
 		genpd_unlock(link->parent);
+		if (!ret)
+			pm_genpd_disable_clks(link->parent);
 	}
 
 	return 0;
@@ -692,17 +731,20 @@ static int genpd_power_off(struct generic_pm_domain *genpd, bool one_dev_on,
  * genpd_power_on - Restore power to a given PM domain and its parents.
  * @genpd: PM domain to power up.
  * @depth: nesting count for lockdep.
+ * @pd_was_on: Return parameter that indicates whether PD was on before
  *
  * Restore power to @genpd and all of its parents so that it is possible to
  * resume a device belonging to it.
  */
-static int genpd_power_on(struct generic_pm_domain *genpd, unsigned int depth)
+static int genpd_power_on(struct generic_pm_domain *genpd, unsigned int depth, bool *pd_was_on)
 {
 	struct gpd_link *link;
 	int ret = 0;
 
-	if (genpd_status_on(genpd))
+	if (genpd_status_on(genpd)) {
+		*pd_was_on = true;
 		return 0;
+	}
 
 	/*
 	 * The list is guaranteed not to change while the loop below is being
@@ -711,16 +753,24 @@ static int genpd_power_on(struct generic_pm_domain *genpd, unsigned int depth)
 	 */
 	list_for_each_entry(link, &genpd->child_links, child_node) {
 		struct generic_pm_domain *parent = link->parent;
+		bool pd_state = false;
 
 		genpd_sd_counter_inc(parent);
 
+		ret = pm_genpd_enable_clks(parent);
+		if (ret)
+			return ret;
+
 		genpd_lock_nested(parent, depth + 1);
-		ret = genpd_power_on(parent, depth + 1);
+		ret = genpd_power_on(parent, depth + 1, &pd_state);
 		genpd_unlock(parent);
 
 		if (ret) {
 			genpd_sd_counter_dec(parent);
+			pm_genpd_disable_clks(parent);
 			goto err;
+		} else if (pd_state) {
+			pm_genpd_disable_clks(parent);
 		}
 	}
 
@@ -739,8 +789,10 @@ static int genpd_power_on(struct generic_pm_domain *genpd, unsigned int depth)
 					child_node) {
 		genpd_sd_counter_dec(link->parent);
 		genpd_lock_nested(link->parent, depth + 1);
-		genpd_power_off(link->parent, false, depth + 1);
+		ret = genpd_power_off(link->parent, false, depth + 1);
 		genpd_unlock(link->parent);
+		if (!ret)
+			pm_genpd_disable_clks(link->parent);
 	}
 
 	return ret;
@@ -800,12 +852,16 @@ static int genpd_dev_pm_qos_notifier(struct notifier_block *nb,
 static void genpd_power_off_work_fn(struct work_struct *work)
 {
 	struct generic_pm_domain *genpd;
+	int ret;
 
 	genpd = container_of(work, struct generic_pm_domain, power_off_work);
 
 	genpd_lock(genpd);
-	genpd_power_off(genpd, false, 0);
+	ret = genpd_power_off(genpd, false, 0);
 	genpd_unlock(genpd);
+
+	if (!ret)
+		pm_genpd_disable_clks(genpd);
 }
 
 /**
@@ -925,9 +981,12 @@ static int genpd_runtime_suspend(struct device *dev)
 
 	genpd_lock(genpd);
 	gpd_data->rpm_pstate = genpd_drop_performance_state(dev);
-	genpd_power_off(genpd, true, 0);
+	ret = genpd_power_off(genpd, true, 0);
 	genpd_unlock(genpd);
 
+	if (!ret)
+		pm_genpd_disable_clks(genpd);
+
 	return 0;
 }
 
@@ -945,6 +1004,7 @@ static int genpd_runtime_resume(struct device *dev)
 	struct generic_pm_domain_data *gpd_data = dev_gpd_data(dev);
 	struct gpd_timing_data *td = &gpd_data->td;
 	bool runtime_pm = pm_runtime_enabled(dev);
+	bool pd_was_on = false;
 	ktime_t time_start;
 	s64 elapsed_ns;
 	int ret;
@@ -965,14 +1025,22 @@ static int genpd_runtime_resume(struct device *dev)
 		goto out;
 	}
 
+	ret = pm_genpd_enable_clks(genpd);
+	if (ret)
+		return ret;
+
 	genpd_lock(genpd);
-	ret = genpd_power_on(genpd, 0);
+	ret = genpd_power_on(genpd, 0, &pd_was_on);
 	if (!ret)
 		genpd_restore_performance_state(dev, gpd_data->rpm_pstate);
 	genpd_unlock(genpd);
 
-	if (ret)
+	if (ret) {
+		pm_genpd_disable_clks(genpd);
 		return ret;
+	} else if (pd_was_on) {
+		pm_genpd_disable_clks(genpd);
+	}
 
  out:
 	/* Measure resume latency. */
@@ -1012,6 +1080,8 @@ static int genpd_runtime_resume(struct device *dev)
 		genpd_unlock(genpd);
 	}
 
+	pm_genpd_disable_clks(genpd);
+
 	return ret;
 }
 
@@ -1062,15 +1132,24 @@ late_initcall(genpd_power_off_unused);
  * these cases the lock must be held.
  */
 static void genpd_sync_power_off(struct generic_pm_domain *genpd, bool use_lock,
-				 unsigned int depth)
+				 unsigned int depth, bool *need_disable_clk)
 {
 	struct gpd_link *link;
 
-	if (!genpd_status_on(genpd) || genpd_is_always_on(genpd))
+	/*
+	 * Give the power domain a chance to switch to the deepest state in
+	 * case it's already off but in an intermediate low power state.
+	 */
+	genpd->state_idx_saved = genpd->state_idx;
+
+	if (genpd_is_always_on(genpd))
 		return;
 
-	if (genpd->suspended_count != genpd->device_count
-	    || atomic_read(&genpd->sd_count) > 0)
+	if (!genpd_status_on(genpd) &&
+	    genpd->state_idx == (genpd->state_count - 1))
+		return;
+
+	if (genpd->suspended_count != genpd->device_count)
 		return;
 
 	/* Choose the deepest state when suspending */
@@ -1078,18 +1157,26 @@ static void genpd_sync_power_off(struct generic_pm_domain *genpd, bool use_lock,
 	if (_genpd_power_off(genpd, false))
 		return;
 
+	if (genpd->status == GENPD_STATE_OFF)
+		return;
+
 	genpd->status = GENPD_STATE_OFF;
+	*need_disable_clk = true;
 
 	list_for_each_entry(link, &genpd->child_links, child_node) {
+		bool disable_clk = false;
 		genpd_sd_counter_dec(link->parent);
 
 		if (use_lock)
 			genpd_lock_nested(link->parent, depth + 1);
 
-		genpd_sync_power_off(link->parent, use_lock, depth + 1);
+		genpd_sync_power_off(link->parent, use_lock, depth + 1, &disable_clk);
 
 		if (use_lock)
 			genpd_unlock(link->parent);
+
+		if (disable_clk)
+			pm_genpd_disable_clks(link->parent);
 	}
 }
 
@@ -1104,26 +1191,38 @@ static void genpd_sync_power_off(struct generic_pm_domain *genpd, bool use_lock,
  * these cases the lock must be held.
  */
 static void genpd_sync_power_on(struct generic_pm_domain *genpd, bool use_lock,
-				unsigned int depth)
+				unsigned int depth, bool *pd_was_on)
 {
 	struct gpd_link *link;
 
-	if (genpd_status_on(genpd))
+	if (genpd_status_on(genpd)) {
+		*pd_was_on = true;
 		return;
+	}
 
 	list_for_each_entry(link, &genpd->child_links, child_node) {
+		bool pd_state = false;
+
 		genpd_sd_counter_inc(link->parent);
 
+		pm_genpd_enable_clks(link->parent);
+
 		if (use_lock)
 			genpd_lock_nested(link->parent, depth + 1);
 
-		genpd_sync_power_on(link->parent, use_lock, depth + 1);
+		genpd_sync_power_on(link->parent, use_lock, depth + 1, &pd_state);
 
 		if (use_lock)
 			genpd_unlock(link->parent);
+
+		if (pd_state)
+			pm_genpd_disable_clks(link->parent);
 	}
 
 	_genpd_power_on(genpd, false);
+	/* restore save power domain state after resume */
+	genpd->state_idx = genpd->state_idx_saved;
+
 	genpd->status = GENPD_STATE_ON;
 }
 
@@ -1179,6 +1278,7 @@ static int genpd_prepare(struct device *dev)
 static int genpd_finish_suspend(struct device *dev, bool poweroff)
 {
 	struct generic_pm_domain *genpd;
+	bool need_disable_clk = false;
 	int ret = 0;
 
 	genpd = dev_to_genpd(dev);
@@ -1209,9 +1309,12 @@ static int genpd_finish_suspend(struct device *dev, bool poweroff)
 
 	genpd_lock(genpd);
 	genpd->suspended_count++;
-	genpd_sync_power_off(genpd, true, 0);
+	genpd_sync_power_off(genpd, true, 0, &need_disable_clk);
 	genpd_unlock(genpd);
 
+	if (need_disable_clk)
+		pm_genpd_disable_clks(genpd);
+
 	return 0;
 }
 
@@ -1238,6 +1341,7 @@ static int genpd_suspend_noirq(struct device *dev)
 static int genpd_resume_noirq(struct device *dev)
 {
 	struct generic_pm_domain *genpd;
+	bool pd_was_on = false;
 	int ret;
 
 	dev_dbg(dev, "%s()\n", __func__);
@@ -1249,11 +1353,18 @@ static int genpd_resume_noirq(struct device *dev)
 	if (device_wakeup_path(dev) && genpd_is_active_wakeup(genpd))
 		return pm_generic_resume_noirq(dev);
 
+	ret = pm_genpd_enable_clks(genpd);
+	if (ret)
+		return ret;
+
 	genpd_lock(genpd);
-	genpd_sync_power_on(genpd, true, 0);
+	genpd_sync_power_on(genpd, true, 0, &pd_was_on);
 	genpd->suspended_count--;
 	genpd_unlock(genpd);
 
+	if (pd_was_on)
+		pm_genpd_disable_clks(genpd);
+
 	if (genpd->dev_ops.stop && genpd->dev_ops.start &&
 	    !pm_runtime_status_suspended(dev)) {
 		ret = genpd_start_dev(genpd, dev);
@@ -1348,6 +1459,7 @@ static int genpd_poweroff_noirq(struct device *dev)
 static int genpd_restore_noirq(struct device *dev)
 {
 	struct generic_pm_domain *genpd;
+	bool pd_was_on = false;
 	int ret = 0;
 
 	dev_dbg(dev, "%s()\n", __func__);
@@ -1356,6 +1468,10 @@ static int genpd_restore_noirq(struct device *dev)
 	if (IS_ERR(genpd))
 		return -EINVAL;
 
+	ret = pm_genpd_enable_clks(genpd);
+	if (ret)
+		return ret;
+
 	/*
 	 * At this point suspended_count == 0 means we are being run for the
 	 * first time for the given domain in the present cycle.
@@ -1370,9 +1486,12 @@ static int genpd_restore_noirq(struct device *dev)
 		genpd->status = GENPD_STATE_OFF;
 	}
 
-	genpd_sync_power_on(genpd, true, 0);
+	genpd_sync_power_on(genpd, true, 0, &pd_was_on);
 	genpd_unlock(genpd);
 
+	if (pd_was_on)
+		pm_genpd_disable_clks(genpd);
+
 	if (genpd->dev_ops.stop && genpd->dev_ops.start &&
 	    !pm_runtime_status_suspended(dev)) {
 		ret = genpd_start_dev(genpd, dev);
@@ -1416,12 +1535,16 @@ static void genpd_complete(struct device *dev)
 static void genpd_switch_state(struct device *dev, bool suspend)
 {
 	struct generic_pm_domain *genpd;
+	bool need_disable_clk = false;
 	bool use_lock;
 
 	genpd = dev_to_genpd_safe(dev);
 	if (!genpd)
 		return;
 
+	if (!suspend)
+		pm_genpd_enable_clks(genpd);
+
 	use_lock = genpd_is_irq_safe(genpd);
 
 	if (use_lock)
@@ -1429,14 +1552,17 @@ static void genpd_switch_state(struct device *dev, bool suspend)
 
 	if (suspend) {
 		genpd->suspended_count++;
-		genpd_sync_power_off(genpd, use_lock, 0);
+		genpd_sync_power_off(genpd, use_lock, 0, &need_disable_clk);
 	} else {
-		genpd_sync_power_on(genpd, use_lock, 0);
+		genpd_sync_power_on(genpd, use_lock, 0, &need_disable_clk);
 		genpd->suspended_count--;
 	}
 
 	if (use_lock)
 		genpd_unlock(genpd);
+
+	if (need_disable_clk)
+		pm_genpd_disable_clks(genpd);
 }
 
 /**
@@ -1978,9 +2104,10 @@ int pm_genpd_init(struct generic_pm_domain *genpd,
 	genpd->device_count = 0;
 	genpd->max_off_time_ns = -1;
 	genpd->max_off_time_changed = true;
-	genpd->next_wakeup = KTIME_MAX;
 	genpd->provider = NULL;
 	genpd->has_provider = false;
+	genpd->clks = NULL;
+	genpd->num_clks = 0;
 	genpd->accounting_time = ktime_get();
 	genpd->domain.ops.runtime_suspend = genpd_runtime_suspend;
 	genpd->domain.ops.runtime_resume = genpd_runtime_resume;
@@ -2017,7 +2144,7 @@ int pm_genpd_init(struct generic_pm_domain *genpd,
 			return ret;
 		}
 	} else if (!gov && genpd->state_count > 1) {
-		pr_warn("%s: no governor for states\n", genpd->name);
+		pr_debug("%s: no governor for states\n", genpd->name);
 	}
 
 	device_initialize(&genpd->dev);
@@ -2059,9 +2186,9 @@ static int genpd_remove(struct generic_pm_domain *genpd)
 		kfree(link);
 	}
 
+	genpd_debug_remove(genpd);
 	list_del(&genpd->gpd_list_node);
 	genpd_unlock(genpd);
-	genpd_debug_remove(genpd);
 	cancel_work_sync(&genpd->power_off_work);
 	if (genpd_is_cpu_domain(genpd))
 		free_cpumask_var(genpd->cpus);
@@ -2650,6 +2777,7 @@ static int __genpd_dev_pm_attach(struct device *dev, struct device *base_dev,
 {
 	struct of_phandle_args pd_args;
 	struct generic_pm_domain *pd;
+	bool pd_was_on = false;
 	int pstate;
 	int ret;
 
@@ -2683,15 +2811,22 @@ static int __genpd_dev_pm_attach(struct device *dev, struct device *base_dev,
 	dev->pm_domain->detach = genpd_dev_pm_detach;
 	dev->pm_domain->sync = genpd_dev_pm_sync;
 
+	ret = pm_genpd_enable_clks(pd);
+	if (ret)
+		return ret;
+
 	if (power_on) {
 		genpd_lock(pd);
-		ret = genpd_power_on(pd, 0);
+		ret = genpd_power_on(pd, 0, &pd_was_on);
 		genpd_unlock(pd);
 	}
 
 	if (ret) {
+		pm_genpd_disable_clks(pd);
 		genpd_remove_device(pd, dev);
 		return -EPROBE_DEFER;
+	} else if (pd_was_on) {
+		pm_genpd_disable_clks(pd);
 	}
 
 	/* Set the default performance state */
@@ -2710,6 +2845,7 @@ static int __genpd_dev_pm_attach(struct device *dev, struct device *base_dev,
 err:
 	dev_err(dev, "failed to set required performance state for power-domain %s: %d\n",
 		pd->name, ret);
+	pm_genpd_disable_clks(pd);
 	genpd_remove_device(pd, dev);
 	return ret;
 }
diff --git a/drivers/clk/clk-bulk.c b/drivers/clk/clk-bulk.c
index e9e16425c..470155856 100644
--- a/drivers/clk/clk-bulk.c
+++ b/drivers/clk/clk-bulk.c
@@ -43,7 +43,7 @@ static int __must_check of_clk_bulk_get(struct device_node *np, int num_clks,
 	return ret;
 }
 
-static int __must_check of_clk_bulk_get_all(struct device_node *np,
+int __must_check of_clk_bulk_get_all(struct device_node *np,
 					    struct clk_bulk_data **clks)
 {
 	struct clk_bulk_data *clk_bulk;
@@ -68,6 +68,7 @@ static int __must_check of_clk_bulk_get_all(struct device_node *np,
 
 	return num_clks;
 }
+EXPORT_SYMBOL_GPL(of_clk_bulk_get_all);
 
 void clk_bulk_put(int num_clks, struct clk_bulk_data *clks)
 {
diff --git a/drivers/firmware/imx/Kconfig b/drivers/firmware/imx/Kconfig
index c027d99f2..43f043c51 100644
--- a/drivers/firmware/imx/Kconfig
+++ b/drivers/firmware/imx/Kconfig
@@ -28,3 +28,25 @@ config IMX_SCU_PD
 	depends on IMX_SCU
 	help
 	  The System Controller Firmware (SCFW) based power domain driver.
+
+config IMX_SECO_MU
+	tristate "i.MX Security Controller (SECO) support"
+	depends on IMX_MBOX
+	default y if IMX_SCU
+
+	help
+	  It is possible to use APIs exposed by the SECO like HSM and SHE using the
+	  SAB protocol via the shared Messaging Unit. This driver exposes these
+	  interfaces via a set of file descriptors allowing to configure shared
+	  memory, send and receive messages.
+
+config IMX_EL_ENCLAVE
+	tristate "i.MX Embedded EdgeLock Enclave support."
+	depends on IMX_MBOX
+	default y if ARM64
+
+	help
+	  It is possible to use APIs exposed by the iMX EdgeLock Enclave like base, HSM &
+	  SHE using the SAB protocol via the shared Messaging Unit. This driver exposes
+	  these interfaces via a set of file descriptors allowing to configure shared
+	  memory, send and receive messages.
diff --git a/drivers/firmware/imx/Makefile b/drivers/firmware/imx/Makefile
index b76acbade..f73720edd 100644
--- a/drivers/firmware/imx/Makefile
+++ b/drivers/firmware/imx/Makefile
@@ -1,4 +1,7 @@
 # SPDX-License-Identifier: GPL-2.0
 obj-$(CONFIG_IMX_DSP)		+= imx-dsp.o
-obj-$(CONFIG_IMX_SCU)		+= imx-scu.o misc.o imx-scu-irq.o rm.o imx-scu-soc.o
+obj-$(CONFIG_IMX_SCU)		+= imx-scu.o misc.o imx-scu-irq.o rm.o imx-scu-soc.o seco.o
 obj-$(CONFIG_IMX_SCU_PD)	+= scu-pd.o
+obj-${CONFIG_IMX_SECO_MU}	+= seco_mu.o
+el_enclave-objs			= ele_mu.o ele_base_msg.o
+obj-${CONFIG_IMX_EL_ENCLAVE}	+= el_enclave.o
diff --git a/drivers/firmware/imx/ele_base_msg.c b/drivers/firmware/imx/ele_base_msg.c
new file mode 100644
index 000000000..4e3381add
--- /dev/null
+++ b/drivers/firmware/imx/ele_base_msg.c
@@ -0,0 +1,176 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Pankaj <pankaj.gupta@nxp.com>
+	   Alice Guo <alice.guo@nxp.com>
+ */
+
+#include <linux/types.h>
+#include <linux/completion.h>
+#include <linux/mailbox_client.h>
+
+#include <linux/firmware/imx/ele_base_msg.h>
+#include <linux/firmware/imx/ele_mu_ioctl.h>
+
+#include "ele_mu.h"
+
+/* Fill a command message header with a given command ID and length in bytes. */
+static int plat_fill_cmd_msg_hdr(struct mu_hdr *hdr, uint8_t cmd, uint32_t len)
+{
+	struct ele_mu_priv *priv = NULL;
+	int err = 0;
+
+	err = get_ele_mu_priv(&priv);
+	if (err) {
+		pr_err("Error: iMX EdgeLock Enclave MU is not probed successfully.\n");
+		return err;
+	}
+	hdr->tag = priv->cmd_tag;
+	hdr->ver = MESSAGING_VERSION_6;
+	hdr->command = cmd;
+	hdr->size = (uint8_t)(len / sizeof(uint32_t));
+
+	return err;
+}
+
+static int imx_ele_msg_send_rcv(struct ele_mu_priv *priv)
+{
+	unsigned int wait;
+	int err = 0;
+
+	mutex_lock(&priv->mu_cmd_lock);
+	mutex_lock(&priv->mu_lock);
+
+	err = mbox_send_message(priv->tx_chan, &priv->tx_msg);
+	if (err < 0) {
+		pr_err("Error: mbox_send_message failure.\n");
+		mutex_unlock(&priv->mu_lock);
+		return err;
+	}
+	mutex_unlock(&priv->mu_lock);
+
+	wait = msecs_to_jiffies(1000);
+	if (!wait_for_completion_timeout(&priv->done, wait)) {
+		mutex_unlock(&priv->mu_cmd_lock);
+		pr_err("Error: wait_for_completion timed out.\n");
+		return -ETIMEDOUT;
+	}
+
+	/* As part of func ele_mu_rx_callback() execution,
+	 * response will copied to ele_msg->rsp_msg.
+	 *
+	 * Lock: (mutex_unlock(&ele_mu_priv->mu_cmd_lock),
+	 * will be unlocked if it is a response.
+	 */
+	return err;
+}
+
+static int read_otp_uniq_id(struct ele_mu_priv *priv, u32 *value)
+{
+	unsigned int tag, command, size, ver, status;
+
+	tag = MSG_TAG(priv->rx_msg.header);
+	command = MSG_COMMAND(priv->rx_msg.header);
+	size = MSG_SIZE(priv->rx_msg.header);
+	ver = MSG_VER(priv->rx_msg.header);
+	status = RES_STATUS(priv->rx_msg.data[0]);
+
+	if (tag == 0xe1 && command == ELE_READ_FUSE_REQ &&
+	    size == 0x07 && ver == ELE_VERSION && status == ELE_SUCCESS_IND) {
+		value[0] = priv->rx_msg.data[1];
+		value[1] = priv->rx_msg.data[2];
+		value[2] = priv->rx_msg.data[3];
+		value[3] = priv->rx_msg.data[4];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int read_fuse_word(struct ele_mu_priv *priv, u32 *value)
+{
+	unsigned int tag, command, size, ver, status;
+
+	tag = MSG_TAG(priv->rx_msg.header);
+	command = MSG_COMMAND(priv->rx_msg.header);
+	size = MSG_SIZE(priv->rx_msg.header);
+	ver = MSG_VER(priv->rx_msg.header);
+	status = RES_STATUS(priv->rx_msg.data[0]);
+
+	if (tag == 0xe1 && command == ELE_READ_FUSE_REQ &&
+	    size == 0x03 && ver == 0x06 && status == ELE_SUCCESS_IND) {
+		value[0] = priv->rx_msg.data[1];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+int read_common_fuse(uint16_t fuse_id, u32 *value)
+{
+	struct ele_mu_priv *priv = NULL;
+	int err = 0;
+
+	err = get_ele_mu_priv(&priv);
+	if (err) {
+		pr_err("Error: iMX EdgeLock Enclave MU is not probed successfully.\n");
+		return err;
+	}
+	err = plat_fill_cmd_msg_hdr((struct mu_hdr *)&priv->tx_msg.header, ELE_READ_FUSE_REQ, 8);
+	if (err) {
+		pr_err("Error: plat_fill_cmd_msg_hdr failed.\n");
+		return err;
+	}
+
+	priv->tx_msg.data[0] = fuse_id;
+	err = imx_ele_msg_send_rcv(priv);
+	if (err < 0)
+		return err;
+
+	switch (fuse_id) {
+	case OTP_UNIQ_ID:
+		err = read_otp_uniq_id(priv, value);
+		break;
+	default:
+		err = read_fuse_word(priv, value);
+		break;
+	}
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(read_common_fuse);
+
+int ele_ping(void)
+{
+	struct ele_mu_priv *priv = NULL;
+	unsigned int tag, command, size, ver, status;
+	int err;
+
+	err = get_ele_mu_priv(&priv);
+	if (err) {
+		pr_err("Error: iMX EdgeLock Enclave MU is not probed successfully.\n");
+		return err;
+	}
+	err = plat_fill_cmd_msg_hdr((struct mu_hdr *)&priv->tx_msg.header, ELE_PING_REQ, 4);
+	if (err) {
+		pr_err("Error: plat_fill_cmd_msg_hdr failed.\n");
+		return err;
+	}
+
+	err = imx_ele_msg_send_rcv(priv);
+	if (err < 0)
+		return err;
+
+	tag = MSG_TAG(priv->rx_msg.header);
+	command = MSG_COMMAND(priv->rx_msg.header);
+	size = MSG_SIZE(priv->rx_msg.header);
+	ver = MSG_VER(priv->rx_msg.header);
+	status = RES_STATUS(priv->rx_msg.data[0]);
+
+	if (tag == 0xe1 && command == ELE_PING_REQ &&
+	    size == 0x2 && ver == ELE_VERSION && status == ELE_SUCCESS_IND)
+		return 0;
+
+	return -EAGAIN;
+}
+EXPORT_SYMBOL_GPL(ele_ping);
diff --git a/drivers/firmware/imx/ele_mu.c b/drivers/firmware/imx/ele_mu.c
new file mode 100644
index 000000000..ad05abed5
--- /dev/null
+++ b/drivers/firmware/imx/ele_mu.c
@@ -0,0 +1,918 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Alice Guo <alice.guo@nxp.com>
+ * Author: Pankaj Gupta <pankaj.gupta@nxp.com>
+ */
+
+#include <linux/dma-mapping.h>
+#include <linux/completion.h>
+#include <linux/dev_printk.h>
+#include <linux/errno.h>
+#include <linux/export.h>
+#include <linux/firmware/imx/ele_base_msg.h>
+#include <linux/firmware/imx/ele_mu_ioctl.h>
+#include <linux/io.h>
+#include <linux/init.h>
+#include <linux/mailbox_client.h>
+#include <linux/miscdevice.h>
+#include <linux/mod_devicetable.h>
+#include <linux/module.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/sys_soc.h>
+
+#include "ele_mu.h"
+
+struct ele_mu_priv *ele_priv_export;
+
+int get_ele_mu_priv(struct ele_mu_priv **export)
+{
+	if (!ele_priv_export)
+		return -EPROBE_DEFER;
+
+	*export = ele_priv_export;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(get_ele_mu_priv);
+
+
+/*
+ * Callback called by mailbox FW when data are received
+ */
+static void ele_mu_rx_callback(struct mbox_client *c, void *msg)
+{
+	struct device *dev = c->dev;
+	struct ele_mu_priv *priv = dev_get_drvdata(dev);
+	struct ele_mu_device_ctx *dev_ctx;
+	bool is_response = false;
+	int msg_size;
+	struct mu_hdr header;
+
+	dev_dbg(dev, "Message received on mailbox\n");
+
+	/* The function can be called with NULL msg */
+	if (!msg) {
+		dev_err(dev, "Message is invalid\n");
+		return;
+	}
+
+	if (IS_ERR(msg)) {
+		dev_err(dev, "Error during reception of message: %ld\n",
+				PTR_ERR(msg));
+		return;
+	}
+
+	header.tag = ((u8 *)msg)[3];
+	header.command = ((u8 *)msg)[2];
+	header.size = ((u8 *)msg)[1];
+	header.ver = ((u8 *)msg)[0];
+
+	dev_dbg(dev, "Selecting device\n");
+
+	/* Incoming command: wake up the receiver if any. */
+	if (header.tag == priv->cmd_tag) {
+		dev_dbg(dev, "Selecting cmd receiver\n");
+		dev_ctx = priv->cmd_receiver_dev;
+	} else if (header.tag == priv->rsp_tag) {
+		if (priv->waiting_rsp_dev) {
+			dev_dbg(dev, "Selecting rsp waiter\n");
+			dev_ctx = priv->waiting_rsp_dev;
+			is_response = true;
+		} else {
+			/* Reading the EdgeLock Enclave response
+			 * to the command sent by other
+			 * linux kernel services.
+			 */
+			spin_lock(&priv->lock);
+			priv->rx_msg = *(struct ele_api_msg *)msg;
+			complete(&priv->done);
+			spin_unlock(&priv->lock);
+			mutex_unlock(&priv->mu_cmd_lock);
+			return;
+		}
+	} else {
+		dev_err(dev, "Failed to select a device for message: %.8x\n",
+				*((u32 *) &header));
+		return;
+	}
+
+	if (!dev_ctx) {
+		dev_err(dev, "No device context selected for message: %.8x\n",
+				*((u32 *)&header));
+		return;
+	}
+	/* Init reception */
+	msg_size = header.size;
+	if (msg_size > MAX_RECV_SIZE) {
+		devctx_err(dev_ctx, "Message is too big (%d > %d)", msg_size,
+				MAX_RECV_SIZE);
+		return;
+	}
+
+	memcpy(dev_ctx->temp_resp, msg, msg_size * sizeof(u32));
+	dev_ctx->temp_resp_size = msg_size;
+
+	/* Allow user to read */
+	dev_ctx->pending_hdr = dev_ctx->temp_resp[0];
+	wake_up_interruptible(&dev_ctx->wq);
+
+	if (is_response) {
+		/* Allow user to send new command */
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+}
+
+struct device *imx_soc_device_register(void)
+{
+	struct soc_device_attribute *attr;
+	struct soc_device *dev;
+	u32 v[4];
+	int err;
+
+	err = read_common_fuse(OTP_UNIQ_ID, v);
+	if (err)
+		return NULL;
+
+	attr = kzalloc(sizeof(*attr), GFP_KERNEL);
+	if (!attr)
+		return NULL;
+
+	err = of_property_read_string(of_root, "model", &attr->machine);
+	if (err) {
+		kfree(attr);
+		return NULL;
+	}
+	attr->family = kasprintf(GFP_KERNEL, "Freescale i.MX");
+	attr->revision = kasprintf(GFP_KERNEL, "1.0");
+	attr->serial_number = kasprintf(GFP_KERNEL, "%016llX", (u64)v[3] << 32 | v[0]);
+	attr->soc_id = kasprintf(GFP_KERNEL, "i.MX8ULP");
+
+	dev = soc_device_register(attr);
+	if (IS_ERR(dev)) {
+		kfree(attr->soc_id);
+		kfree(attr->serial_number);
+		kfree(attr->revision);
+		kfree(attr->family);
+		kfree(attr->machine);
+		kfree(attr);
+		return ERR_CAST(dev);
+	}
+
+	return soc_device_to_device(dev);
+}
+
+/*
+ * File operations for user-space
+ */
+
+/* Write a message to the MU. */
+static ssize_t ele_mu_fops_write(struct file *fp, const char __user *buf,
+				    size_t size, loff_t *ppos)
+{
+	struct ele_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					   struct ele_mu_device_ctx, miscdev);
+	struct ele_mu_priv *ele_mu_priv = dev_ctx->priv;
+	u32 nb_words = 0;
+	struct mu_hdr header;
+	int err;
+
+	devctx_dbg(dev_ctx, "write from buf (%p)%ld, ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (size < 4) {//sizeof(struct she_mu_hdr)) {
+		devctx_err(dev_ctx, "User buffer too small(%ld < %x)\n", size, 0x4);
+		//devctx_err(dev_ctx, "User buffer too small(%ld < %lu)\n", size, ()0x4);
+			  // sizeof(struct she_mu_hdr));
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	if (size > MAX_MESSAGE_SIZE_BYTES) {
+		devctx_err(dev_ctx, "User buffer too big(%ld > %lu)\n", size,
+			   MAX_MESSAGE_SIZE_BYTES);
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	/* Copy data to buffer */
+	err = (int)copy_from_user(dev_ctx->temp_cmd, buf, size);
+	if (err) {
+		err = -EFAULT;
+		devctx_err(dev_ctx, "Fail copy message from user\n");
+		goto exit;
+	}
+
+	print_hex_dump_debug("from user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_cmd, size, false);
+
+	header = *((struct mu_hdr *) (&dev_ctx->temp_cmd[0]));
+
+	/* Check the message is valid according to tags */
+	if (header.tag == ele_mu_priv->cmd_tag) {
+		/*
+		 * unlocked in ele_mu_receive_work_handler when the
+		 * response to this command is received.
+		 */
+		mutex_lock(&ele_mu_priv->mu_cmd_lock);
+		ele_mu_priv->waiting_rsp_dev = dev_ctx;
+	} else if (header.tag == ele_mu_priv->rsp_tag) {
+		/* Check the device context can send the command */
+		if (dev_ctx != ele_mu_priv->cmd_receiver_dev) {
+			devctx_err(dev_ctx,
+				   "This channel is not configured to send response to SECO\n");
+			err = -EPERM;
+			goto exit;
+		}
+	} else {
+		devctx_err(dev_ctx, "The message does not have a valid TAG\n");
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/*
+	 * Check that the size passed as argument matches the size
+	 * carried in the message.
+	 */
+	nb_words = header.size;
+	if (nb_words * sizeof(u32) != size) {
+		devctx_err(dev_ctx, "User buffer too small\n");
+		goto exit;
+	}
+
+	mutex_lock(&ele_mu_priv->mu_lock);
+
+	/* Send message */
+	devctx_dbg(dev_ctx, "sending message\n");
+	err = mbox_send_message(ele_mu_priv->tx_chan, dev_ctx->temp_cmd);
+	if (err < 0) {
+		devctx_err(dev_ctx, "Failed to send message\n");
+		goto unlock;
+	}
+
+	err = nb_words * (u32)sizeof(u32);
+
+unlock:
+	mutex_unlock(&ele_mu_priv->mu_lock);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/*
+ * Read a message from the MU.
+ * Blocking until a message is available.
+ */
+static ssize_t ele_mu_fops_read(struct file *fp, char __user *buf,
+				 size_t size, loff_t *ppos)
+{
+	struct ele_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					   struct ele_mu_device_ctx, miscdev);
+	u32 data_size = 0, size_to_copy = 0;
+	struct ele_obuf_desc *b_desc;
+	int err;
+
+	devctx_dbg(dev_ctx, "read to buf %p(%ld), ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/* Wait until the complete message is received on the MU. */
+	err = wait_event_interruptible(dev_ctx->wq, dev_ctx->pending_hdr != 0);
+	if (err) {
+		devctx_err(dev_ctx, "Err[0x%x]:Interrupted by signal.\n", err);
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "%s %s\n", __func__,
+		   "message received, start transmit to user");
+
+	/* Check that the size passed as argument is larger than
+	 * the one carried in the message.
+	 */
+	data_size = dev_ctx->temp_resp_size * sizeof(u32);
+	size_to_copy = data_size;
+	if (size_to_copy > size) {
+		devctx_dbg(dev_ctx, "User buffer too small (%ld < %d)\n",
+			   size, size_to_copy);
+		size_to_copy = size;
+	}
+
+	/* We may need to copy the output data to user before
+	 * delivering the completion message.
+	 */
+	while (!list_empty(&dev_ctx->pending_out)) {
+		b_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						  struct ele_obuf_desc,
+						  link);
+		if (b_desc->out_usr_ptr && b_desc->out_ptr) {
+			devctx_dbg(dev_ctx, "Copy output data to user\n");
+			err = (int)copy_to_user(b_desc->out_usr_ptr,
+						b_desc->out_ptr,
+						b_desc->out_size);
+			if (err) {
+				devctx_err(dev_ctx,
+					   "Failed to copy output data to user\n");
+				err = -EFAULT;
+				goto exit;
+			}
+		}
+		__list_del_entry(&b_desc->link);
+		devm_kfree(dev_ctx->dev, b_desc);
+	}
+
+	/* Copy data from the buffer */
+	print_hex_dump_debug("to user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_resp, size_to_copy, false);
+	err = (int)copy_to_user(buf, dev_ctx->temp_resp, size_to_copy);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	err = size_to_copy;
+
+	/* free memory allocated on the shared buffers. */
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	dev_ctx->pending_hdr = 0;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Give access to EdgeLock Enclave, to the memory we want to share */
+static int ele_mu_setup_ele_mem_access(struct ele_mu_device_ctx *dev_ctx,
+					     u64 addr, u32 len)
+{
+	/* Assuming EdgeLock Enclave has access to all the memory regions */
+	int ret = 0;
+
+	if (ret) {
+		devctx_err(dev_ctx, "Fail find memreg\n");
+		goto exit;
+	}
+
+	if (ret) {
+		devctx_err(dev_ctx, "Fail set permission for resource\n");
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+static int ele_mu_ioctl_get_mu_info(struct ele_mu_device_ctx *dev_ctx,
+				  unsigned long arg)
+{
+	struct ele_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct ele_mu_ioctl_get_mu_info info;
+	int err = -EINVAL;
+
+	info.ele_mu_id = (u8)priv->ele_mu_id;
+	info.interrupt_idx = 0;
+	info.tz = 0;
+	info.did = 0x7;
+
+	devctx_dbg(dev_ctx,
+		   "info [mu_idx: %d, irq_idx: %d, tz: 0x%x, did: 0x%x]\n",
+		   info.ele_mu_id, info.interrupt_idx, info.tz, info.did);
+
+	err = (int)copy_to_user((u8 *)arg, &info,
+		sizeof(info));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy mu info to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/*
+ * Copy a buffer of daa to/from the user and return the address to use in
+ * messages
+ */
+static int ele_mu_ioctl_setup_iobuf_handler(struct ele_mu_device_ctx *dev_ctx,
+					       unsigned long arg)
+{
+	struct ele_obuf_desc *out_buf_desc;
+	struct ele_mu_ioctl_setup_iobuf io = {0};
+	struct ele_shared_mem *shared_mem;
+	int err = -EINVAL;
+	u32 pos;
+
+	err = (int)copy_from_user(&io,
+		(u8 *)arg,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed copy iobuf config from user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "io [buf: %p(%d) flag: %x]\n",
+		   io.user_buf, io.length, io.flags);
+
+	if (io.length == 0 || !io.user_buf) {
+		/*
+		 * Accept NULL pointers since some buffers are optional
+		 * in SECO commands. In this case we should return 0 as
+		 * pointer to be embedded into the message.
+		 * Skip all data copy part of code below.
+		 */
+		io.ele_addr = 0;
+		goto copy;
+	}
+
+	/* Select the shared memory to be used for this buffer. */
+	if (io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) {
+		/* App requires to use secure memory for this buffer.*/
+		devctx_err(dev_ctx, "Failed allocate SEC MEM memory\n");
+		err = -EFAULT;
+		goto exit;
+	} else {
+		/* No specific requirement for this buffer. */
+		shared_mem = &dev_ctx->non_secure_mem;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (io.length >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough space in shared memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+	shared_mem->pos += round_up(io.length, 8u);
+	io.ele_addr = (u64)shared_mem->dma_addr + pos;
+
+	if ((io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) &&
+	    !(io.flags & SECO_MU_IO_FLAGS_USE_SHORT_ADDR)) {
+		/*Add base address to get full address.*/
+		devctx_err(dev_ctx, "Failed allocate SEC MEM memory\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	if (io.flags & SECO_MU_IO_FLAGS_IS_INPUT) {
+		/*
+		 * buffer is input:
+		 * copy data from user space to this allocated buffer.
+		 */
+		err = (int)copy_from_user(shared_mem->ptr + pos, io.user_buf,
+					  io.length);
+		if (err) {
+			devctx_err(dev_ctx,
+				   "Failed copy data to shared memory\n");
+			err = -EFAULT;
+			goto exit;
+		}
+	} else {
+		/*
+		 * buffer is output:
+		 * add an entry in the "pending buffers" list so data
+		 * can be copied to user space when receiving SECO
+		 * response.
+		 */
+		out_buf_desc = devm_kmalloc(dev_ctx->dev, sizeof(*out_buf_desc),
+					    GFP_KERNEL);
+		if (!out_buf_desc) {
+			err = -ENOMEM;
+			devctx_err(dev_ctx,
+				   "Failed allocating mem for pending buffer\n"
+				   );
+			goto exit;
+		}
+
+		out_buf_desc->out_ptr = shared_mem->ptr + pos;
+		out_buf_desc->out_usr_ptr = io.user_buf;
+		out_buf_desc->out_size = io.length;
+		list_add_tail(&out_buf_desc->link, &dev_ctx->pending_out);
+	}
+
+copy:
+	/* Provide the EdgeLock Enclave address to user space only if success. */
+	err = (int)copy_to_user((u8 *)arg, &io,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy iobuff setup to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+exit:
+	return err;
+}
+
+
+
+/* Open a char device. */
+static int ele_mu_fops_open(struct inode *nd, struct file *fp)
+{
+	struct ele_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+							    struct ele_mu_device_ctx,
+							    miscdev);
+	int err;
+
+	/* Avoid race if opened at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* Authorize only 1 instance. */
+	if (dev_ctx->status != MU_FREE) {
+		err = -EBUSY;
+		goto exit;
+	}
+
+	/*
+	 * Allocate some memory for data exchanges with S40x.
+	 * This will be used for data not requiring secure memory.
+	 */
+	dev_ctx->non_secure_mem.ptr = dmam_alloc_coherent(dev_ctx->dev,
+					MAX_DATA_SIZE_PER_USER,
+					&dev_ctx->non_secure_mem.dma_addr,
+					GFP_KERNEL);
+	if (!dev_ctx->non_secure_mem.ptr) {
+		err = -ENOMEM;
+		devctx_err(dev_ctx, "Failed to map shared memory with S40x\n");
+		goto exit;
+	}
+
+	err = ele_mu_setup_ele_mem_access(dev_ctx,
+						dev_ctx->non_secure_mem.dma_addr,
+						MAX_DATA_SIZE_PER_USER);
+	if (err) {
+		err = -EPERM;
+		devctx_err(dev_ctx,
+			   "Failed to share access to shared memory\n");
+		goto free_coherent;
+	}
+
+	dev_ctx->non_secure_mem.size = MAX_DATA_SIZE_PER_USER;
+	dev_ctx->non_secure_mem.pos = 0;
+	dev_ctx->status = MU_OPENED;
+
+	dev_ctx->pending_hdr = 0;
+
+	goto exit;
+
+free_coherent:
+	dmam_free_coherent(dev_ctx->priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Close a char device. */
+static int ele_mu_fops_close(struct inode *nd, struct file *fp)
+{
+	struct ele_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct ele_mu_device_ctx, miscdev);
+	struct ele_mu_priv *priv = dev_ctx->priv;
+	struct ele_obuf_desc *out_buf_desc;
+
+	/* Avoid race if closed at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* The device context has not been opened */
+	if (dev_ctx->status != MU_OPENED)
+		goto exit;
+
+	/* check if this device was registered as command receiver. */
+	if (priv->cmd_receiver_dev == dev_ctx)
+		priv->cmd_receiver_dev = NULL;
+
+	/* check if this device was registered as waiting response. */
+	if (priv->waiting_rsp_dev == dev_ctx) {
+		priv->waiting_rsp_dev = NULL;
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+
+	/* Unmap secure memory shared buffer. */
+	if (dev_ctx->secure_mem.ptr)
+		devm_iounmap(dev_ctx->dev, dev_ctx->secure_mem.ptr);
+
+	dev_ctx->secure_mem.ptr = NULL;
+	dev_ctx->secure_mem.dma_addr = 0;
+	dev_ctx->secure_mem.size = 0;
+	dev_ctx->secure_mem.pos = 0;
+
+	/* Free non-secure shared buffer. */
+	dmam_free_coherent(dev_ctx->priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+	dev_ctx->non_secure_mem.ptr = NULL;
+	dev_ctx->non_secure_mem.dma_addr = 0;
+	dev_ctx->non_secure_mem.size = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	while (!list_empty(&dev_ctx->pending_out)) {
+		out_buf_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						struct ele_obuf_desc,
+						link);
+		__list_del_entry(&out_buf_desc->link);
+		devm_kfree(dev_ctx->dev, out_buf_desc);
+	}
+
+	dev_ctx->status = MU_FREE;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return 0;
+}
+
+/* IOCTL entry point of a char device */
+static long ele_mu_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
+{
+	struct ele_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+							    struct ele_mu_device_ctx,
+							    miscdev);
+	struct ele_mu_priv *ele_mu_priv = dev_ctx->priv;
+	int err = -EINVAL;
+
+	/* Prevent race during change of device context */
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	switch (cmd) {
+	case ELE_MU_IOCTL_ENABLE_CMD_RCV:
+		if (!ele_mu_priv->cmd_receiver_dev) {
+			ele_mu_priv->cmd_receiver_dev = dev_ctx;
+			err = 0;
+		};
+		break;
+	case ELE_MU_IOCTL_GET_MU_INFO:
+		err = ele_mu_ioctl_get_mu_info(dev_ctx, arg);
+		break;
+	case ELE_MU_IOCTL_SHARED_BUF_CFG:
+		devctx_err(dev_ctx, "ELE_MU_IOCTL_SHARED_BUF_CFG not supported [0x%x].\n", err);
+		break;
+	case ELE_MU_IOCTL_SETUP_IOBUF:
+		err = ele_mu_ioctl_setup_iobuf_handler(dev_ctx, arg);
+		break;
+	case ELE_MU_IOCTL_SIGNED_MESSAGE:
+		devctx_err(dev_ctx, "ELE_MU_IOCTL_SIGNED_MESSAGE not supported [0x%x].\n", err);
+		break;
+	default:
+		err = -EINVAL;
+		devctx_dbg(dev_ctx, "IOCTL %.8x not supported\n", cmd);
+	}
+
+	up(&dev_ctx->fops_lock);
+	return (long)err;
+}
+
+/* Char driver setup */
+static const struct file_operations ele_mu_fops = {
+	.open		= ele_mu_fops_open,
+	.owner		= THIS_MODULE,
+	.release	= ele_mu_fops_close,
+	.unlocked_ioctl = ele_mu_ioctl,
+	.read		= ele_mu_fops_read,
+	.write		= ele_mu_fops_write,
+};
+
+/* interface for managed res to free a mailbox channel */
+static void if_mbox_free_channel(void *mbox_chan)
+{
+	mbox_free_channel(mbox_chan);
+}
+
+/* interface for managed res to unregister a char device */
+static void if_misc_deregister(void *miscdevice)
+{
+	misc_deregister(miscdevice);
+}
+
+static int ele_mu_request_channel(struct device *dev,
+				 struct mbox_chan **chan,
+				 struct mbox_client *cl,
+				 const char *name)
+{
+	struct mbox_chan *t_chan;
+	int ret = 0;
+
+	t_chan = mbox_request_channel_byname(cl, name);
+	if (IS_ERR(t_chan)) {
+		ret = PTR_ERR(t_chan);
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev,
+				"Failed to request chan %s ret %d\n", name,
+				ret);
+		goto exit;
+	}
+
+	ret = devm_add_action(dev, if_mbox_free_channel, t_chan);
+	if (ret) {
+		dev_err(dev, "failed to add devm removal of mbox %s\n", name);
+		goto exit;
+	}
+
+	*chan = t_chan;
+
+exit:
+	return ret;
+}
+
+static int ele_mu_probe(struct platform_device *pdev)
+{
+	struct ele_mu_device_ctx *dev_ctx;
+	struct device *dev = &pdev->dev;
+	struct ele_mu_priv *priv;
+	struct device_node *np;
+	int max_nb_users = 0;
+	char *devname;
+	struct device *soc;
+	int ret;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv) {
+		ret = -ENOMEM;
+		dev_err(dev, "Fail allocate mem for private data\n");
+		goto exit;
+	}
+	priv->dev = dev;
+	dev_set_drvdata(dev, priv);
+
+	/*
+	 * Get the address of MU to be used for communication with the SCU
+	 */
+	np = pdev->dev.of_node;
+	if (!np) {
+		dev_err(dev, "Cannot find MU User entry in device tree\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+	/* Initialize the mutex. */
+	mutex_init(&priv->mu_cmd_lock);
+	mutex_init(&priv->mu_lock);
+
+	/* TBD */
+	priv->cmd_receiver_dev = NULL;
+	priv->waiting_rsp_dev = NULL;
+
+	ret = of_property_read_u32(np, "fsl,ele_mu_id", &priv->ele_mu_id);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_id", __func__);
+		priv->ele_mu_id = S4_DEFAULT_MUAP_INDEX;
+	}
+
+	ret = of_property_read_u32(np, "fsl,ele_mu_max_users", &max_nb_users);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_max_user", __func__);
+		max_nb_users = S4_MUAP_DEFAULT_MAX_USERS;
+	}
+
+	ret = of_property_read_u8(np, "fsl,cmd_tag", &priv->cmd_tag);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read cmd_tag", __func__);
+		priv->cmd_tag = DEFAULT_MESSAGING_TAG_COMMAND;
+	}
+
+	ret = of_property_read_u8(np, "fsl,rsp_tag", &priv->rsp_tag);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read rsp_tag", __func__);
+		priv->rsp_tag = DEFAULT_MESSAGING_TAG_RESPONSE;
+	}
+
+	/* Mailbox client configuration */
+	priv->ele_mb_cl.dev		= dev;
+	priv->ele_mb_cl.tx_block	= false;
+	priv->ele_mb_cl.knows_txdone	= true;
+	priv->ele_mb_cl.rx_callback	= ele_mu_rx_callback;
+
+	ret = ele_mu_request_channel(dev, &priv->tx_chan, &priv->ele_mb_cl, "tx");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request tx channel\n");
+
+		goto exit;
+	}
+
+	ret = ele_mu_request_channel(dev, &priv->rx_chan, &priv->ele_mb_cl, "rx");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request rx channel\n");
+
+		goto exit;
+	}
+
+	/* Create users */
+	for (i = 0; i < max_nb_users; i++) {
+		dev_ctx = devm_kzalloc(dev, sizeof(*dev_ctx), GFP_KERNEL);
+		if (!dev_ctx) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for device context\n");
+			goto exit;
+		}
+
+		dev_ctx->dev = dev;
+		dev_ctx->status = MU_FREE;
+		dev_ctx->priv = priv;
+		/* Default value invalid for an header. */
+		init_waitqueue_head(&dev_ctx->wq);
+
+		INIT_LIST_HEAD(&dev_ctx->pending_out);
+		sema_init(&dev_ctx->fops_lock, 1);
+
+		devname = devm_kasprintf(dev, GFP_KERNEL, "ele_mu%d_ch%d",
+					 priv->ele_mu_id, i);
+		if (!devname) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for misc dev name\n");
+			goto exit;
+		}
+
+		dev_ctx->miscdev.name = devname;
+		dev_ctx->miscdev.minor = MISC_DYNAMIC_MINOR;
+		dev_ctx->miscdev.fops = &ele_mu_fops;
+		dev_ctx->miscdev.parent = dev;
+		ret = misc_register(&dev_ctx->miscdev);
+		if (ret) {
+			dev_err(dev, "failed to register misc device %d\n",
+				ret);
+			goto exit;
+		}
+
+		ret = devm_add_action(dev, if_misc_deregister,
+				      &dev_ctx->miscdev);
+
+	}
+
+	init_completion(&priv->done);
+	spin_lock_init(&priv->lock);
+
+	ele_priv_export = priv;
+
+	soc = imx_soc_device_register();
+	if (IS_ERR(soc)) {
+		pr_err("failed to register SoC device: %ld\n", PTR_ERR(soc));
+		return PTR_ERR(soc);
+	}
+
+	dev_set_drvdata(dev, priv);
+	return devm_of_platform_populate(dev);
+
+exit:
+	return ret;
+}
+
+static int ele_mu_remove(struct platform_device *pdev)
+{
+	struct ele_mu_priv *priv;
+
+	priv = dev_get_drvdata(&pdev->dev);
+	mbox_free_channel(priv->tx_chan);
+	mbox_free_channel(priv->rx_chan);
+
+	return 0;
+}
+
+static const struct of_device_id ele_mu_match[] = {
+	{ .compatible = "fsl,imx-ele", },
+	{},
+};
+
+static struct platform_driver ele_mu_driver = {
+	.driver = {
+		.name = "fsl-ele-mu",
+		.of_match_table = ele_mu_match,
+	},
+	.probe = ele_mu_probe,
+	.remove = ele_mu_remove,
+};
+module_platform_driver(ele_mu_driver);
+
+MODULE_AUTHOR("Pankaj Gupta <pankaj.gupta@nxp.com>");
+MODULE_DESCRIPTION("iMX Secure Enclave MU Driver.");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/firmware/imx/ele_mu.h b/drivers/firmware/imx/ele_mu.h
new file mode 100644
index 000000000..ef0133f30
--- /dev/null
+++ b/drivers/firmware/imx/ele_mu.h
@@ -0,0 +1,139 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2021 NXP
+ */
+
+#ifndef ELE_MU_H
+#define ELE_MU_H
+
+#include <linux/miscdevice.h>
+#include <linux/semaphore.h>
+
+/* macro to log operation of a misc device */
+#define miscdev_dbg(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_dbg((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+#define miscdev_info(p_miscdev, fmt, va_args...)                               \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_info((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name, \
+		##va_args);                                                    \
+	})
+
+#define miscdev_err(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_err((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+/* macro to log operation of a device context */
+#define devctx_dbg(p_devctx, fmt, va_args...) \
+	miscdev_dbg(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_info(p_devctx, fmt, va_args...) \
+	miscdev_info(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_err(p_devctx, fmt, va_args...) \
+	miscdev_err((&(p_devctx)->miscdev), fmt, ##va_args)
+
+#define MSG_TAG(x)			(((x) & 0xff000000) >> 24)
+#define MSG_COMMAND(x)			(((x) & 0x00ff0000) >> 16)
+#define MSG_SIZE(x)			(((x) & 0x0000ff00) >> 8)
+#define MSG_VER(x)			((x) & 0x000000ff)
+#define RES_STATUS(x)			((x) & 0x000000ff)
+#define MAX_DATA_SIZE_PER_USER		(65 * 1024)
+#define S4_DEFAULT_MUAP_INDEX		(2)
+#define S4_MUAP_DEFAULT_MAX_USERS	(4)
+
+#define DEFAULT_MESSAGING_TAG_COMMAND           (0x17u)
+#define DEFAULT_MESSAGING_TAG_RESPONSE          (0xe1u)
+
+#define SECO_MU_IO_FLAGS_IS_INPUT	(0x01u)
+#define SECO_MU_IO_FLAGS_USE_SEC_MEM	(0x02u)
+#define SECO_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+struct ele_obuf_desc {
+	u8 *out_ptr;
+	u8 *out_usr_ptr;
+	u32 out_size;
+	struct list_head link;
+};
+
+/* Status of a char device */
+enum mu_device_status_t {
+	MU_FREE,
+	MU_OPENED
+};
+
+struct ele_shared_mem {
+	dma_addr_t dma_addr;
+	u32 size;
+	u32 pos;
+	u8 *ptr;
+};
+
+/* Private struct for each char device instance. */
+struct ele_mu_device_ctx {
+	struct device *dev;
+	struct ele_mu_priv *priv;
+	struct miscdevice miscdev;
+
+	enum mu_device_status_t status;
+	wait_queue_head_t wq;
+	struct semaphore fops_lock;
+
+	u32 pending_hdr;
+	struct list_head pending_out;
+
+	struct ele_shared_mem secure_mem;
+	struct ele_shared_mem non_secure_mem;
+
+	u32 temp_cmd[MAX_MESSAGE_SIZE];
+	u32 temp_resp[MAX_RECV_SIZE];
+	u32 temp_resp_size;
+	struct notifier_block ele_notify;
+};
+
+/* Header of the messages exchange with the EdgeLock Enclave */
+struct mu_hdr {
+	u8 ver;
+	u8 size;
+	u8 command;
+	u8 tag;
+}  __packed;
+
+struct ele_api_msg {
+	u32 header; /* u8 Tag; u8 Command; u8 Size; u8 Ver; */
+	u32 data[ELE_MSG_DATA_NUM];
+};
+
+struct ele_mu_priv {
+	struct ele_mu_device_ctx *cmd_receiver_dev;
+	struct ele_mu_device_ctx *waiting_rsp_dev;
+	/*
+	 * prevent parallel access to the MU registers
+	 * e.g. a user trying to send a command while the other one is
+	 * sending a response.
+	 */
+	struct mutex mu_lock;
+	/*
+	 * prevent a command to be sent on the MU while another one is still
+	 * processing. (response to a command is allowed)
+	 */
+	struct mutex mu_cmd_lock;
+	struct device *dev;
+	u32 ele_mu_id;
+	u8 cmd_tag;
+	u8 rsp_tag;
+
+	struct mbox_client ele_mb_cl;
+	struct mbox_chan *tx_chan, *rx_chan;
+	struct ele_api_msg tx_msg, rx_msg;
+	struct completion done;
+	spinlock_t lock;
+};
+
+int get_ele_mu_priv(struct ele_mu_priv **export);
+#endif
diff --git a/drivers/firmware/imx/imx-scu-irq.c b/drivers/firmware/imx/imx-scu-irq.c
index d9dcc2094..6ce53c1ff 100644
--- a/drivers/firmware/imx/imx-scu-irq.c
+++ b/drivers/firmware/imx/imx-scu-irq.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0+
 /*
- * Copyright 2019 NXP
+ * Copyright 2019-2020 NXP
  *
  * Implementation of the SCU IRQ functions using MU.
  *
@@ -11,10 +11,11 @@
 #include <linux/firmware/imx/sci.h>
 #include <linux/mailbox_client.h>
 #include <linux/suspend.h>
+#include <linux/sysfs.h>
+#include <linux/kobject.h>
 
 #define IMX_SC_IRQ_FUNC_ENABLE	1
 #define IMX_SC_IRQ_FUNC_STATUS	2
-#define IMX_SC_IRQ_NUM_GROUP	4
 
 static u32 mu_resource_id;
 
@@ -40,63 +41,100 @@ struct imx_sc_msg_irq_enable {
 	u8 enable;
 } __packed;
 
+struct scu_wakeup {
+	u32 mask;
+	u32 wakeup_src;
+	bool valid;
+};
+
+/* Sysfs functions */
+struct kobject *wakeup_obj;
+static ssize_t wakeup_source_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf);
+static struct kobj_attribute wakeup_source_attr = __ATTR(wakeup_src, 0660, wakeup_source_show, NULL);
+
+static struct scu_wakeup scu_irq_wakeup[IMX_SC_IRQ_NUM_GROUP];
+
+
 static struct imx_sc_ipc *imx_sc_irq_ipc_handle;
 static struct work_struct imx_sc_irq_work;
-static ATOMIC_NOTIFIER_HEAD(imx_scu_irq_notifier_chain);
+static BLOCKING_NOTIFIER_HEAD(imx_scu_irq_notifier_chain);
 
 int imx_scu_irq_register_notifier(struct notifier_block *nb)
 {
-	return atomic_notifier_chain_register(
+	return blocking_notifier_chain_register(
 		&imx_scu_irq_notifier_chain, nb);
 }
 EXPORT_SYMBOL(imx_scu_irq_register_notifier);
 
 int imx_scu_irq_unregister_notifier(struct notifier_block *nb)
 {
-	return atomic_notifier_chain_unregister(
+	return blocking_notifier_chain_unregister(
 		&imx_scu_irq_notifier_chain, nb);
 }
 EXPORT_SYMBOL(imx_scu_irq_unregister_notifier);
 
 static int imx_scu_irq_notifier_call_chain(unsigned long status, u8 *group)
 {
-	return atomic_notifier_call_chain(&imx_scu_irq_notifier_chain,
+	return blocking_notifier_call_chain(&imx_scu_irq_notifier_chain,
 		status, (void *)group);
 }
 
 static void imx_scu_irq_work_handler(struct work_struct *work)
 {
-	struct imx_sc_msg_irq_get_status msg;
-	struct imx_sc_rpc_msg *hdr = &msg.hdr;
 	u32 irq_status;
 	int ret;
 	u8 i;
 
 	for (i = 0; i < IMX_SC_IRQ_NUM_GROUP; i++) {
-		hdr->ver = IMX_SC_RPC_VERSION;
-		hdr->svc = IMX_SC_RPC_SVC_IRQ;
-		hdr->func = IMX_SC_IRQ_FUNC_STATUS;
-		hdr->size = 2;
-
-		msg.data.req.resource = mu_resource_id;
-		msg.data.req.group = i;
-
-		ret = imx_scu_call_rpc(imx_sc_irq_ipc_handle, &msg, true);
+		if (scu_irq_wakeup[i].mask) {
+			scu_irq_wakeup[i].valid = false;
+			scu_irq_wakeup[i].wakeup_src = 0;
+		}
+		ret = imx_scu_irq_get_status(i, &irq_status);
 		if (ret) {
 			pr_err("get irq group %d status failed, ret %d\n",
 			       i, ret);
 			return;
 		}
 
-		irq_status = msg.data.resp.status;
 		if (!irq_status)
 			continue;
-
+		if (scu_irq_wakeup[i].mask & irq_status) {
+			scu_irq_wakeup[i].valid = true;
+			scu_irq_wakeup[i].wakeup_src = irq_status & scu_irq_wakeup[i].mask;
+		} else {
+			scu_irq_wakeup[i].wakeup_src = irq_status;
+		}
 		pm_system_wakeup();
 		imx_scu_irq_notifier_call_chain(irq_status, &i);
 	}
 }
 
+int imx_scu_irq_get_status(u8 group, u32 *irq_status)
+{
+	struct imx_sc_msg_irq_get_status msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_IRQ;
+	hdr->func = IMX_SC_IRQ_FUNC_STATUS;
+	hdr->size = 2;
+
+	msg.data.req.resource = mu_resource_id;
+	msg.data.req.group = group;
+
+	ret = imx_scu_call_rpc(imx_sc_irq_ipc_handle, &msg, true);
+	if (ret)
+		return ret;
+
+	if (irq_status)
+		*irq_status = msg.data.resp.status;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_scu_irq_get_status);
+
 int imx_scu_irq_group_enable(u8 group, u32 mask, u8 enable)
 {
 	struct imx_sc_msg_irq_enable msg;
@@ -121,6 +159,11 @@ int imx_scu_irq_group_enable(u8 group, u32 mask, u8 enable)
 		pr_err("enable irq failed, group %d, mask %d, ret %d\n",
 			group, mask, ret);
 
+	if (enable)
+		scu_irq_wakeup[group].mask |= mask;
+	else
+		scu_irq_wakeup[group].mask &= ~mask;
+
 	return ret;
 }
 EXPORT_SYMBOL(imx_scu_irq_group_enable);
@@ -130,6 +173,24 @@ static void imx_scu_irq_callback(struct mbox_client *c, void *msg)
 	schedule_work(&imx_sc_irq_work);
 }
 
+static ssize_t wakeup_source_show(struct kobject *kobj,
+					struct kobj_attribute *attr, char *buf)
+{
+	u8 i = 0, size = 0;
+
+	for (i = 0; i < IMX_SC_IRQ_NUM_GROUP; i++) {
+		if (scu_irq_wakeup[i].wakeup_src != 0) {
+			if (scu_irq_wakeup[i].valid)
+				size += sprintf(buf + size, "Wakeup source group = %d, irq = 0x%x\n",
+							i, scu_irq_wakeup[i].wakeup_src);
+			else
+				size += sprintf(buf + size, "Spurious SCU wakeup, group = %d, irq = 0x%x\n",
+							i, scu_irq_wakeup[i].wakeup_src);
+		}
+	}
+	return strlen(buf);
+}
+
 int imx_scu_enable_general_irq_channel(struct device *dev)
 {
 	struct of_phandle_args spec;
@@ -169,6 +230,15 @@ int imx_scu_enable_general_irq_channel(struct device *dev)
 
 	mu_resource_id = IMX_SC_R_MU_0A + i;
 
+	/* Create directory under /sysfs/firmware */
+	wakeup_obj = kobject_create_and_add("scu_wakeup_source", firmware_kobj);
+
+	if (sysfs_create_file(wakeup_obj, &wakeup_source_attr.attr)) {
+		pr_err("Cannot create sysfs file......\n");
+		kobject_put(wakeup_obj);
+		sysfs_remove_file(firmware_kobj, &wakeup_source_attr.attr);
+	}
+
 	return ret;
 }
 EXPORT_SYMBOL(imx_scu_enable_general_irq_channel);
diff --git a/drivers/firmware/imx/imx-scu-soc.c b/drivers/firmware/imx/imx-scu-soc.c
index 2f32353de..c8d14315d 100644
--- a/drivers/firmware/imx/imx-scu-soc.c
+++ b/drivers/firmware/imx/imx-scu-soc.c
@@ -12,6 +12,8 @@
 
 static struct imx_sc_ipc *imx_sc_soc_ipc_handle;
 
+extern bool TKT340553_SW_WORKAROUND;
+
 struct imx_sc_msg_misc_get_soc_id {
 	struct imx_sc_rpc_msg hdr;
 	union {
@@ -35,18 +37,15 @@ static int imx_scu_soc_uid(u64 *soc_uid)
 {
 	struct imx_sc_msg_misc_get_soc_uid msg;
 	struct imx_sc_rpc_msg *hdr = &msg.hdr;
-	int ret;
+
+	memset(&msg, 0, sizeof(msg));
 
 	hdr->ver = IMX_SC_RPC_VERSION;
 	hdr->svc = IMX_SC_RPC_SVC_MISC;
 	hdr->func = IMX_SC_MISC_FUNC_UNIQUE_ID;
 	hdr->size = 1;
 
-	ret = imx_scu_call_rpc(imx_sc_soc_ipc_handle, &msg, true);
-	if (ret) {
-		pr_err("%s: get soc uid failed, ret %d\n", __func__, ret);
-		return ret;
-	}
+	imx_scu_call_rpc(imx_sc_soc_ipc_handle, &msg, true);
 
 	*soc_uid = msg.uid_high;
 	*soc_uid <<= 32;
@@ -113,9 +112,13 @@ int imx_scu_soc_init(struct device *dev)
 
 	/* format soc_id value passed from SCU firmware */
 	val = id & 0x1f;
-	soc_dev_attr->soc_id = devm_kasprintf(dev, GFP_KERNEL, "0x%x", val);
-	if (!soc_dev_attr->soc_id)
-		return -ENOMEM;
+	if (of_machine_is_compatible("fsl,imx8qm")) {
+		soc_dev_attr->soc_id = "i.MX8QM";
+		TKT340553_SW_WORKAROUND = true;
+	} else if (of_machine_is_compatible("fsl,imx8qxp"))
+		soc_dev_attr->soc_id = "i.MX8QXP";
+	else if (of_machine_is_compatible("fsl,imx8dxl"))
+		soc_dev_attr->soc_id = "i.MX8DXL";
 
 	/* format revision value passed from SCU firmware */
 	val = (id >> 5) & 0xf;
diff --git a/drivers/firmware/imx/imx-scu.c b/drivers/firmware/imx/imx-scu.c
index dca79cacc..fd6de5771 100644
--- a/drivers/firmware/imx/imx-scu.c
+++ b/drivers/firmware/imx/imx-scu.c
@@ -7,6 +7,7 @@
  *
  */
 
+#include <linux/arm-smccc.h>
 #include <linux/err.h>
 #include <linux/firmware/imx/ipc.h>
 #include <linux/firmware/imx/sci.h>
@@ -19,8 +20,11 @@
 #include <linux/of_platform.h>
 #include <linux/platform_device.h>
 
+#include <xen/xen.h>
+
+#define FSL_HVC_SC                      0xC6000000
 #define SCU_MU_CHAN_NUM		8
-#define MAX_RX_TIMEOUT		(msecs_to_jiffies(30))
+#define MAX_RX_TIMEOUT		(msecs_to_jiffies(3000))
 
 struct imx_sc_chan {
 	struct imx_sc_ipc *sc_ipc;
@@ -204,6 +208,7 @@ int imx_scu_call_rpc(struct imx_sc_ipc *sc_ipc, void *msg, bool have_resp)
 {
 	uint8_t saved_svc, saved_func;
 	struct imx_sc_rpc_msg *hdr;
+	struct arm_smccc_res res;
 	int ret;
 
 	if (WARN_ON(!sc_ipc || !msg))
@@ -218,33 +223,45 @@ int imx_scu_call_rpc(struct imx_sc_ipc *sc_ipc, void *msg, bool have_resp)
 		saved_func = ((struct imx_sc_rpc_msg *)msg)->func;
 	}
 	sc_ipc->count = 0;
-	ret = imx_scu_ipc_write(sc_ipc, msg);
-	if (ret < 0) {
-		dev_err(sc_ipc->dev, "RPC send msg failed: %d\n", ret);
-		goto out;
-	}
-
-	if (have_resp) {
-		if (!wait_for_completion_timeout(&sc_ipc->done,
-						 MAX_RX_TIMEOUT)) {
-			dev_err(sc_ipc->dev, "RPC send msg timeout\n");
-			mutex_unlock(&sc_ipc->lock);
-			return -ETIMEDOUT;
+	sc_ipc->rx_size = 0;
+	if (xen_initial_domain()) {
+		arm_smccc_hvc(FSL_HVC_SC, (uint64_t)msg, !have_resp, 0, 0, 0,
+			      0, 0, &res);
+		if (res.a0)
+			printk("Error FSL_HVC_SC %ld\n", res.a0);
+
+		ret = res.a0;
+
+	} else {
+		ret = imx_scu_ipc_write(sc_ipc, msg);
+		if (ret < 0) {
+			dev_err(sc_ipc->dev, "RPC send msg failed: %d\n", ret);
+			goto out;
 		}
 
-		/* response status is stored in hdr->func field */
-		hdr = msg;
-		ret = hdr->func;
-		/*
-		 * Some special SCU firmware APIs do NOT have return value
-		 * in hdr->func, but they do have response data, those special
-		 * APIs are defined as void function in SCU firmware, so they
-		 * should be treated as return success always.
-		 */
-		if ((saved_svc == IMX_SC_RPC_SVC_MISC) &&
-			(saved_func == IMX_SC_MISC_FUNC_UNIQUE_ID ||
-			 saved_func == IMX_SC_MISC_FUNC_GET_BUTTON_STATUS))
-			ret = 0;
+		if (have_resp) {
+			if (!wait_for_completion_timeout(&sc_ipc->done,
+							 MAX_RX_TIMEOUT)) {
+				dev_err(sc_ipc->dev, "RPC send msg timeout\n");
+				mutex_unlock(&sc_ipc->lock);
+				return -ETIMEDOUT;
+			}
+
+			/* response status is stored in hdr->func field */
+			hdr = msg;
+			ret = hdr->func;
+
+			/*
+			 * Some special SCU firmware APIs do NOT have return value
+			 * in hdr->func, but they do have response data, those special
+			 * APIs are defined as void function in SCU firmware, so they
+			 * should be treated as return success always.
+			 */
+			if ((saved_svc == IMX_SC_RPC_SVC_MISC) &&
+				(saved_func == IMX_SC_MISC_FUNC_UNIQUE_ID ||
+				 saved_func == IMX_SC_MISC_FUNC_GET_BUTTON_STATUS))
+				ret = 0;
+		}
 	}
 
 out:
@@ -354,7 +371,12 @@ static struct platform_driver imx_scu_driver = {
 	},
 	.probe = imx_scu_probe,
 };
-builtin_platform_driver(imx_scu_driver);
+
+static int __init imx_scu_driver_init(void)
+{
+	return platform_driver_register(&imx_scu_driver);
+}
+subsys_initcall_sync(imx_scu_driver_init);
 
 MODULE_AUTHOR("Dong Aisheng <aisheng.dong@nxp.com>");
 MODULE_DESCRIPTION("IMX SCU firmware protocol driver");
diff --git a/drivers/firmware/imx/misc.c b/drivers/firmware/imx/misc.c
index d073cb3ce..01878451d 100644
--- a/drivers/firmware/imx/misc.c
+++ b/drivers/firmware/imx/misc.c
@@ -18,6 +18,13 @@ struct imx_sc_msg_req_misc_set_ctrl {
 	u16 resource;
 } __packed __aligned(4);
 
+
+struct imx_sc_msg_req_misc_set_dma_group {
+	struct imx_sc_rpc_msg hdr;
+	u16 resource;
+	u8 val;
+} __packed __aligned(4);
+
 struct imx_sc_msg_req_cpu_start {
 	struct imx_sc_rpc_msg hdr;
 	u32 address_hi;
@@ -67,6 +74,24 @@ int imx_sc_misc_set_control(struct imx_sc_ipc *ipc, u32 resource,
 }
 EXPORT_SYMBOL(imx_sc_misc_set_control);
 
+int imx_sc_misc_set_dma_group(struct imx_sc_ipc *ipc, u32 resource,
+			    u32 val)
+{
+	struct imx_sc_msg_req_misc_set_dma_group msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_MISC;
+	hdr->func = (uint8_t)IMX_SC_MISC_FUNC_SET_DMA_GROUP;
+	hdr->size = 2;
+
+	msg.val = val;
+	msg.resource = resource;
+
+	return imx_scu_call_rpc(ipc, &msg, true);
+}
+EXPORT_SYMBOL(imx_sc_misc_set_dma_group);
+
 /*
  * This function gets a miscellaneous control value.
  *
diff --git a/drivers/firmware/imx/rm.c b/drivers/firmware/imx/rm.c
index a12db6ff3..6dd4db386 100644
--- a/drivers/firmware/imx/rm.c
+++ b/drivers/firmware/imx/rm.c
@@ -13,6 +13,11 @@ struct imx_sc_msg_rm_rsrc_owned {
 	u16 resource;
 } __packed __aligned(4);
 
+struct imx_sc_msg_rm_pt {
+	struct imx_sc_rpc_msg hdr;
+	u8 val;
+} __packed __aligned(4);
+
 /*
  * This function check @resource is owned by current partition or not
  *
@@ -43,3 +48,160 @@ bool imx_sc_rm_is_resource_owned(struct imx_sc_ipc *ipc, u16 resource)
 	return hdr->func;
 }
 EXPORT_SYMBOL(imx_sc_rm_is_resource_owned);
+
+/*
+ * This function returns the current partition number
+ *
+ * @param[in]     ipc         IPC handle
+ * @param[out]    pt          holding the partition number
+ *
+ * @return Returns 0 for success and < 0 for errors.
+ */
+int imx_sc_rm_get_partition(struct imx_sc_ipc *ipc, u8 *pt)
+{
+	struct imx_sc_msg_rm_pt msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_PARTITION;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (pt != NULL)
+		*pt = msg.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_partition);
+
+struct imx_sc_msg_rm_find_memreg {
+	struct imx_sc_rpc_msg hdr;
+	union {
+		struct {
+			u32 add_start_hi;
+			u32 add_start_lo;
+			u32 add_end_hi;
+			u32 add_end_lo;
+		} req;
+		struct {
+			u8 val;
+		} resp;
+	} data;
+}  __packed __aligned(4);
+
+int imx_sc_rm_find_memreg(struct imx_sc_ipc *ipc, u8 *mr, u64 addr_start,
+			  u64 addr_end)
+{
+	struct imx_sc_msg_rm_find_memreg msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_FIND_MEMREG;
+	hdr->size = 5;
+
+	msg.data.req.add_start_hi = addr_start >> 32;
+	msg.data.req.add_start_lo = addr_start;
+	msg.data.req.add_end_hi = addr_end >> 32;
+	msg.data.req.add_end_lo = addr_end;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (mr)
+		*mr = msg.data.resp.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_find_memreg);
+
+struct imx_sc_msg_rm_get_resource_owner {
+	struct imx_sc_rpc_msg hdr;
+	union {
+		struct {
+			u16 resource;
+		} req;
+		struct {
+			u8 val;
+		} resp;
+	} data;
+} __packed __aligned(4);
+
+int imx_sc_rm_get_resource_owner(struct imx_sc_ipc *ipc, u16 resource, u8 *pt)
+{
+	struct imx_sc_msg_rm_get_resource_owner msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_RESOURCE_OWNER;
+	hdr->size = 2;
+
+	msg.data.req.resource = resource;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	if (pt)
+		*pt = msg.data.resp.val;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_resource_owner);
+
+struct imx_sc_msg_set_memreg_permissions {
+	struct imx_sc_rpc_msg hdr;
+	u8 mr;
+	u8 pt;
+	u8 perm;
+} __packed __aligned(4);
+
+int imx_sc_rm_set_memreg_permissions(struct imx_sc_ipc *ipc, u8 mr,
+				     u8 pt, u8 perm)
+{
+	struct imx_sc_msg_set_memreg_permissions msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_SET_MEMREG_PERMISSIONS;
+	hdr->size = 2;
+
+	msg.mr = mr;
+	msg.pt = pt;
+	msg.perm = perm;
+
+	return imx_scu_call_rpc(ipc, &msg, true);
+}
+EXPORT_SYMBOL(imx_sc_rm_set_memreg_permissions);
+
+int imx_sc_rm_get_did(struct imx_sc_ipc *ipc, u8 *did)
+{
+	struct imx_sc_rpc_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_RM;
+	hdr->func = IMX_SC_RM_FUNC_GET_DID;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret < 0)
+		return ret;
+
+	if (did)
+		*did = msg.func;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_rm_get_did);
diff --git a/drivers/firmware/imx/seco.c b/drivers/firmware/imx/seco.c
new file mode 100644
index 000000000..18232c700
--- /dev/null
+++ b/drivers/firmware/imx/seco.c
@@ -0,0 +1,249 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2020 NXP
+ *
+ * File containing client-side RPC functions for the SECO service. These
+ * function are ported to clients that communicate to the SC.
+ */
+
+#include <linux/firmware/imx/sci.h>
+
+struct imx_sc_msg_seco_get_build_id {
+	struct imx_sc_rpc_msg hdr;
+	u32 version;
+	u32 commit;
+} __packed __aligned(4);
+
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit)
+{
+	struct imx_sc_msg_seco_get_build_id msg = {0};
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_SECO;
+	hdr->func = IMX_SC_SECO_FUNC_BUILD_INFO;
+	hdr->size = 1;
+
+	imx_scu_call_rpc(ipc, &msg, true);
+
+	if (version)
+		*version = msg.version;
+	if (commit)
+		*commit = msg.commit;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_build_info);
+
+struct imx_sc_msg_seco_sab_msg {
+	struct imx_sc_rpc_msg hdr;
+	u32 smsg_addr_hi;
+	u32 smsg_addr_lo;
+} __packed __aligned(4);
+
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr)
+{
+	struct imx_sc_msg_seco_sab_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = IMX_SC_RPC_SVC_SECO;
+	hdr->func = IMX_SC_SECO_FUNC_SAB_MSG;
+	hdr->size = 3;
+
+	msg.smsg_addr_hi = smsg_addr >> 32;
+	msg.smsg_addr_lo = smsg_addr;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	return ret;
+}
+EXPORT_SYMBOL(imx_sc_seco_sab_msg);
+
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc)
+{
+	struct imx_sc_rpc_msg msg;
+	struct imx_sc_rpc_msg *hdr = &msg;
+	int ret;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_ENABLE;
+	hdr->size = 1;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_enable);
+
+struct imx_sc_msg_req_seco_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data0;
+	u32 data1;
+	u32 data2;
+	u32 data3;
+	u32 data4;
+	u8 id;
+	u8 access;
+	u8 size;
+} __packed __aligned(4);
+
+struct imx_sc_msg_resp_seco_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data0;
+	u32 data1;
+	u32 data2;
+	u32 data3;
+	u32 data4;
+} __packed __aligned(4);
+
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size)
+{
+	struct imx_sc_msg_req_seco_config msg;
+	struct imx_sc_msg_resp_seco_config *resp;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	if (!ipc)
+		return -EINVAL;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_CONFIG;
+	hdr->size = 7;
+
+	/* Check the pointers on data are valid and set it if doing a write */
+	switch (size) {
+	case 5:
+		if (data4) {
+			if (access)
+				msg.data4 = *data4;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 4:
+		if (data3) {
+			if (access)
+				msg.data3 = *data3;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 3:
+		if (data2) {
+			if (access)
+				msg.data2 = *data2;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 2:
+		if (data1) {
+			if (access)
+				msg.data1 = *data1;
+		} else {
+			return -EINVAL;
+		}
+		fallthrough;
+	case 1:
+		if (data0) {
+			if (access)
+				msg.data0 = *data0;
+		} else {
+			return -EINVAL;
+		}
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	msg.id = id;
+	msg.access = access;
+	msg.size = size;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	resp = (struct imx_sc_msg_resp_seco_config *)&msg;
+
+	/* Pointers already checked so we just copy the data if reading */
+	if (!access)
+		switch (size) {
+		case 5:
+			*data4 = resp->data4;
+		fallthrough;
+		case 4:
+			*data3 = resp->data3;
+		fallthrough;
+		case 3:
+			*data2 = resp->data2;
+		fallthrough;
+		case 2:
+			*data1 = resp->data1;
+		fallthrough;
+		case 1:
+			*data0 = resp->data0;
+		}
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_config);
+
+struct imx_sc_msg_req_seco_dgo_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data;
+	u8 id;
+	u8 access;
+} __packed __aligned(4);
+
+struct imx_sc_msg_resp_seco_dgo_config {
+	struct imx_sc_rpc_msg hdr;
+	u32 data;
+} __packed __aligned(4);
+
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data)
+{
+	struct imx_sc_msg_req_seco_dgo_config msg;
+	struct imx_sc_msg_resp_seco_dgo_config *resp;
+	struct imx_sc_rpc_msg *hdr = &msg.hdr;
+	int ret;
+
+	if (!ipc)
+		return -EINVAL;
+
+	hdr->ver = IMX_SC_RPC_VERSION;
+	hdr->svc = (uint8_t)IMX_SC_RPC_SVC_SECO;
+	hdr->func = (uint8_t)IMX_SC_SECO_FUNC_SECVIO_DGO_CONFIG;
+	hdr->size = 3;
+
+	if (access) {
+		if (data)
+			msg.data = *data;
+		else
+			return -EINVAL;
+	}
+
+	msg.access = access;
+	msg.id = id;
+
+	ret = imx_scu_call_rpc(ipc, &msg, true);
+	if (ret)
+		return ret;
+
+	resp = (struct imx_sc_msg_resp_seco_dgo_config *)&msg;
+
+	if (!access && data)
+		*data = resp->data;
+
+	return 0;
+}
+EXPORT_SYMBOL(imx_sc_seco_secvio_dgo_config);
diff --git a/drivers/firmware/imx/seco_mu.c b/drivers/firmware/imx/seco_mu.c
new file mode 100644
index 000000000..02f4295f8
--- /dev/null
+++ b/drivers/firmware/imx/seco_mu.c
@@ -0,0 +1,1210 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright 2019-2020 NXP
+ */
+
+/*
+ * This driver allows to send messages to the SECO using a shared mailbox. The
+ * messages must follow the protocol defined.
+ */
+
+/*
+ * Architecture of the driver:
+ *
+ *                                     Non-Secure           +   Secure
+ *                                                          |
+ *                                                          |
+ *                   +---------+      +-------------+       |
+ *                   |seco_mu.c+<---->+imx-mailbox.c|       |
+ *                   |         |      |  mailbox.c  +<-->+------+    +------+
+ *                   +---+-----+      +-------------+    | MU X +<-->+ SECO |
+ *                       |                               +------+    +------+
+ *                       +----------------+                 |
+ *                       |                |                 |
+ *                       v                v                 |
+ *                   logical           logical              |
+ *                   receiver          waiter               |
+ *                      +                 +                 |
+ *                      |                 |                 |
+ *                      |                 |                 |
+ *                      |            +----+------+          |
+ *                      |            |           |          |
+ *                      |            |           |          |
+ *               device_ctx     device_ctx     device_ctx   |
+ *                                                          |
+ *                 User 0        User 1       User Y        |
+ *                 +------+      +------+     +------+      |
+ *                 |misc.c|      |misc.c|     |misc.c|      |
+ * kernel space    +------+      +------+     +------+      |
+ *                                                          |
+ *  +------------------------------------------------------ |
+ *                     |             |           |          |
+ * userspace     /dev/seco_muXch0    |           |          |
+ *                          /dev/seco_muXch1     |          |
+ *                                        /dev/seco_muXchY  |
+ *                                                          |
+ *
+ * When a user sends a command to the seco, it registers its device_ctx as
+ * waiter of a response from SECO
+ *
+ * A user can be registered as receiver of command by the SECO.
+ *
+ * When a message is received, the driver select the device_ctx receiving the
+ * message depending on the tag in the message. It selects the device_ctx
+ * accordingly.
+ */
+
+#include <linux/dma-mapping.h>
+#include <linux/interrupt.h>
+#include <linux/miscdevice.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/uaccess.h>
+#include <linux/firmware/imx/sci.h>
+#include <dt-bindings/firmware/imx/rsrc.h>
+#include <linux/firmware/imx/seco_mu_ioctl.h>
+#include <linux/mailbox_client.h>
+
+#define MAX_RECV_SIZE 31
+#define MAX_RECV_SIZE_BYTES (MAX_RECV_SIZE * sizeof(u32))
+#define MAX_MESSAGE_SIZE 31
+#define MAX_MESSAGE_SIZE_BYTES (MAX_MESSAGE_SIZE * sizeof(u32))
+#define MESSAGE_SIZE(hdr) (((struct she_mu_hdr *)(&(hdr)))->size)
+#define MESSAGE_TAG(hdr) (((struct she_mu_hdr *)(&(hdr)))->tag)
+
+#define DEFAULT_MESSAGING_TAG_COMMAND           (0x17u)
+#define DEFAULT_MESSAGING_TAG_RESPONSE          (0xe1u)
+
+#define SECURE_RAM_BASE_ADDRESS	(0x31800000ULL)
+#define SECURE_RAM_BASE_ADDRESS_SCU	(0x20800000u)
+#define SECURE_RAM_SIZE	(0x10000ULL)
+
+#define SECO_MU_DEFAULT_MAX_USERS 4
+
+#define SECO_MU_INTERRUPT_INDEX	(0u)
+#define SECO_DEFAULT_MU_INDEX	(1u)
+#define SECO_DEFAULT_TZ		(0u)
+#define DEFAULT_DID		(0u)
+
+#define MAX_DATA_SIZE_PER_USER  (65 * 1024)
+
+/* Header of the messages exchange with the SECO */
+struct she_mu_hdr {
+	u8 ver;
+	u8 size;
+	u8 command;
+	u8 tag;
+}  __packed;
+
+/* Status of a char device */
+enum mu_device_status_t {
+	MU_FREE,
+	MU_OPENED
+};
+
+struct seco_shared_mem {
+	dma_addr_t dma_addr;
+	u32 size;
+	u32 pos;
+	u8 *ptr;
+};
+
+struct seco_out_buffer_desc {
+	u8 *out_ptr;
+	u8 *out_usr_ptr;
+	u32 out_size;
+	struct list_head link;
+};
+
+/* Private struct for each char device instance. */
+struct seco_mu_device_ctx {
+	struct device *dev;
+	struct seco_mu_priv *mu_priv;
+	struct miscdevice miscdev;
+
+	enum mu_device_status_t status;
+	wait_queue_head_t wq;
+	struct semaphore fops_lock;
+
+	u32 pending_hdr;
+	struct list_head pending_out;
+
+	struct seco_shared_mem secure_mem;
+	struct seco_shared_mem non_secure_mem;
+
+	u32 temp_cmd[MAX_MESSAGE_SIZE];
+	u32 temp_resp[MAX_RECV_SIZE];
+	u32 temp_resp_size;
+	struct notifier_block scu_notify;
+	bool v2x_reset;
+};
+
+/* Private struct for seco MU driver. */
+struct seco_mu_priv {
+	struct seco_mu_device_ctx *cmd_receiver_dev;
+	struct seco_mu_device_ctx *waiting_rsp_dev;
+	/*
+	 * prevent parallel access to the MU registers
+	 * e.g. a user trying to send a command while the other one is
+	 * sending a response.
+	 */
+	struct mutex mu_lock;
+	/*
+	 * prevent a command to be sent on the MU while another one is still
+	 * processing. (response to a command is allowed)
+	 */
+	struct mutex mu_cmd_lock;
+	struct device *dev;
+	u32 seco_mu_id;
+	u8 cmd_tag;
+	u8 rsp_tag;
+
+	struct mbox_client cl;
+	struct mbox_chan *tx_chan;
+	struct mbox_chan *rx_chan;
+
+	struct imx_sc_ipc *ipc_scu;
+	u8 seco_part_owner;
+};
+
+/* macro to log operation of a misc device */
+#define miscdev_dbg(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_dbg((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+#define miscdev_info(p_miscdev, fmt, va_args...)                               \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_info((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name, \
+		##va_args);                                                    \
+	})
+
+#define miscdev_err(p_miscdev, fmt, va_args...)                                \
+	({                                                                     \
+		struct miscdevice *_p_miscdev = p_miscdev;                     \
+		dev_err((_p_miscdev)->parent, "%s: " fmt, (_p_miscdev)->name,  \
+		##va_args);                                                    \
+	})
+
+/* macro to log operation of a device context */
+#define devctx_dbg(p_devctx, fmt, va_args...) \
+	miscdev_dbg(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_info(p_devctx, fmt, va_args...) \
+	miscdev_info(&((p_devctx)->miscdev), fmt, ##va_args)
+#define devctx_err(p_devctx, fmt, va_args...) \
+	miscdev_err((&(p_devctx)->miscdev), fmt, ##va_args)
+
+#define IMX_SC_RM_PERM_FULL         7U	/* Full access */
+
+/* Give access to SECU to the memory we want to share */
+static int seco_mu_setup_seco_memory_access(struct seco_mu_device_ctx *dev_ctx,
+					    u64 addr, u32 len)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	int ret;
+	u8 mr;
+
+	ret = imx_sc_rm_find_memreg(priv->ipc_scu, &mr, addr, addr + len);
+	if (ret) {
+		devctx_err(dev_ctx, "Fail find memreg\n");
+		goto exit;
+	}
+
+	ret = imx_sc_rm_set_memreg_permissions(priv->ipc_scu, mr,
+					       priv->seco_part_owner,
+					       IMX_SC_RM_PERM_FULL);
+	if (ret) {
+		devctx_err(dev_ctx, "Fail set permission for resource\n");
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+/*
+ * File operations for user-space
+ */
+/* Open a char device. */
+static int seco_mu_fops_open(struct inode *nd, struct file *fp)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	int err;
+
+	/* Avoid race if opened at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* Authorize only 1 instance. */
+	if (dev_ctx->status != MU_FREE) {
+		err = -EBUSY;
+		goto exit;
+	}
+
+	/*
+	 * Allocate some memory for data exchanges with SECO.
+	 * This will be used for data not requiring secure memory.
+	 */
+	dev_ctx->non_secure_mem.ptr = dmam_alloc_coherent(dev_ctx->dev,
+					MAX_DATA_SIZE_PER_USER,
+					&dev_ctx->non_secure_mem.dma_addr,
+					GFP_KERNEL);
+	if (!dev_ctx->non_secure_mem.ptr) {
+		err = -ENOMEM;
+		devctx_err(dev_ctx, "Failed to map shared memory with SECO\n");
+		goto exit;
+	}
+
+	err = seco_mu_setup_seco_memory_access(dev_ctx,
+					       dev_ctx->non_secure_mem.dma_addr,
+					       MAX_DATA_SIZE_PER_USER);
+	if (err) {
+		err = -EPERM;
+		devctx_err(dev_ctx,
+			   "Failed to share access to shared memory\n");
+		goto free_coherent;
+	}
+
+	dev_ctx->non_secure_mem.size = MAX_DATA_SIZE_PER_USER;
+	dev_ctx->non_secure_mem.pos = 0;
+	dev_ctx->status = MU_OPENED;
+
+	dev_ctx->pending_hdr = 0;
+	dev_ctx->v2x_reset = 0;
+
+	goto exit;
+
+free_coherent:
+	dmam_free_coherent(dev_ctx->mu_priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Close a char device. */
+static int seco_mu_fops_close(struct inode *nd, struct file *fp)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	struct seco_out_buffer_desc *out_buf_desc;
+
+	/* Avoid race if closed at the same time */
+	if (down_trylock(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	/* The device context has not been opened */
+	if (dev_ctx->status != MU_OPENED)
+		goto exit;
+
+	/* check if this device was registered as command receiver. */
+	if (mu_priv->cmd_receiver_dev == dev_ctx)
+		mu_priv->cmd_receiver_dev = NULL;
+
+	/* check if this device was registered as waiting response. */
+	if (mu_priv->waiting_rsp_dev == dev_ctx) {
+		mu_priv->waiting_rsp_dev = NULL;
+		mutex_unlock(&mu_priv->mu_cmd_lock);
+	}
+
+	/* Unmap secure memory shared buffer. */
+	if (dev_ctx->secure_mem.ptr)
+		devm_iounmap(dev_ctx->dev, dev_ctx->secure_mem.ptr);
+
+	dev_ctx->secure_mem.ptr = NULL;
+	dev_ctx->secure_mem.dma_addr = 0;
+	dev_ctx->secure_mem.size = 0;
+	dev_ctx->secure_mem.pos = 0;
+
+	/* Free non-secure shared buffer. */
+	dmam_free_coherent(dev_ctx->mu_priv->dev, MAX_DATA_SIZE_PER_USER,
+			   dev_ctx->non_secure_mem.ptr,
+			   dev_ctx->non_secure_mem.dma_addr);
+
+	dev_ctx->non_secure_mem.ptr = NULL;
+	dev_ctx->non_secure_mem.dma_addr = 0;
+	dev_ctx->non_secure_mem.size = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	while (!list_empty(&dev_ctx->pending_out)) {
+		out_buf_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						struct seco_out_buffer_desc,
+						link);
+		__list_del_entry(&out_buf_desc->link);
+		devm_kfree(dev_ctx->dev, out_buf_desc);
+	}
+
+	dev_ctx->status = MU_FREE;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return 0;
+}
+
+/* Write a message to the MU. */
+static ssize_t seco_mu_fops_write(struct file *fp, const char __user *buf,
+				  size_t size, loff_t *ppos)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	u32 nb_words = 0, header;
+	int err;
+
+	devctx_dbg(dev_ctx, "write from buf (%p)%ld, ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (size < sizeof(struct she_mu_hdr)) {
+		devctx_err(dev_ctx, "User buffer too small(%ld < %lu)\n", size,
+			   sizeof(struct she_mu_hdr));
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	if (size > MAX_MESSAGE_SIZE_BYTES) {
+		devctx_err(dev_ctx, "User buffer too big(%ld > %lu)\n", size,
+			   MAX_MESSAGE_SIZE_BYTES);
+		err = -ENOSPC;
+		goto exit;
+	}
+
+	/* Copy data to buffer */
+	err = (int)copy_from_user(dev_ctx->temp_cmd, buf, size);
+	if (err) {
+		err = -EFAULT;
+		devctx_err(dev_ctx, "Fail copy message from user\n");
+		goto exit;
+	}
+
+	print_hex_dump_debug("from user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_cmd, size, false);
+
+	header = dev_ctx->temp_cmd[0];
+
+	/* Check the message is valid according to tags */
+	if (MESSAGE_TAG(header) == mu_priv->cmd_tag) {
+		/*
+		 * unlocked in seco_mu_receive_work_handler when the
+		 * response to this command is received.
+		 */
+		mutex_lock(&mu_priv->mu_cmd_lock);
+		mu_priv->waiting_rsp_dev = dev_ctx;
+	} else if (MESSAGE_TAG(header) == mu_priv->rsp_tag) {
+		/* Check the device context can send the command */
+		if (dev_ctx != mu_priv->cmd_receiver_dev) {
+			devctx_err(dev_ctx,
+				   "This channel is not configured to send response to SECO\n");
+			err = -EPERM;
+			goto exit;
+		}
+	} else {
+		devctx_err(dev_ctx, "The message does not have a valid TAG\n");
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/*
+	 * Check that the size passed as argument matches the size
+	 * carried in the message.
+	 */
+	nb_words = MESSAGE_SIZE(header);
+	if (nb_words * sizeof(u32) != size) {
+		devctx_err(dev_ctx, "User buffer too small\n");
+		goto exit;
+	}
+
+	mutex_lock(&mu_priv->mu_lock);
+
+	/* Send message */
+	devctx_dbg(dev_ctx, "sending message\n");
+	err = mbox_send_message(mu_priv->tx_chan, dev_ctx->temp_cmd);
+	if (err < 0) {
+		devctx_err(dev_ctx, "Failed to send message\n");
+		goto unlock;
+	}
+
+	err = nb_words * (u32)sizeof(u32);
+
+unlock:
+	mutex_unlock(&mu_priv->mu_lock);
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/*
+ * Read a message from the MU.
+ * Blocking until a message is available.
+ */
+static ssize_t seco_mu_fops_read(struct file *fp, char __user *buf,
+				 size_t size, loff_t *ppos)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	u32 data_size = 0, size_to_copy = 0;
+	struct seco_out_buffer_desc *b_desc;
+	int err;
+
+	devctx_dbg(dev_ctx, "read to buf %p(%ld), ppos=%lld\n", buf, size,
+		   ((ppos) ? *ppos : 0));
+
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	if (dev_ctx->status != MU_OPENED) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	if (dev_ctx->v2x_reset) {
+		err = -EINVAL;
+		goto exit;
+	}
+
+	/* Wait until the complete message is received on the MU. */
+	err = wait_event_interruptible(dev_ctx->wq, dev_ctx->pending_hdr != 0);
+	if (err) {
+		devctx_err(dev_ctx, "Interrupted by signal\n");
+		goto exit;
+	}
+
+	if (dev_ctx->v2x_reset) {
+		err = -EINVAL;
+		dev_ctx->v2x_reset = 0;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "%s %s\n", __func__,
+		   "message received, start transmit to user");
+
+	/* Check that the size passed as argument is larger than
+	 * the one carried in the message.
+	 */
+	data_size = dev_ctx->temp_resp_size * sizeof(u32);
+	size_to_copy = data_size;
+	if (size_to_copy > size) {
+		devctx_dbg(dev_ctx, "User buffer too small (%ld < %d)\n",
+			   size, size_to_copy);
+		size_to_copy = size;
+	}
+
+	/* We may need to copy the output data to user before
+	 * delivering the completion message.
+	 */
+	while (!list_empty(&dev_ctx->pending_out)) {
+		b_desc = list_first_entry_or_null(&dev_ctx->pending_out,
+						  struct seco_out_buffer_desc,
+						  link);
+		if (b_desc->out_usr_ptr && b_desc->out_ptr) {
+			devctx_dbg(dev_ctx, "Copy output data to user\n");
+			err = (int)copy_to_user(b_desc->out_usr_ptr,
+						b_desc->out_ptr,
+						b_desc->out_size);
+			if (err) {
+				devctx_err(dev_ctx,
+					   "Failed to copy output data to user\n");
+				err = -EFAULT;
+				goto exit;
+			}
+		}
+		__list_del_entry(&b_desc->link);
+		devm_kfree(dev_ctx->dev, b_desc);
+	}
+
+	/* Copy data from the buffer */
+	print_hex_dump_debug("to user ", DUMP_PREFIX_OFFSET, 4, 4,
+			     dev_ctx->temp_resp, size_to_copy, false);
+	err = (int)copy_to_user(buf, dev_ctx->temp_resp, size_to_copy);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	err = size_to_copy;
+
+	/* free memory allocated on the shared buffers. */
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->non_secure_mem.pos = 0;
+
+	dev_ctx->pending_hdr = 0;
+
+exit:
+	up(&dev_ctx->fops_lock);
+	return err;
+}
+
+/* Configure the shared memory according to user config */
+static int
+seco_mu_ioctl_shared_mem_cfg_handler(struct seco_mu_device_ctx *dev_ctx,
+				     unsigned long arg)
+{
+	struct seco_mu_ioctl_shared_mem_cfg cfg;
+	int err = -EINVAL;
+	u64 high_boundary;
+
+	/* Check if not already configured. */
+	if (dev_ctx->secure_mem.dma_addr != 0u) {
+		devctx_err(dev_ctx, "Shared memory not configured\n");
+		goto exit;
+	}
+
+	err = (int)copy_from_user(&cfg, (u8 *)arg,
+		sizeof(cfg));
+	if (err) {
+		devctx_err(dev_ctx, "Fail copy shared memory config to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "cfg offset: %u(%d)\n", cfg.base_offset, cfg.size);
+
+	high_boundary = cfg.base_offset;
+	if (high_boundary > SECURE_RAM_SIZE) {
+		devctx_err(dev_ctx, "base offset is over secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	high_boundary += cfg.size;
+	if (high_boundary > SECURE_RAM_SIZE) {
+		devctx_err(dev_ctx, "total memory is over secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	dev_ctx->secure_mem.dma_addr = (dma_addr_t)cfg.base_offset;
+	dev_ctx->secure_mem.size = cfg.size;
+	dev_ctx->secure_mem.pos = 0;
+	dev_ctx->secure_mem.ptr = devm_ioremap(dev_ctx->dev,
+					(phys_addr_t)(SECURE_RAM_BASE_ADDRESS +
+					(u64)dev_ctx->secure_mem.dma_addr),
+					dev_ctx->secure_mem.size);
+	if (!dev_ctx->secure_mem.ptr) {
+		devctx_err(dev_ctx, "Failed to map secure memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/*
+ * Copy a buffer of daa to/from the user and return the address to use in
+ * messages
+ */
+static int seco_mu_ioctl_setup_iobuf_handler(struct seco_mu_device_ctx *dev_ctx,
+					     unsigned long arg)
+{
+	struct seco_out_buffer_desc *out_buf_desc;
+	struct seco_mu_ioctl_setup_iobuf io;
+	struct seco_shared_mem *shared_mem;
+	int err = -EINVAL;
+	u32 pos;
+
+	err = (int)copy_from_user(&io,
+		(u8 *)arg,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed copy iobuf config from user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx, "io [buf: %p(%d) flag: %x]\n",
+		   io.user_buf, io.length, io.flags);
+
+	if (io.length == 0 || !io.user_buf) {
+		/*
+		 * Accept NULL pointers since some buffers are optional
+		 * in SECO commands. In this case we should return 0 as
+		 * pointer to be embedded into the message.
+		 * Skip all data copy part of code below.
+		 */
+		io.seco_addr = 0;
+		goto copy;
+	}
+
+	/* Select the shared memory to be used for this buffer. */
+	if (io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) {
+		/* App requires to use secure memory for this buffer.*/
+		shared_mem = &dev_ctx->secure_mem;
+	} else {
+		/* No specific requirement for this buffer. */
+		shared_mem = &dev_ctx->non_secure_mem;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (io.length >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough space in shared memory\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+	shared_mem->pos += round_up(io.length, 8u);
+	io.seco_addr = (u64)shared_mem->dma_addr + pos;
+
+	if ((io.flags & SECO_MU_IO_FLAGS_USE_SEC_MEM) &&
+	    !(io.flags & SECO_MU_IO_FLAGS_USE_SHORT_ADDR))
+		/*Add base address to get full address.*/
+		io.seco_addr += SECURE_RAM_BASE_ADDRESS_SCU;
+
+	if (io.flags & SECO_MU_IO_FLAGS_IS_INPUT) {
+		/*
+		 * buffer is input:
+		 * copy data from user space to this allocated buffer.
+		 */
+		err = (int)copy_from_user(shared_mem->ptr + pos, io.user_buf,
+					  io.length);
+		if (err) {
+			devctx_err(dev_ctx,
+				   "Failed copy data to shared memory\n");
+			err = -EFAULT;
+			goto exit;
+		}
+	} else {
+		/*
+		 * buffer is output:
+		 * add an entry in the "pending buffers" list so data
+		 * can be copied to user space when receiving SECO
+		 * response.
+		 */
+		out_buf_desc = devm_kmalloc(dev_ctx->dev, sizeof(*out_buf_desc),
+					    GFP_KERNEL);
+		if (!out_buf_desc) {
+			err = -ENOMEM;
+			devctx_err(dev_ctx,
+				   "Failed allocating mem for pending buffer\n"
+				   );
+			goto exit;
+		}
+
+		out_buf_desc->out_ptr = shared_mem->ptr + pos;
+		out_buf_desc->out_usr_ptr = io.user_buf;
+		out_buf_desc->out_size = io.length;
+		list_add_tail(&out_buf_desc->link, &dev_ctx->pending_out);
+	}
+
+copy:
+	/* Provide the seco address to user space only if success. */
+	err = (int)copy_to_user((u8 *)arg, &io,
+		sizeof(io));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy iobuff setup to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/* Retrieve info about the MU */
+static int seco_mu_ioctl_get_mu_info_handler(struct seco_mu_device_ctx *dev_ctx,
+					     unsigned long arg)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct seco_mu_ioctl_get_mu_info info;
+	int err = -EINVAL;
+
+	info.seco_mu_idx = (u8)priv->seco_mu_id;
+	info.interrupt_idx = SECO_MU_INTERRUPT_INDEX;
+	info.tz = SECO_DEFAULT_TZ;
+
+	err = imx_sc_rm_get_did(priv->ipc_scu, &info.did);
+	if (err) {
+		devctx_err(dev_ctx, "Get did failed\n");
+		goto exit;
+	}
+
+	devctx_dbg(dev_ctx,
+		   "info [mu_idx: %d, irq_idx: %d, tz: 0x%x, did: 0x%x]\n",
+		   info.seco_mu_idx, info.interrupt_idx, info.tz, info.did);
+
+	err = (int)copy_to_user((u8 *)arg, &info,
+		sizeof(info));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy mu info to user\n");
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+static int seco_mu_ioctl_signed_msg_handler(struct seco_mu_device_ctx *dev_ctx,
+					    unsigned long arg)
+{
+	struct seco_shared_mem *shared_mem = &dev_ctx->non_secure_mem;
+	struct seco_mu_priv *priv = dev_get_drvdata(dev_ctx->dev);
+	struct seco_mu_ioctl_signed_message msg;
+	int err = -EINVAL;
+	u64 addr;
+	u32 pos;
+
+	err = (int)copy_from_user(&msg,
+		(u8 *)arg,
+		sizeof(msg));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy from user: %d\n", err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+	/* Check there is enough space in the shared memory. */
+	if (msg.msg_size >= shared_mem->size - shared_mem->pos) {
+		devctx_err(dev_ctx, "Not enough mem: %d left, %d required\n",
+			   shared_mem->size - shared_mem->pos, msg.msg_size);
+		err = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate space in shared memory. 8 bytes aligned. */
+	pos = shared_mem->pos;
+
+	/* get physical address from the pos */
+	addr = (u64)shared_mem->dma_addr + pos;
+
+	/* copy signed message from user space to this allocated buffer */
+	err = (int)copy_from_user(shared_mem->ptr + pos, msg.message,
+				  msg.msg_size);
+	if (err) {
+		devctx_err(dev_ctx, "Failed to signed message from user: %d\n",
+			   err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+	/* Send the message to SECO through SCU */
+	msg.error_code = imx_sc_seco_sab_msg(priv->ipc_scu, addr);
+
+	err = (int)copy_to_user((u8 *)arg, &msg,
+		sizeof(msg));
+	if (err) {
+		devctx_err(dev_ctx, "Failed to copy to user: %d\n", err);
+		err = -EFAULT;
+		goto exit;
+	}
+
+exit:
+	return err;
+}
+
+/* IOCTL entry point of a char device */
+static long seco_mu_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(fp->private_data,
+					struct seco_mu_device_ctx, miscdev);
+	struct seco_mu_priv *mu_priv = dev_ctx->mu_priv;
+	int err = -EINVAL;
+
+	/* Prevent race during change of device context */
+	if (down_interruptible(&dev_ctx->fops_lock))
+		return -EBUSY;
+
+	switch (cmd) {
+	case SECO_MU_IOCTL_ENABLE_CMD_RCV:
+		if (!mu_priv->cmd_receiver_dev) {
+			devctx_dbg(dev_ctx, "setting as receiver\n");
+			mu_priv->cmd_receiver_dev = dev_ctx;
+			err = 0;
+		};
+		break;
+	case SECO_MU_IOCTL_SHARED_BUF_CFG:
+		err = seco_mu_ioctl_shared_mem_cfg_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_SETUP_IOBUF:
+		err = seco_mu_ioctl_setup_iobuf_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_GET_MU_INFO:
+		err = seco_mu_ioctl_get_mu_info_handler(dev_ctx, arg);
+		break;
+	case SECO_MU_IOCTL_SIGNED_MESSAGE:
+		err = seco_mu_ioctl_signed_msg_handler(dev_ctx, arg);
+		break;
+	default:
+		err = -EINVAL;
+		devctx_dbg(dev_ctx, "IOCTL %.8x not supported\n", cmd);
+	}
+
+	up(&dev_ctx->fops_lock);
+	return (long)err;
+}
+
+/*
+ * Callback called by mailbox FW when data are received
+ */
+static void seco_mu_rx_callback(struct mbox_client *c, void *msg)
+{
+	struct device *dev = c->dev;
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	struct seco_mu_device_ctx *dev_ctx;
+	bool is_response = false;
+	int msg_size;
+	u32 header;
+
+	dev_dbg(dev, "Message received on mailbox\n");
+
+	/* The function can be called with NULL msg */
+	if (!msg) {
+		dev_err(dev, "Message is invalid\n");
+		return;
+	}
+
+	if (IS_ERR(msg)) {
+		dev_err(dev, "Error during reception of message: %ld\n",
+			PTR_ERR(msg));
+		return;
+	}
+
+	header = *(u32 *)msg;
+
+	dev_dbg(dev, "Selecting device\n");
+
+	/* Incoming command: wake up the receiver if any. */
+	if (MESSAGE_TAG(header) == priv->cmd_tag) {
+		dev_dbg(dev, "Selecting cmd receiver\n");
+		dev_ctx = priv->cmd_receiver_dev;
+	} else if (MESSAGE_TAG(header) == priv->rsp_tag) {
+		dev_dbg(dev, "Selecting rsp waiter\n");
+		dev_ctx = priv->waiting_rsp_dev;
+		is_response = true;
+	} else {
+		dev_err(dev, "Failed to select a device for message: %.8x\n",
+			header);
+		return;
+	}
+
+	if (!dev_ctx) {
+		dev_err(dev, "No device context selected for message: %.8x\n",
+			header);
+		return;
+	}
+
+	/* Init reception */
+	msg_size = MESSAGE_SIZE(header);
+	if (msg_size > MAX_RECV_SIZE) {
+		devctx_err(dev_ctx, "Message is too big (%d > %d)", msg_size,
+			   MAX_RECV_SIZE);
+		return;
+	}
+
+	memcpy(dev_ctx->temp_resp, msg, msg_size * sizeof(u32));
+	dev_ctx->temp_resp_size = msg_size;
+
+	/* Allow user to read */
+	dev_ctx->pending_hdr = dev_ctx->temp_resp[0];
+	wake_up_interruptible(&dev_ctx->wq);
+
+	if (is_response) {
+		/* Allow user to send new command */
+		mutex_unlock(&priv->mu_cmd_lock);
+	}
+}
+
+#define SECO_FW_VER_FEAT_MASK		(0x0000FFF0u)
+#define SECO_FW_VER_FEAT_SHIFT		(0x04u)
+#define SECO_FW_VER_FEAT_MIN_ALL_MU	(0x04u)
+
+/*
+ * Get SECO FW version and check if it supports receiving commands on all MUs
+ * The version is retrieved through SCU since this is the only communication
+ * channel to SECO always present.
+ */
+static int seco_mu_check_all_mu_supported(struct device *dev)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	u32 seco_ver;
+	int ret;
+
+	ret = imx_sc_seco_build_info(priv->ipc_scu, &seco_ver, NULL);
+	if (ret) {
+		dev_err(dev, "failed to retrieve SECO build info\n");
+		goto exit;
+	}
+
+	if (((seco_ver & SECO_FW_VER_FEAT_MASK) >> SECO_FW_VER_FEAT_SHIFT)
+		< SECO_FW_VER_FEAT_MIN_ALL_MU) {
+		dev_err(dev, "current SECO FW do not support MU with Linux\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+/* Char driver setup */
+static const struct file_operations seco_mu_fops = {
+	.open		= seco_mu_fops_open,
+	.owner		= THIS_MODULE,
+	.read		= seco_mu_fops_read,
+	.release	= seco_mu_fops_close,
+	.write		= seco_mu_fops_write,
+	.unlocked_ioctl = seco_mu_ioctl,
+};
+
+/* interface for managed res to free a mailbox channel */
+static void if_mbox_free_channel(void *mbox_chan)
+{
+	mbox_free_channel(mbox_chan);
+}
+
+/* interface for managed res to unregister a char device */
+static void if_misc_deregister(void *miscdevice)
+{
+	misc_deregister(miscdevice);
+}
+
+static int seco_mu_request_channel(struct device *dev,
+				   struct mbox_chan **chan,
+				   const char *name)
+{
+	struct seco_mu_priv *priv = dev_get_drvdata(dev);
+	struct mbox_chan *t_chan;
+	int ret = 0;
+
+	t_chan = mbox_request_channel_byname(&priv->cl, name);
+	if (IS_ERR(t_chan)) {
+		ret = PTR_ERR(t_chan);
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev,
+				"Failed to request chan %s ret %d\n", name,
+				ret);
+		goto exit;
+	}
+
+	ret = devm_add_action(dev, if_mbox_free_channel, t_chan);
+	if (ret) {
+		dev_err(dev, "failed to add devm removal of mbox %s\n", name);
+		goto exit;
+	}
+
+	*chan = t_chan;
+
+exit:
+	return ret;
+}
+
+static int imx_sc_v2x_reset_notify(struct notifier_block *nb,
+                                      unsigned long event, void *group)
+{
+	struct seco_mu_device_ctx *dev_ctx = container_of(nb,
+					struct seco_mu_device_ctx, scu_notify);
+
+	if (!(event & IMX_SC_IRQ_V2X_RESET))
+		return 0;
+
+	dev_ctx->v2x_reset = true;
+
+	wake_up_interruptible(&dev_ctx->wq);
+	return 0;
+}
+/* Driver probe.*/
+static int seco_mu_probe(struct platform_device *pdev)
+{
+	struct seco_mu_device_ctx *dev_ctx;
+	struct device *dev = &pdev->dev;
+	struct seco_mu_priv *priv;
+	struct device_node *np;
+	int max_nb_users = 0;
+	char *devname;
+	int ret;
+	int i;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv) {
+		ret = -ENOMEM;
+		dev_err(dev, "Fail allocate mem for private data\n");
+		goto exit;
+	}
+	priv->dev = dev;
+	dev_set_drvdata(dev, priv);
+
+	/*
+	 * Get the address of MU to be used for communication with the SCU
+	 */
+	np = pdev->dev.of_node;
+	if (!np) {
+		dev_err(dev, "Cannot find MU User entry in device tree\n");
+		ret = -ENOTSUPP;
+		goto exit;
+	}
+
+	ret = imx_scu_get_handle(&priv->ipc_scu);
+	if (ret) {
+		dev_err(dev, "Fail to retrieve IPC handle\n");
+		goto exit;
+	}
+
+	ret = imx_sc_rm_get_resource_owner(priv->ipc_scu, IMX_SC_R_SECO,
+					   &priv->seco_part_owner);
+	if (ret) {
+		dev_err(dev, "Fail get owner of SECO resource\n");
+		goto exit;
+	}
+
+	ret = seco_mu_check_all_mu_supported(dev);
+	if (ret) {
+		dev_err(dev, "Fail seco_mu_check_all_mu_supported\n");
+		goto exit;
+	}
+
+	/* Initialize the mutex. */
+	mutex_init(&priv->mu_cmd_lock);
+	mutex_init(&priv->mu_lock);
+
+	priv->cmd_receiver_dev = NULL;
+	priv->waiting_rsp_dev = NULL;
+
+	ret = of_property_read_u32(np, "fsl,seco_mu_id", &priv->seco_mu_id);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_id", __func__);
+		priv->seco_mu_id = SECO_DEFAULT_MU_INDEX;
+	}
+
+	ret = of_property_read_u32(np, "fsl,seco_max_users", &max_nb_users);
+	if (ret) {
+		dev_warn(dev, "%s: Not able to read mu_max_user", __func__);
+		max_nb_users = SECO_MU_DEFAULT_MAX_USERS;
+	}
+
+	ret = of_property_read_u8(np, "fsl,cmd_tag", &priv->cmd_tag);
+	if (ret)
+		priv->cmd_tag = DEFAULT_MESSAGING_TAG_COMMAND;
+
+	ret = of_property_read_u8(np, "fsl,rsp_tag", &priv->rsp_tag);
+	if (ret)
+		priv->rsp_tag = DEFAULT_MESSAGING_TAG_RESPONSE;
+
+	/* Mailbox client configuration */
+	priv->cl.dev = dev;
+	priv->cl.knows_txdone = true;
+	priv->cl.rx_callback = seco_mu_rx_callback;
+
+	ret = seco_mu_request_channel(dev, &priv->tx_chan, "txdb");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request txdb channel\n");
+
+		goto exit;
+	}
+
+	ret = seco_mu_request_channel(dev, &priv->rx_chan, "rxdb");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to request rxdb channel\n");
+
+		goto exit;
+	}
+
+	/* Create users */
+	for (i = 0; i < max_nb_users; i++) {
+		dev_ctx = devm_kzalloc(dev, sizeof(*dev_ctx), GFP_KERNEL);
+		if (!dev_ctx) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for device context\n");
+			goto exit;
+		}
+
+		dev_ctx->dev = dev;
+		dev_ctx->status = MU_FREE;
+		dev_ctx->mu_priv = priv;
+		/* Default value invalid for an header. */
+		init_waitqueue_head(&dev_ctx->wq);
+
+		INIT_LIST_HEAD(&dev_ctx->pending_out);
+		sema_init(&dev_ctx->fops_lock, 1);
+
+		devname = devm_kasprintf(dev, GFP_KERNEL, "seco_mu%d_ch%d",
+					 priv->seco_mu_id, i);
+		if (!devname) {
+			ret = -ENOMEM;
+			dev_err(dev,
+				"Fail to allocate memory for misc dev name\n");
+			goto exit;
+		}
+
+		dev_ctx->miscdev.name = devname;
+		dev_ctx->miscdev.minor	= MISC_DYNAMIC_MINOR;
+		dev_ctx->miscdev.fops = &seco_mu_fops;
+		dev_ctx->miscdev.parent = dev;
+		ret = misc_register(&dev_ctx->miscdev);
+		if (ret) {
+			dev_err(dev, "failed to register misc device %d\n",
+				ret);
+			goto exit;
+		}
+
+		ret = devm_add_action(dev, if_misc_deregister,
+				      &dev_ctx->miscdev);
+
+		dev_ctx->scu_notify.notifier_call = imx_sc_v2x_reset_notify;
+
+		ret = imx_scu_irq_register_notifier(&dev_ctx->scu_notify);
+		if (ret) {
+			dev_err(&pdev->dev, "v2x reqister scu notifier failed.\n");
+			return ret;
+		}
+
+		if (ret)
+			dev_warn(dev,
+				 "failed to add managed removal of miscdev\n");
+	}
+
+	ret = imx_scu_irq_group_enable(IMX_SC_IRQ_GROUP_WAKE,
+					IMX_SC_IRQ_V2X_RESET, true);
+	if (ret) {
+		dev_warn(&pdev->dev, "v2x Enable irq failed.\n");
+		return ret;
+	}
+
+exit:
+	return ret;
+}
+
+static const struct of_device_id seco_mu_match[] = {
+	{
+		.compatible = "fsl,imx-seco-mu",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, seco_mu_match);
+
+static struct platform_driver seco_mu_driver = {
+	.driver = {
+		.name = "seco_mu",
+		.of_match_table = seco_mu_match,
+	},
+	.probe       = seco_mu_probe,
+};
+
+module_platform_driver(seco_mu_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("IMX Seco MU");
+MODULE_AUTHOR("NXP");
diff --git a/drivers/pinctrl/freescale/pinctrl-imx93.c b/drivers/pinctrl/freescale/pinctrl-imx93.c
new file mode 100644
index 000000000..417e41b37
--- /dev/null
+++ b/drivers/pinctrl/freescale/pinctrl-imx93.c
@@ -0,0 +1,273 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2021 NXP
+ */
+
+#include <linux/err.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/pinctrl/pinctrl.h>
+
+#include "pinctrl-imx.h"
+
+enum imx93_pads {
+	IMX93_IOMUXC_DAP_TDI = 0,
+	IMX93_IOMUXC_DAP_TMS_SWDIO = 1,
+	IMX93_IOMUXC_DAP_TCLK_SWCLK = 2,
+	IMX93_IOMUXC_DAP_TDO_TRACESWO = 3,
+	IMX93_IOMUXC_GPIO_IO00 = 4,
+	IMX93_IOMUXC_GPIO_IO01 = 5,
+	IMX93_IOMUXC_GPIO_IO02 = 6,
+	IMX93_IOMUXC_GPIO_IO03 = 7,
+	IMX93_IOMUXC_GPIO_IO04 = 8,
+	IMX93_IOMUXC_GPIO_IO05 = 9,
+	IMX93_IOMUXC_GPIO_IO06 = 10,
+	IMX93_IOMUXC_GPIO_IO07 = 11,
+	IMX93_IOMUXC_GPIO_IO08 = 12,
+	IMX93_IOMUXC_GPIO_IO09 = 13,
+	IMX93_IOMUXC_GPIO_IO10 = 14,
+	IMX93_IOMUXC_GPIO_IO11 = 15,
+	IMX93_IOMUXC_GPIO_IO12 = 16,
+	IMX93_IOMUXC_GPIO_IO13 = 17,
+	IMX93_IOMUXC_GPIO_IO14 = 18,
+	IMX93_IOMUXC_GPIO_IO15 = 19,
+	IMX93_IOMUXC_GPIO_IO16 = 20,
+	IMX93_IOMUXC_GPIO_IO17 = 21,
+	IMX93_IOMUXC_GPIO_IO18 = 22,
+	IMX93_IOMUXC_GPIO_IO19 = 23,
+	IMX93_IOMUXC_GPIO_IO20 = 24,
+	IMX93_IOMUXC_GPIO_IO21 = 25,
+	IMX93_IOMUXC_GPIO_IO22 = 26,
+	IMX93_IOMUXC_GPIO_IO23 = 27,
+	IMX93_IOMUXC_GPIO_IO24 = 28,
+	IMX93_IOMUXC_GPIO_IO25 = 29,
+	IMX93_IOMUXC_GPIO_IO26 = 30,
+	IMX93_IOMUXC_GPIO_IO27 = 31,
+	IMX93_IOMUXC_GPIO_IO28 = 32,
+	IMX93_IOMUXC_GPIO_IO29 = 33,
+	IMX93_IOMUXC_CCM_CLKO1 = 34,
+	IMX93_IOMUXC_CCM_CLKO2 = 35,
+	IMX93_IOMUXC_CCM_CLKO3 = 36,
+	IMX93_IOMUXC_CCM_CLKO4 = 37,
+	IMX93_IOMUXC_ENET1_MDC = 38,
+	IMX93_IOMUXC_ENET1_MDIO = 39,
+	IMX93_IOMUXC_ENET1_TD3 = 40,
+	IMX93_IOMUXC_ENET1_TD2 = 41,
+	IMX93_IOMUXC_ENET1_TD1 = 42,
+	IMX93_IOMUXC_ENET1_TD0 = 43,
+	IMX93_IOMUXC_ENET1_TX_CTL = 44,
+	IMX93_IOMUXC_ENET1_TXC = 45,
+	IMX93_IOMUXC_ENET1_RX_CTL = 46,
+	IMX93_IOMUXC_ENET1_RXC = 47,
+	IMX93_IOMUXC_ENET1_RD0 = 48,
+	IMX93_IOMUXC_ENET1_RD1 = 49,
+	IMX93_IOMUXC_ENET1_RD2 = 50,
+	IMX93_IOMUXC_ENET1_RD3 = 51,
+	IMX93_IOMUXC_ENET2_MDC = 52,
+	IMX93_IOMUXC_ENET2_MDIO = 53,
+	IMX93_IOMUXC_ENET2_TD3 = 54,
+	IMX93_IOMUXC_ENET2_TD2 = 55,
+	IMX93_IOMUXC_ENET2_TD1 = 56,
+	IMX93_IOMUXC_ENET2_TD0 = 57,
+	IMX93_IOMUXC_ENET2_TX_CTL = 58,
+	IMX93_IOMUXC_ENET2_TXC = 59,
+	IMX93_IOMUXC_ENET2_RX_CTL = 60,
+	IMX93_IOMUXC_ENET2_RXC = 61,
+	IMX93_IOMUXC_ENET2_RD0 = 62,
+	IMX93_IOMUXC_ENET2_RD1 = 63,
+	IMX93_IOMUXC_ENET2_RD2 = 64,
+	IMX93_IOMUXC_ENET2_RD3 = 65,
+	IMX93_IOMUXC_SD1_CLK = 66,
+	IMX93_IOMUXC_SD1_CMD = 67,
+	IMX93_IOMUXC_SD1_DATA0 = 68,
+	IMX93_IOMUXC_SD1_DATA1 = 69,
+	IMX93_IOMUXC_SD1_DATA2 = 70,
+	IMX93_IOMUXC_SD1_DATA3 = 71,
+	IMX93_IOMUXC_SD1_DATA4 = 72,
+	IMX93_IOMUXC_SD1_DATA5 = 73,
+	IMX93_IOMUXC_SD1_DATA6 = 74,
+	IMX93_IOMUXC_SD1_DATA7 = 75,
+	IMX93_IOMUXC_SD1_STROBE = 76,
+	IMX93_IOMUXC_SD2_VSELECT = 77,
+	IMX93_IOMUXC_SD3_CLK = 78,
+	IMX93_IOMUXC_SD3_CMD = 79,
+	IMX93_IOMUXC_SD3_DATA0 = 80,
+	IMX93_IOMUXC_SD3_DATA1 = 81,
+	IMX93_IOMUXC_SD3_DATA2 = 82,
+	IMX93_IOMUXC_SD3_DATA3 = 83,
+	IMX93_IOMUXC_SD2_CD_B = 84,
+	IMX93_IOMUXC_SD2_CLK = 85,
+	IMX93_IOMUXC_SD2_CMD = 86,
+	IMX93_IOMUXC_SD2_DATA0 = 87,
+	IMX93_IOMUXC_SD2_DATA1 = 88,
+	IMX93_IOMUXC_SD2_DATA2 = 89,
+	IMX93_IOMUXC_SD2_DATA3 = 90,
+	IMX93_IOMUXC_SD2_RESET_B = 91,
+	IMX93_IOMUXC_I2C1_SCL = 92,
+	IMX93_IOMUXC_I2C1_SDA = 93,
+	IMX93_IOMUXC_I2C2_SCL = 94,
+	IMX93_IOMUXC_I2C2_SDA = 95,
+	IMX93_IOMUXC_UART1_RXD = 96,
+	IMX93_IOMUXC_UART1_TXD = 97,
+	IMX93_IOMUXC_UART2_RXD = 98,
+	IMX93_IOMUXC_UART2_TXD = 99,
+	IMX93_IOMUXC_PDM_CLK = 100,
+	IMX93_IOMUXC_PDM_BIT_STREAM0 = 101,
+	IMX93_IOMUXC_PDM_BIT_STREAM1 = 102,
+	IMX93_IOMUXC_SAI1_TXFS = 103,
+	IMX93_IOMUXC_SAI1_TXC = 104,
+	IMX93_IOMUXC_SAI1_TXD0 = 105,
+	IMX93_IOMUXC_SAI1_RXD0 = 106,
+	IMX93_IOMUXC_WDOG_ANY  = 107,
+};
+
+/* Pad names for the pinmux subsystem */
+static const struct pinctrl_pin_desc imx93_pinctrl_pads[] = {
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_DAP_TDI),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_DAP_TMS_SWDIO),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_DAP_TCLK_SWCLK),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_DAP_TDO_TRACESWO),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO00),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO01),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO02),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO03),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO04),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO05),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO06),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO07),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO08),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO09),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO10),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO11),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO12),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO13),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO14),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO15),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO16),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO17),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO18),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO19),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO20),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO21),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO22),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO23),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO24),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO25),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO26),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO27),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO28),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_GPIO_IO29),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_CCM_CLKO1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_CCM_CLKO2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_CCM_CLKO3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_CCM_CLKO4),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_MDC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_MDIO),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TD3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TD2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TD1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TX_CTL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_TXC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RX_CTL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RXC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RD1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RD2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET1_RD3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_MDC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_MDIO),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TD3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TD2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TD1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TX_CTL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_TXC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RX_CTL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RXC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RD1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RD2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_ENET2_RD3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_CLK),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_CMD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA4),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA5),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA6),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_DATA7),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD1_STROBE),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_VSELECT),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_CLK),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_CMD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_DATA0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_DATA1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_DATA2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD3_DATA3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_CD_B),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_CLK),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_CMD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_DATA0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_DATA1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_DATA2),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_DATA3),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SD2_RESET_B),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_I2C1_SCL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_I2C1_SDA),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_I2C2_SCL),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_I2C2_SDA),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_UART1_RXD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_UART1_TXD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_UART2_RXD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_UART2_TXD),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_PDM_CLK),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_PDM_BIT_STREAM0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_PDM_BIT_STREAM1),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SAI1_TXFS),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SAI1_TXC),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SAI1_TXD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_SAI1_RXD0),
+	IMX_PINCTRL_PIN(IMX93_IOMUXC_WDOG_ANY),
+};
+
+static const struct imx_pinctrl_soc_info imx93_pinctrl_info = {
+	.pins = imx93_pinctrl_pads,
+	.npins = ARRAY_SIZE(imx93_pinctrl_pads),
+	.flags = ZERO_OFFSET_VALID,
+	.gpr_compatible = "fsl,imx93-iomuxc-gpr",
+};
+
+static const struct of_device_id imx93_pinctrl_of_match[] = {
+	{ .compatible = "fsl,imx93-iomuxc", },
+	{ /* sentinel */ }
+};
+
+static int imx93_pinctrl_probe(struct platform_device *pdev)
+{
+	return imx_pinctrl_probe(pdev, &imx93_pinctrl_info);
+}
+
+static struct platform_driver imx93_pinctrl_driver = {
+	.driver = {
+		.name = "imx93-pinctrl",
+		.of_match_table = imx93_pinctrl_of_match,
+		.suppress_bind_attrs = true,
+	},
+	.probe = imx93_pinctrl_probe,
+};
+
+static int __init imx93_pinctrl_init(void)
+{
+	return platform_driver_register(&imx93_pinctrl_driver);
+}
+arch_initcall(imx93_pinctrl_init);
+
+MODULE_AUTHOR("Bai Ping <ping.bai@nxp.com>");
+MODULE_DESCRIPTION("NXP i.MX93 pinctrl driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/pinctrl/freescale/pinctrl-s32v-core.c b/drivers/pinctrl/freescale/pinctrl-s32v-core.c
new file mode 100644
index 000000000..75d0adc2b
--- /dev/null
+++ b/drivers/pinctrl/freescale/pinctrl-s32v-core.c
@@ -0,0 +1,526 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Core driver for the S32V pin controller
+ *
+ * Copyright (C) 2015-2016 Freescale Semiconductor, Inc.
+ * Copyright (C) 2017 NXP
+ *
+ * Based on pinctrl-imx.c:
+ *	Author: Dong Aisheng <dong.aisheng@linaro.org>
+ *	Copyright (C) 2012 Freescale Semiconductor, Inc.
+ *	Copyright (C) 2012 Linaro Ltd.
+ */
+
+#include <linux/err.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/pinctrl/machine.h>
+#include <linux/pinctrl/pinconf.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <linux/pinctrl/pinmux.h>
+#include <linux/slab.h>
+
+#include "../core.h"
+#include "pinctrl-s32v.h"
+
+/**
+ * @dev: a pointer back to containing device
+ * @base: the offset to the controller in virtual memory
+ */
+struct s32v_pinctrl {
+	struct device *dev;
+	struct pinctrl_dev *pctl;
+	void __iomem *base;
+	const struct s32v_pinctrl_soc_info *info;
+};
+
+static const char *pin_get_name_from_info(struct s32v_pinctrl_soc_info *info,
+					  const unsigned int pin_id)
+{
+	int i;
+
+	for (i = 0; i < info->npins; i++) {
+		if (info->pins[i].number == pin_id)
+			return info->pins[i].name;
+	}
+
+	return NULL;
+}
+
+static inline const struct s32v_pin_group *s32v_pinctrl_find_group_by_name(
+				const struct s32v_pinctrl_soc_info *info,
+				const char *name)
+{
+	const struct s32v_pin_group *grp = NULL;
+	unsigned int i;
+
+	for (i = 0; i < info->ngroups; i++) {
+		if (!strcmp(info->groups[i].name, name)) {
+			grp = &info->groups[i];
+			break;
+		}
+	}
+
+	return grp;
+}
+
+static int s32v_get_groups_count(struct pinctrl_dev *pctldev)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	return info->ngroups;
+}
+
+static const char *s32v_get_group_name(struct pinctrl_dev *pctldev,
+				       unsigned int selector)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	return info->groups[selector].name;
+}
+
+static int s32v_get_group_pins(struct pinctrl_dev *pctldev,
+			       unsigned int selector, const unsigned int **pins,
+			       unsigned int *npins)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	if (selector >= info->ngroups)
+		return -EINVAL;
+
+	*pins = info->groups[selector].pin_ids;
+	*npins = info->groups[selector].npins;
+
+	return 0;
+}
+
+static void s32v_pin_dbg_show(struct pinctrl_dev *pctldev, struct seq_file *s,
+			      unsigned int offset)
+{
+	seq_printf(s, "%s", dev_name(pctldev->dev));
+}
+
+static int s32v_dt_node_to_map(struct pinctrl_dev *pctldev,
+			       struct device_node *np,
+			       struct pinctrl_map **map, unsigned int *num_maps)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+	const struct s32v_pin_group *grp;
+	struct pinctrl_map *new_map;
+	struct device_node *parent;
+	int map_num = 1;
+	int i, j;
+
+	/*
+	 * first find the group of this node and check if we need create
+	 * config maps for pins
+	 */
+	grp = s32v_pinctrl_find_group_by_name(info, np->name);
+	if (!grp) {
+		dev_err(info->dev, "unable to find group for node %s\n",
+			np->name);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < grp->npins; i++)
+		map_num++;
+
+	new_map = kmalloc_array(map_num, sizeof(struct pinctrl_map),
+				GFP_KERNEL);
+	if (!new_map)
+		return -ENOMEM;
+
+	*map = new_map;
+	*num_maps = map_num;
+
+	/* create mux map */
+	parent = of_get_parent(np);
+	if (!parent) {
+		kfree(new_map);
+		return -EINVAL;
+	}
+	new_map[0].type = PIN_MAP_TYPE_MUX_GROUP;
+	new_map[0].data.mux.function = parent->name;
+	new_map[0].data.mux.group = np->name;
+	of_node_put(parent);
+
+	/* create config map */
+	new_map++;
+	for (i = j = 0; i < grp->npins; i++) {
+		new_map[j].type = PIN_MAP_TYPE_CONFIGS_PIN;
+		new_map[j].data.configs.group_or_pin =
+			pin_get_name(pctldev, grp->pins[i].pin_id);
+		new_map[j].data.configs.configs = &grp->pins[i].config;
+		new_map[j].data.configs.num_configs = 1;
+		j++;
+	}
+
+	dev_dbg(pctldev->dev, "maps: function %s group %s num %d\n",
+		(*map)->data.mux.function, (*map)->data.mux.group, map_num);
+
+	return 0;
+}
+
+static void s32v_dt_free_map(struct pinctrl_dev *pctldev,
+			     struct pinctrl_map *map, unsigned int num_maps)
+{
+	kfree(map);
+}
+
+static const struct pinctrl_ops s32v_pctrl_ops = {
+	.get_groups_count = s32v_get_groups_count,
+	.get_group_name = s32v_get_group_name,
+	.get_group_pins = s32v_get_group_pins,
+	.pin_dbg_show = s32v_pin_dbg_show,
+	.dt_node_to_map = s32v_dt_node_to_map,
+	.dt_free_map = s32v_dt_free_map,
+
+};
+
+static int s32v_pmx_set(struct pinctrl_dev *pctldev, unsigned int selector,
+			unsigned int group)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+	unsigned int npins, pin_id;
+	int i;
+	struct s32v_pin_group *grp;
+
+	/*
+	 * Configure the mux mode for each pin in the group for a specific
+	 * function.
+	 */
+	grp = &info->groups[group];
+	npins = grp->npins;
+
+	dev_dbg(ipctl->dev, "enable function %s group %s\n",
+		info->functions[selector].name, grp->name);
+
+	for (i = 0; i < npins; i++) {
+		struct s32v_pin *pin = &grp->pins[i];
+
+		pin_id = pin->pin_id;
+
+		writel(pin->config, ipctl->base + S32V_PAD_CONFIG(pin_id));
+		dev_dbg(ipctl->dev, "write: offset 0x%x val %lu\n",
+			S32V_PAD_CONFIG(pin_id), pin->config);
+	}
+
+	return 0;
+}
+
+static int s32v_pmx_get_funcs_count(struct pinctrl_dev *pctldev)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	return info->nfunctions;
+}
+
+static const char *s32v_pmx_get_func_name(struct pinctrl_dev *pctldev,
+					  unsigned int selector)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	return info->functions[selector].name;
+}
+
+static int s32v_pmx_get_groups(struct pinctrl_dev *pctldev,
+			       unsigned int selector,
+			       const char * const **groups,
+			       unsigned int * const num_groups)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+
+	*groups = info->functions[selector].groups;
+	*num_groups = info->functions[selector].num_groups;
+
+	return 0;
+}
+
+static const struct pinmux_ops s32v_pmx_ops = {
+	.get_functions_count = s32v_pmx_get_funcs_count,
+	.get_function_name = s32v_pmx_get_func_name,
+	.get_function_groups = s32v_pmx_get_groups,
+	.set_mux = s32v_pmx_set,
+};
+
+static int s32v_pinconf_get(struct pinctrl_dev *pctldev,
+			    unsigned int pin_id, unsigned long *config)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+
+	*config = readl(ipctl->base + S32V_PAD_CONFIG(pin_id));
+
+	return 0;
+}
+
+static int s32v_pinconf_set(struct pinctrl_dev *pctldev,
+			    unsigned int pin_id, unsigned long *configs,
+			    unsigned int num_configs)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	int i;
+
+	dev_dbg(ipctl->dev, "pinconf set pin %s\n",
+		pin_get_name(pctldev, pin_id));
+
+	for (i = 0; i < num_configs; i++) {
+		writel(configs[i], ipctl->base + S32V_PAD_CONFIG(pin_id));
+		dev_dbg(ipctl->dev, "write: offset 0x%x val 0x%lx\n",
+			S32V_PAD_CONFIG(pin_id), configs[i]);
+	} /* for each config */
+
+	return 0;
+}
+
+static void s32v_pinconf_dbg_show(struct pinctrl_dev *pctldev,
+				  struct seq_file *s, unsigned int pin_id)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	unsigned long config;
+
+	config = readl(ipctl->base + S32V_PAD_CONFIG(pin_id));
+	seq_printf(s, "0x%lx", config);
+}
+
+static void s32v_pinconf_group_dbg_show(struct pinctrl_dev *pctldev,
+					struct seq_file *s, unsigned int group)
+{
+	struct s32v_pinctrl *ipctl = pinctrl_dev_get_drvdata(pctldev);
+	const struct s32v_pinctrl_soc_info *info = ipctl->info;
+	struct s32v_pin_group *grp;
+	unsigned long config;
+	const char *name;
+	int i, ret;
+
+	if (group > info->ngroups)
+		return;
+
+	seq_puts(s, "\n");
+	grp = &info->groups[group];
+	for (i = 0; i < grp->npins; i++) {
+		struct s32v_pin *pin = &grp->pins[i];
+
+		name = pin_get_name(pctldev, pin->pin_id);
+		ret = s32v_pinconf_get(pctldev, pin->pin_id, &config);
+		if (ret)
+			return;
+		seq_printf(s, "%s: 0x%lx", name, config);
+	}
+}
+
+static const struct pinconf_ops s32v_pinconf_ops = {
+	.pin_config_get = s32v_pinconf_get,
+	.pin_config_set = s32v_pinconf_set,
+	.pin_config_dbg_show = s32v_pinconf_dbg_show,
+	.pin_config_group_dbg_show = s32v_pinconf_group_dbg_show,
+};
+
+static struct pinctrl_desc s32v_pinctrl_desc = {
+	.pctlops = &s32v_pctrl_ops,
+	.pmxops = &s32v_pmx_ops,
+	.confops = &s32v_pinconf_ops,
+	.owner = THIS_MODULE,
+};
+
+/*
+ * Each pin represented in fsl,pins consists of 5 u32 PIN_FUNC_ID and
+ * 1 u32 CONFIG, so 24 types in total for each pin.
+ */
+#define FSL_PIN_SIZE 24
+#define SHARE_FSL_PIN_SIZE 20
+
+static int s32v_pinctrl_parse_groups(struct device_node *np,
+				     struct s32v_pin_group *grp,
+				     struct s32v_pinctrl_soc_info *info,
+				     u32 index)
+{
+	int size, i;
+	const __be32 *list;
+
+	dev_dbg(info->dev, "group(%d): %s\n", index, np->name);
+
+	/* Initialise group */
+	grp->name = np->name;
+
+	/*
+	 * the binding format is fsl,pins = <PIN CONFIG>,
+	 * do sanity check and calculate pins number
+	 */
+	list = of_get_property(np, "fsl,pins", &size);
+	if (!list) {
+		dev_err(info->dev, "no fsl,pins property in node %s\n",
+			np->full_name);
+		return -EINVAL;
+	}
+
+	/* we do not check return since it's safe node passed down */
+	if (!size || size % S32V_PIN_SIZE) {
+		dev_err(info->dev, "Invalid fsl,pins property in node %s\n",
+			np->full_name);
+		return -EINVAL;
+	}
+
+	grp->npins = size / S32V_PIN_SIZE;
+	grp->pins = devm_kzalloc(info->dev,
+				 grp->npins * sizeof(struct s32v_pin),
+				 GFP_KERNEL);
+	grp->pin_ids = devm_kzalloc(info->dev,
+				    grp->npins * sizeof(unsigned int),
+				    GFP_KERNEL);
+	if (!grp->pins || !grp->pin_ids)
+		return -ENOMEM;
+
+	for (i = 0; i < grp->npins; i++) {
+		struct s32v_pin *pin = &grp->pins[i];
+
+		pin->pin_id = be32_to_cpu(*list++);
+		pin->config = be32_to_cpu(*list++);
+		grp->pin_ids[i] = grp->pins[i].pin_id;
+
+		dev_dbg(info->dev, "%s: 0x%08lx",
+			pin_get_name_from_info(info, pin->pin_id), pin->config);
+	}
+
+	return 0;
+}
+
+static int s32v_pinctrl_parse_functions(struct device_node *np,
+					struct s32v_pinctrl_soc_info *info,
+					u32 index)
+{
+	struct device_node *child;
+	struct s32v_pmx_func *func;
+	struct s32v_pin_group *grp;
+	static u32 grp_index;
+	u32 i = 0;
+
+	dev_dbg(info->dev, "parse function(%d): %s\n", index, np->name);
+
+	func = &info->functions[index];
+
+	/* Initialise function */
+	func->name = np->name;
+	func->num_groups = of_get_child_count(np);
+	if (func->num_groups == 0) {
+		dev_err(info->dev, "no groups defined in %s\n", np->full_name);
+		return -EINVAL;
+	}
+	func->groups = devm_kzalloc(info->dev,
+				    func->num_groups * sizeof(char *),
+				    GFP_KERNEL);
+
+	for_each_child_of_node(np, child) {
+		func->groups[i] = child->name;
+		grp = &info->groups[grp_index++];
+		s32v_pinctrl_parse_groups(child, grp, info, i++);
+	}
+
+	return 0;
+}
+
+static int s32v_pinctrl_probe_dt(struct platform_device *pdev,
+				 struct s32v_pinctrl_soc_info *info)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct device_node *child;
+	u32 nfuncs = 0;
+	u32 i = 0;
+
+	if (!np)
+		return -ENODEV;
+
+	nfuncs = of_get_child_count(np);
+	if (nfuncs <= 0) {
+		dev_err(&pdev->dev, "no functions defined\n");
+		return -EINVAL;
+	}
+
+	info->nfunctions = nfuncs;
+	info->functions = devm_kzalloc(&pdev->dev,
+				       nfuncs * sizeof(struct s32v_pmx_func),
+				       GFP_KERNEL);
+	if (!info->functions)
+		return -ENOMEM;
+
+	info->ngroups = 0;
+	for_each_child_of_node(np, child)
+		info->ngroups += of_get_child_count(child);
+	info->groups = devm_kzalloc(&pdev->dev, info->ngroups *
+						sizeof(struct s32v_pin_group),
+				    GFP_KERNEL);
+	if (!info->groups)
+		return -ENOMEM;
+
+	for_each_child_of_node(np, child)
+		s32v_pinctrl_parse_functions(child, info, i++);
+
+	return 0;
+}
+
+int s32v_pinctrl_probe(struct platform_device *pdev,
+		       struct s32v_pinctrl_soc_info *info)
+{
+	struct s32v_pinctrl *ipctl;
+	struct resource *res;
+	int ret;
+
+	if (!info || !info->pins || !info->npins) {
+		dev_err(&pdev->dev, "wrong pinctrl info\n");
+		return -EINVAL;
+	}
+	info->dev = &pdev->dev;
+
+	/* Create state holders etc for this driver */
+	ipctl = devm_kzalloc(&pdev->dev, sizeof(*ipctl), GFP_KERNEL);
+	if (!ipctl)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	ipctl->base = devm_ioremap_resource(&pdev->dev, res);
+
+	if (IS_ERR(ipctl->base))
+		return PTR_ERR(ipctl->base);
+
+	s32v_pinctrl_desc.name = dev_name(&pdev->dev);
+	s32v_pinctrl_desc.pins = info->pins;
+	s32v_pinctrl_desc.npins = info->npins;
+
+	ret = s32v_pinctrl_probe_dt(pdev, info);
+	if (ret) {
+		dev_err(&pdev->dev, "fail to probe dt properties\n");
+		return ret;
+	}
+
+	ipctl->info = info;
+	ipctl->dev = info->dev;
+	platform_set_drvdata(pdev, ipctl);
+	ipctl->pctl = pinctrl_register(&s32v_pinctrl_desc, &pdev->dev, ipctl);
+	if (!ipctl->pctl) {
+		dev_err(&pdev->dev, "could not register s32 pinctrl driver\n");
+		return -EINVAL;
+	}
+
+	dev_info(&pdev->dev, "initialized s32 pinctrl driver\n");
+
+	return 0;
+}
+
+int s32v_pinctrl_remove(struct platform_device *pdev)
+{
+	struct s32v_pinctrl *ipctl = platform_get_drvdata(pdev);
+
+	pinctrl_unregister(ipctl->pctl);
+
+	return 0;
+}
diff --git a/drivers/pinctrl/freescale/pinctrl-s32v.h b/drivers/pinctrl/freescale/pinctrl-s32v.h
new file mode 100644
index 000000000..f231607bb
--- /dev/null
+++ b/drivers/pinctrl/freescale/pinctrl-s32v.h
@@ -0,0 +1,72 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+/*
+ * S32V pinmux core definitions
+ *
+ * Copyright (C) 2017 NXP
+ * Copyright (C) 2015-2016 Freescale Semiconductor, Inc.
+ * Copyright (C) 2012 Linaro Ltd.
+ *
+ * Based on pinctrl-imx.h, by Dong Aisheng <dong.aisheng@linaro.org>
+ */
+
+#ifndef __DRIVERS_PINCTRL_S32V_H
+#define __DRIVERS_PINCTRL_S32V_H
+
+struct platform_device;
+
+/**
+ * struct s32v_pin - describes a single S32V pin
+ * @pin_id: the pin_id of this pin
+ * @config: the config for this pin.
+ */
+struct s32v_pin {
+	unsigned int pin_id;
+	unsigned long config;
+};
+
+/**
+ * struct s32v_pin_group - describes an S32V pin group
+ * @name: the name of this specific pin group
+ * @npins: the number of pins in this group array, i.e. the number of
+ *	elements in .pins so we can iterate over that array
+ * @pin_ids: array of pin_ids. pinctrl forces us to maintain such an array
+ * @pins: array of pins
+ */
+struct s32v_pin_group {
+	const char *name;
+	unsigned int npins;
+	unsigned int *pin_ids;
+	struct s32v_pin *pins;
+};
+
+/**
+ * struct s32v_pmx_func - describes S32V pinmux functions
+ * @name: the name of this specific function
+ * @groups: corresponding pin groups
+ * @num_groups: the number of groups
+ */
+struct s32v_pmx_func {
+	const char *name;
+	const char **groups;
+	unsigned int num_groups;
+};
+
+struct s32v_pinctrl_soc_info {
+	struct device *dev;
+	const struct pinctrl_pin_desc *pins;
+	unsigned int npins;
+	struct s32v_pin_group *groups;
+	unsigned int ngroups;
+	struct s32v_pmx_func *functions;
+	unsigned int nfunctions;
+	unsigned int flags;
+};
+
+#define S32V_PINCTRL_PIN(pin)	PINCTRL_PIN(pin, #pin)
+#define S32V_PAD_CONFIG(idx)	(0x240 + (idx) * 4)
+#define S32V_PIN_SIZE		(8)
+
+int s32v_pinctrl_probe(struct platform_device *pdev,
+		       struct s32v_pinctrl_soc_info *info);
+int s32v_pinctrl_remove(struct platform_device *pdev);
+#endif /* __DRIVERS_PINCTRL_S32V_H */
diff --git a/drivers/pinctrl/freescale/pinctrl-s32v234.c b/drivers/pinctrl/freescale/pinctrl-s32v234.c
new file mode 100644
index 000000000..6c64f4cdc
--- /dev/null
+++ b/drivers/pinctrl/freescale/pinctrl-s32v234.c
@@ -0,0 +1,251 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * s32v234 pinctrl driver based on imx pinmux and pinconf core
+ *
+ * Copyright 2015-2016 Freescale Semiconductor, Inc.
+ * Copyright 2017, 2019 NXP
+ */
+
+#include <linux/err.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <dt-bindings/pinctrl/s32v234-pinctrl.h>
+
+#include "pinctrl-s32v.h"
+
+/* Pad names for the pinmux subsystem */
+static const struct pinctrl_pin_desc s32v234_pinctrl_pads[] = {
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PA15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PB15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PC15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PD15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PE15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PF15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PG15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PH15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PJ15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK6),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK7),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK8),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK9),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK10),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK11),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK12),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK13),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK14),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PK15),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL0),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL1),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL2),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL3),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL4),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL5),
+	S32V_PINCTRL_PIN(S32V234_MSCR_PL8),
+
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_CLK),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_CMD),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT0),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT1),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT2),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT3),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT4),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT5),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT6),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_DAT7),
+	S32V_PINCTRL_PIN(S32V234_IMCR_CAN_FD0_RXD),
+	S32V_PINCTRL_PIN(S32V234_IMCR_CAN_FD1_RXD),
+	S32V_PINCTRL_PIN(S32V234_IMCR_UART0_RXD),
+	S32V_PINCTRL_PIN(S32V234_IMCR_UART1_RXD),
+	S32V_PINCTRL_PIN(S32V234_IMCR_USDHC_WP),
+
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_ER),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_COL),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_CRS),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_DV),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_D0),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_D1),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_D2),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_D3),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_TX_CLK),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_RX_CLK),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_MDIO),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_TIMER0),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_TIMER1),
+	S32V_PINCTRL_PIN(S32V234_IMCR_Ethernet_TIMER2),
+};
+
+static struct s32v_pinctrl_soc_info s32v234_pinctrl_info = {
+	.pins = s32v234_pinctrl_pads,
+	.npins = ARRAY_SIZE(s32v234_pinctrl_pads),
+};
+
+static const struct of_device_id s32v234_pinctrl_of_match[] = {
+	{ .compatible = "fsl,s32v234-siul2", },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, s32v234_pinctrl_of_match);
+
+static int s32v234_pinctrl_probe(struct platform_device *pdev)
+{
+	return s32v_pinctrl_probe(pdev, &s32v234_pinctrl_info);
+}
+
+static struct platform_driver s32v234_pinctrl_driver = {
+	.driver = {
+		.name = "s32v234-siul2",
+		.owner = THIS_MODULE,
+		.of_match_table = s32v234_pinctrl_of_match,
+	},
+	.probe = s32v234_pinctrl_probe,
+	.remove = s32v_pinctrl_remove,
+};
+
+module_platform_driver(s32v234_pinctrl_driver);
+
+MODULE_DESCRIPTION("Freescale S32V234 pinctrl driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/imx/Kconfig b/drivers/soc/imx/Kconfig
index 05812f8ae..14a98e487 100644
--- a/drivers/soc/imx/Kconfig
+++ b/drivers/soc/imx/Kconfig
@@ -1,6 +1,8 @@
 # SPDX-License-Identifier: GPL-2.0-only
 menu "i.MX SoC drivers"
 
+source "drivers/soc/imx/mu/Kconfig"
+
 config IMX_GPCV2_PM_DOMAINS
 	bool "i.MX GPCv2 PM domains"
 	depends on ARCH_MXC || (COMPILE_TEST && OF)
@@ -8,8 +10,18 @@ config IMX_GPCV2_PM_DOMAINS
 	select PM_GENERIC_DOMAINS
 	default y if SOC_IMX7D
 
+config SOC_IMX9
+	tristate "i.MX9 SoC family support"
+	depends on ARCH_MXC || COMPILE_TEST
+	default ARCH_MXC && ARM64
+	select SOC_BUS
+	select PM_GENERIC_DOMAINS
+	help
+	  If you say yes here you get support for the NXP i.MX9 family
+	  support.
+
 config SOC_IMX8M
-	bool "i.MX8M SoC family support"
+	tristate "i.MX8M SoC family support"
 	depends on ARCH_MXC || COMPILE_TEST
 	default ARCH_MXC && ARM64
 	select SOC_BUS
@@ -19,4 +31,57 @@ config SOC_IMX8M
 	  support, it will provide the SoC info like SoC family,
 	  ID and revision etc.
 
+config SOC_IMX9
+	tristate "i.MX9 SoC family support"
+	depends on ARCH_MXC || COMPILE_TEST
+	default ARCH_MXC && ARM64
+	select SOC_BUS
+	select ARM_GIC_V3 if ARCH_MXC && ARCH_MULTI_V7
+	help
+	  If you say yes here you get support for the NXP i.MX9 family
+	  support, it will provide the SoC info like SoC family,
+	  ID and revision etc.
+
+config IMX8M_BUSFREQ
+	tristate "i.MX8M busfreq"
+	depends on SOC_IMX8M
+	default ARCH_MXC
+
+config SECVIO_SC
+	tristate "NXP SC secvio support"
+	depends on IMX_SCU
+	default y
+	help
+	   If you say yes here you get support for the NXP SNVS security
+	   violation module. It includes the possibility to read information
+	   related to security violations and tampers. It also gives the
+	   possibility to register user callbacks when a security violation
+	   occurs.
+
+config IMX8M_PM_DOMAINS
+	tristate "i.MX8M PM domains"
+	default ARCH_MXC
+	depends on ARCH_MXC || (COMPILE_TEST && OF)
+	depends on PM
+	select PM_GENERIC_DOMAINS
+
+config RPMSG_LIFE_CYCLE
+	tristate "i.MX8ULP Rpmsg Life Cycle Support"
+	depends on ARCH_MXC || COMPILE_TEST
+	depends on RPMSG
+	default ARCH_MXC && ARM64
+	help
+	  If you say yes here you get supoort for the rpmsg life cycle support on
+	  i.MX8ULP for low power mode state coordination between A core & M core to
+	  make sure A core can be put into Low power mode without risk by sending
+	  notify to M core.
+
+config IMX8ULP_LPM_CTRL
+	tristate "i.MX8ULP DDR Low Power Control support"
+	depends on ARCH_MXC || COMPILE_TEST
+	default ARCH_MXC && ARM64
+	help
+	  If you say yes here you get supoort for DDR frequency scaling support on
+	  i.MX8ULP for scaling the DDR frequency based on user case. The DDR frequency
+	  need to be switched manually by user.
 endmenu
diff --git a/drivers/soc/imx/Makefile b/drivers/soc/imx/Makefile
index 078dc918f..525b9eac2 100644
--- a/drivers/soc/imx/Makefile
+++ b/drivers/soc/imx/Makefile
@@ -5,3 +5,11 @@ endif
 obj-$(CONFIG_HAVE_IMX_GPC) += gpc.o
 obj-$(CONFIG_IMX_GPCV2_PM_DOMAINS) += gpcv2.o
 obj-$(CONFIG_SOC_IMX8M) += soc-imx8m.o
+obj-$(CONFIG_SOC_IMX9) += soc-imx9.o
+obj-$(CONFIG_IMX8M_BUSFREQ) += busfreq-imx8mq.o
+obj-$(CONFIG_SOC_IMX_MU) += mu/
+obj-${CONFIG_SECVIO_SC} += secvio/
+obj-$(CONFIG_IMX8M_PM_DOMAINS) += imx8m_pm_domains.o
+obj-$(CONFIG_RPMSG_LIFE_CYCLE) += rpmsg_life_cycle.o
+obj-$(CONFIG_IMX8ULP_LPM_CTRL) += imx8ulp_lpm.o
+obj-$(CONFIG_SOC_IMX9) += imx93-pd.o imx93-blk-ctrl.o
diff --git a/drivers/soc/imx/busfreq-imx8mq.c b/drivers/soc/imx/busfreq-imx8mq.c
new file mode 100644
index 000000000..5e3696228
--- /dev/null
+++ b/drivers/soc/imx/busfreq-imx8mq.c
@@ -0,0 +1,670 @@
+/*
+ * Copyright 2017-2018 NXP
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/arm-smccc.h>
+#include <linux/busfreq-imx.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/cpumask.h>
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/mutex.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/proc_fs.h>
+#include <linux/reboot.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/smp.h>
+#include <linux/suspend.h>
+#include <linux/sys_soc.h>
+
+#define FSL_SIP_DDR_DVFS                0xc2000004
+
+#define HIGH_FREQ_3200MTS	0x0
+#define AUDIO_FREQ_400MTS	0x1
+#define LOW_BUS_FREQ_100MTS	0x2
+#define LOW_BUS_FREQ_667MTS	0x1
+#define WAIT_BUS_FREQ_DONE	0xf
+#define DLL_ON_DRATE		667
+
+static struct device *busfreq_dev;
+static int low_bus_freq_mode;
+static int audio_bus_freq_mode;
+static int high_bus_freq_mode;
+static int bus_freq_scaling_initialized;
+static int bus_freq_scaling_is_active;
+static int high_bus_count, audio_bus_count, low_bus_count;
+static int cur_bus_freq_mode;
+static int busfreq_suspended;
+static bool cancel_reduce_bus_freq;
+
+static unsigned int fsp_table[4];
+static unsigned long origin_noc_rate;
+static int low_bus_mode_fsp_index;
+/* no bypass or dll off mode support if lowest fsp > 667mts */
+static bool bypass_support = true;
+
+static struct clk *dram_pll_clk;
+static struct clk *dram_pll;
+static struct clk *sys1_pll_800m;
+static struct clk *sys1_pll_400m;
+static struct clk *sys1_pll_100m;
+static struct clk *sys1_pll_40m;
+static struct clk *dram_alt_src;
+static struct clk *dram_alt_root;
+static struct clk *dram_core_clk;
+static struct clk *dram_apb_src;
+static struct clk *dram_apb_pre_div;
+static struct clk *noc_div;
+static struct clk *main_axi_src;
+static struct clk *ahb_div;
+static struct clk *osc_25m;
+static struct clk *sys2_pll_333m;
+
+static struct delayed_work low_bus_freq_handler;
+static struct delayed_work bus_freq_daemon;
+
+DEFINE_MUTEX(bus_freq_mutex);
+
+static void update_bus_freq(int target_freq)
+{
+	struct arm_smccc_res res;
+	u32 online_cpus = 0;
+	int cpu = 0;
+
+	local_irq_disable();
+
+	for_each_online_cpu(cpu) {
+		online_cpus |= (1 << (cpu * 8));
+	}
+	/* change the ddr freqency */
+	arm_smccc_smc(FSL_SIP_DDR_DVFS, target_freq, online_cpus,
+		0, 0, 0, 0, 0, &res);
+
+	local_irq_enable();
+}
+
+static void reduce_bus_freq(void)
+{
+	u32 rate;
+
+	high_bus_freq_mode = 0;
+
+	/*
+	 * below piece of code has some redundant part, keep
+	 * it at present, we may need update the audio freq
+	 * in the future if needed.
+	 */
+	if (audio_bus_count) {
+		if (cur_bus_freq_mode == BUS_FREQ_HIGH) {
+			if (bypass_support) {
+				/* prepare the necessary clk before frequency change */
+				clk_prepare_enable(sys1_pll_40m);
+				clk_prepare_enable(dram_alt_root);
+				clk_prepare_enable(sys1_pll_100m);
+
+				update_bus_freq(low_bus_mode_fsp_index);
+
+				clk_set_parent(dram_alt_src, sys1_pll_100m);
+				clk_set_parent(dram_core_clk, dram_alt_root);
+				clk_set_parent(dram_apb_src, sys1_pll_40m);
+				clk_set_rate(dram_apb_pre_div, 20000000);
+				clk_disable_unprepare(sys1_pll_100m);
+				clk_disable_unprepare(sys1_pll_40m);
+				clk_disable_unprepare(dram_alt_root);
+			} else {
+				update_bus_freq(low_bus_mode_fsp_index);
+				/*
+				 * the dram_apb and dram_core clk rate is changed
+				 * in ATF side, below two lines of code is just used
+				 * to update the clock tree info in kernel side.
+				 */
+				clk_set_rate(dram_apb_pre_div, 160000000);
+				clk_get_rate(dram_pll);
+			}
+			/* change the NOC rate */
+			if (of_machine_is_compatible("fsl,imx8mq"))
+				clk_set_rate(noc_div, origin_noc_rate / 8);
+			else
+				clk_set_rate(noc_div, origin_noc_rate / 5);
+
+			rate = clk_get_rate(ahb_div);
+			if (rate == 0) {
+				WARN_ON(1);
+				return;
+			}
+			clk_set_rate(ahb_div, rate / 6);
+			clk_set_parent(main_axi_src, osc_25m);
+		}
+
+		low_bus_freq_mode = 0;
+		audio_bus_freq_mode = 1;
+		cur_bus_freq_mode = BUS_FREQ_AUDIO;
+	} else {
+		if (cur_bus_freq_mode == BUS_FREQ_HIGH) {
+			if (bypass_support) {
+				/* prepare the necessary clk before frequency change */
+				clk_prepare_enable(sys1_pll_40m);
+				clk_prepare_enable(dram_alt_root);
+				clk_prepare_enable(sys1_pll_100m);
+
+				update_bus_freq(low_bus_mode_fsp_index);
+
+				clk_set_parent(dram_alt_src, sys1_pll_100m);
+				clk_set_parent(dram_core_clk, dram_alt_root);
+				clk_set_parent(dram_apb_src, sys1_pll_40m);
+				clk_set_rate(dram_apb_pre_div, 20000000);
+				clk_disable_unprepare(sys1_pll_100m);
+				clk_disable_unprepare(sys1_pll_40m);
+				clk_disable_unprepare(dram_alt_root);
+			} else {
+				update_bus_freq(low_bus_mode_fsp_index);
+				/*
+				 * the dram_apb and dram_core clk rate is changed
+				 * in ATF side, below two lines of code is just used
+				 * to update the clock tree info in kernel side.
+				 */
+				clk_set_rate(dram_apb_pre_div, 160000000);
+				clk_get_rate(dram_pll);
+			}
+
+			/* change the NOC rate */
+			if (of_machine_is_compatible("fsl,imx8mq"))
+				clk_set_rate(noc_div, origin_noc_rate / 8);
+			else
+				clk_set_rate(noc_div, origin_noc_rate / 5);
+
+			rate = clk_get_rate(ahb_div);
+			if (rate == 0) {
+				WARN_ON(1);
+				return;
+			}
+			clk_set_rate(ahb_div, rate / 6);
+			clk_set_parent(main_axi_src, osc_25m);
+		}
+
+		low_bus_freq_mode = 1;
+		audio_bus_freq_mode = 0;
+		cur_bus_freq_mode = BUS_FREQ_LOW;
+	}
+
+	if (audio_bus_freq_mode)
+		printk(KERN_DEBUG "ddrc freq set to audio bus mode\n");
+	if (low_bus_freq_mode)
+		printk(KERN_DEBUG "ddrc freq set to low bus mode\n");
+}
+
+static void reduce_bus_freq_handler(struct work_struct *work)
+{
+	mutex_lock(&bus_freq_mutex);
+
+	if (!cancel_reduce_bus_freq)
+		reduce_bus_freq();
+
+	mutex_unlock(&bus_freq_mutex);
+}
+
+static int set_low_bus_freq(void)
+{
+	if (busfreq_suspended)
+		return 0;
+
+	if (!bus_freq_scaling_initialized || !bus_freq_scaling_is_active)
+		return 0;
+
+	cancel_reduce_bus_freq = false;
+
+	/*
+	 * check to see if we need to got from low bus
+	 * freq mode to audio bus freq mode.
+	 * If so, the change needs to be done immediately.
+	 */
+	if (audio_bus_count && low_bus_freq_mode)
+		reduce_bus_freq();
+	else
+		schedule_delayed_work(&low_bus_freq_handler,
+					usecs_to_jiffies(1000000));
+
+	return 0;
+}
+
+static inline void cancel_low_bus_freq_handler(void)
+{
+	cancel_delayed_work(&low_bus_freq_handler);
+	cancel_reduce_bus_freq = true;
+}
+
+static int set_high_bus_freq(int high_bus_freq)
+{
+	if (bus_freq_scaling_initialized || bus_freq_scaling_is_active)
+		cancel_low_bus_freq_handler();
+
+	if (busfreq_suspended)
+		return 0;
+
+	if (!bus_freq_scaling_initialized || !bus_freq_scaling_is_active)
+		return 0;
+
+	if (high_bus_freq_mode)
+		return 0;
+
+	if (bypass_support) {
+		/*  enable the clks needed in frequency */
+		clk_prepare_enable(sys1_pll_800m);
+		clk_prepare_enable(dram_pll_clk);
+
+		/* switch the DDR freqeuncy */
+		update_bus_freq(HIGH_FREQ_3200MTS);
+
+		/* correct the clock tree info */
+		clk_set_parent(dram_apb_src, sys1_pll_800m);
+		clk_set_rate(dram_apb_pre_div, 160000000);
+		clk_set_parent(dram_core_clk, dram_pll_clk);
+		clk_disable_unprepare(sys1_pll_800m);
+		clk_disable_unprepare(dram_pll_clk);
+	} else {
+		/* switch the DDR freqeuncy */
+		update_bus_freq(HIGH_FREQ_3200MTS);
+
+		clk_set_rate(dram_apb_pre_div, 200000000);
+		clk_get_rate(dram_pll);
+	}
+
+	clk_set_rate(noc_div, origin_noc_rate);
+	clk_set_rate(ahb_div, 133333333);
+	clk_set_parent(main_axi_src, sys2_pll_333m);
+
+	high_bus_freq_mode = 1;
+	audio_bus_freq_mode = 0;
+	low_bus_freq_mode = 0;
+	cur_bus_freq_mode = BUS_FREQ_HIGH;
+
+	if (high_bus_freq_mode)
+		printk(KERN_DEBUG "ddrc freq set to high bus mode\n");
+
+	return 0;
+}
+
+void request_bus_freq(enum bus_freq_mode mode)
+{
+	mutex_lock(&bus_freq_mutex);
+
+	if (mode == BUS_FREQ_HIGH)
+		high_bus_count++;
+	else if (mode == BUS_FREQ_AUDIO)
+		audio_bus_count++;
+	else if (mode == BUS_FREQ_LOW)
+		low_bus_count++;
+
+	if (busfreq_suspended || !bus_freq_scaling_initialized ||
+		!bus_freq_scaling_is_active) {
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	cancel_low_bus_freq_handler();
+
+	if ((mode == BUS_FREQ_HIGH) && (!high_bus_freq_mode)) {
+		set_high_bus_freq(1);
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	if ((mode == BUS_FREQ_AUDIO) && (!high_bus_freq_mode) &&
+		 (!audio_bus_freq_mode)) {
+		set_low_bus_freq();
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	mutex_unlock(&bus_freq_mutex);
+}
+EXPORT_SYMBOL(request_bus_freq);
+
+void release_bus_freq(enum bus_freq_mode mode)
+{
+	mutex_lock(&bus_freq_mutex);
+	if (mode == BUS_FREQ_HIGH) {
+		if (high_bus_count == 0) {
+			dev_err(busfreq_dev, "high bus count mismatch!\n");
+			dump_stack();
+			mutex_unlock(&bus_freq_mutex);
+			return;
+		}
+		high_bus_count--;
+	} else if (mode == BUS_FREQ_AUDIO) {
+		if (audio_bus_count == 0) {
+			dev_err(busfreq_dev, "audio bus count mismatch!\n");
+			dump_stack();
+			mutex_unlock(&bus_freq_mutex);
+			return;
+		}
+		audio_bus_count--;
+	} else if (mode == BUS_FREQ_LOW) {
+		if (low_bus_count == 0) {
+			dev_err(busfreq_dev, "low bus count mismatch!\n");
+			dump_stack();
+			mutex_unlock(&bus_freq_mutex);
+			return;
+		}
+		low_bus_count--;
+	}
+
+	if (busfreq_suspended || !bus_freq_scaling_initialized ||
+		!bus_freq_scaling_is_active) {
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	if ((!audio_bus_freq_mode) && (high_bus_count == 0) &&
+		(audio_bus_count != 0)) {
+		set_low_bus_freq();
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	if ((!low_bus_freq_mode) && (high_bus_count == 0) &&
+		(audio_bus_count == 0)) {
+		set_low_bus_freq();
+		mutex_unlock(&bus_freq_mutex);
+		return;
+	}
+
+	mutex_unlock(&bus_freq_mutex);
+}
+EXPORT_SYMBOL(release_bus_freq);
+
+int get_bus_freq_mode(void)
+{
+	return cur_bus_freq_mode;
+}
+EXPORT_SYMBOL(get_bus_freq_mode);
+
+static void bus_freq_daemon_handler(struct work_struct *work)
+{
+	mutex_lock(&bus_freq_mutex);
+	if ((!low_bus_freq_mode) && (high_bus_count == 0) &&
+		(audio_bus_count == 0))
+		set_low_bus_freq();
+	mutex_unlock(&bus_freq_mutex);
+}
+
+static ssize_t bus_freq_scaling_enable_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	if (bus_freq_scaling_is_active)
+		return sprintf(buf, "Bus frequency scaling is enabled\n");
+	else
+		return sprintf(buf, "Bus frequency scaling is disabled\n");
+}
+
+static ssize_t bus_freq_scaling_enable_store(struct device *dev,
+				struct device_attribute *attr,
+				const char *buf, size_t size)
+{
+	if (strncmp(buf, "1", 1) == 0) {
+		bus_freq_scaling_is_active = 1;
+		set_high_bus_freq(1);
+		/*
+		 * We set bus freq to higher at the beginning,
+		 * so we use this daemon thread to make sure system
+		 * can enter low bus mode if there is no high bus request pending
+		 */
+		schedule_delayed_work(&bus_freq_daemon,
+			usecs_to_jiffies(5000000));
+	} else if (strncmp(buf, "0", 1) == 0) {
+		if (bus_freq_scaling_is_active)
+			set_high_bus_freq(1);
+		bus_freq_scaling_is_active = 0;
+	}
+	return size;
+}
+
+static int bus_freq_pm_notify(struct notifier_block *nb, unsigned long event,
+	void *dummy)
+{
+	mutex_lock(&bus_freq_mutex);
+
+	if (event == PM_SUSPEND_PREPARE) {
+		high_bus_count++;
+		set_high_bus_freq(1);
+		busfreq_suspended = 1;
+	} else if (event == PM_POST_SUSPEND) {
+		busfreq_suspended = 0;
+		high_bus_count--;
+		schedule_delayed_work(&bus_freq_daemon,
+			usecs_to_jiffies(5000000));
+	}
+
+	mutex_unlock(&bus_freq_mutex);
+
+	return NOTIFY_OK;
+}
+
+static int busfreq_reboot_notifier_event(struct notifier_block *this,
+						 unsigned long event, void *ptr)
+{
+	/* System is rebooting. Set the system into high_bus_freq_mode. */
+	request_bus_freq(BUS_FREQ_HIGH);
+
+	return 0;
+}
+
+static struct notifier_block imx_bus_freq_pm_notifier = {
+	.notifier_call = bus_freq_pm_notify,
+};
+
+static struct notifier_block imx_busfreq_reboot_notifier = {
+	.notifier_call = busfreq_reboot_notifier_event,
+};
+
+static DEVICE_ATTR(enable, 0644, bus_freq_scaling_enable_show,
+			bus_freq_scaling_enable_store);
+
+static int imx8mq_init_busfreq_clk(struct platform_device *pdev)
+{
+	dram_pll_clk = devm_clk_get(&pdev->dev, "dram_pll");
+	sys1_pll_800m = devm_clk_get(&pdev->dev, "sys1_pll_800m");
+	sys1_pll_400m = devm_clk_get(&pdev->dev, "sys1_pll_400m");
+	sys1_pll_100m = devm_clk_get(&pdev->dev, "sys1_pll_100m");
+	sys1_pll_40m = devm_clk_get(&pdev->dev, "sys1_pll_40m");
+	dram_alt_src = devm_clk_get(&pdev->dev, "dram_alt_src");
+	dram_alt_root = devm_clk_get(&pdev->dev, "dram_alt_root");
+	dram_core_clk = devm_clk_get(&pdev->dev, "dram_core");
+	dram_apb_src = devm_clk_get(&pdev->dev, "dram_apb_src");
+	dram_apb_pre_div = devm_clk_get(&pdev->dev, "dram_apb_pre_div");
+	noc_div = devm_clk_get(&pdev->dev, "noc_div");
+	ahb_div = devm_clk_get(&pdev->dev, "ahb_div");
+	main_axi_src = devm_clk_get(&pdev->dev, "main_axi_src");
+	osc_25m = devm_clk_get(&pdev->dev, "osc_25m");
+	sys2_pll_333m = devm_clk_get(&pdev->dev, "sys2_pll_333m");
+
+	if (IS_ERR(dram_pll_clk) || IS_ERR(sys1_pll_400m) || IS_ERR(sys1_pll_100m) ||
+	    IS_ERR(sys1_pll_40m) || IS_ERR(dram_alt_src) || IS_ERR(dram_alt_root) ||
+	    IS_ERR(dram_core_clk) || IS_ERR(dram_apb_src) || IS_ERR(dram_apb_pre_div)
+	    || IS_ERR(noc_div) || IS_ERR(main_axi_src) || IS_ERR(ahb_div)
+	    || IS_ERR(osc_25m) || IS_ERR(sys2_pll_333m)) {
+		dev_err(&pdev->dev, "failed to get busfreq clk\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int imx8mm_init_busfreq_clk(struct platform_device *pdev)
+{
+	dram_pll = devm_clk_get(&pdev->dev, "dram_pll_div");
+	dram_pll_clk = devm_clk_get(&pdev->dev, "dram_pll");
+	dram_alt_src = devm_clk_get(&pdev->dev, "dram_alt_src");
+	dram_alt_root = devm_clk_get(&pdev->dev, "dram_alt_root");
+	dram_core_clk = devm_clk_get(&pdev->dev, "dram_core");
+	dram_apb_src = devm_clk_get(&pdev->dev, "dram_apb_src");
+	dram_apb_pre_div = devm_clk_get(&pdev->dev, "dram_apb_pre_div");
+	sys1_pll_800m = devm_clk_get(&pdev->dev, "sys_pll1_800m");
+	sys1_pll_100m = devm_clk_get(&pdev->dev, "sys_pll1_100m");
+	sys1_pll_40m = devm_clk_get(&pdev->dev, "sys_pll1_40m");
+	noc_div = devm_clk_get(&pdev->dev, "noc_div");
+	ahb_div = devm_clk_get(&pdev->dev, "ahb_div");
+	main_axi_src = devm_clk_get(&pdev->dev, "main_axi_src");
+	osc_25m = devm_clk_get(&pdev->dev, "osc_24m");
+	sys2_pll_333m = devm_clk_get(&pdev->dev, "sys_pll2_333m");
+
+	if (IS_ERR(dram_pll_clk) || IS_ERR(dram_alt_src) || IS_ERR(dram_alt_root) ||
+	    IS_ERR(dram_core_clk) || IS_ERR(dram_apb_src) || IS_ERR(dram_apb_pre_div) ||
+	    IS_ERR(sys1_pll_800m) || IS_ERR(sys1_pll_100m) || IS_ERR(sys1_pll_40m) ||
+	    IS_ERR(osc_25m) || IS_ERR(noc_div) || IS_ERR(main_axi_src) || IS_ERR(ahb_div) ||
+	    IS_ERR(sys2_pll_333m)) {
+		dev_err(&pdev->dev, "failed to get busfreq clk\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/*!
+ * This is the probe routine for the bus frequency driver.
+ *
+ * @param   pdev   The platform device structure
+ *
+ * @return         The function returns 0 on success
+ *
+ */
+
+static int busfreq_probe(struct platform_device *pdev)
+{
+	int i, err;
+	struct arm_smccc_res res;
+
+	busfreq_dev = &pdev->dev;
+
+	/* get the clock for DDRC */
+	if (of_machine_is_compatible("fsl,imx8mq"))
+		err = imx8mq_init_busfreq_clk(pdev);
+	else
+		err = imx8mm_init_busfreq_clk(pdev);
+
+	if (err) {
+		dev_err(busfreq_dev, "init clk failed\n");
+		return err;
+	}
+
+	origin_noc_rate = clk_get_rate(noc_div);
+	if (origin_noc_rate == 0) {
+		WARN_ON(1);
+		return -EINVAL;
+	}
+
+	/*
+	 * Get the supported frequency, normally the lowest frequency point
+	 * is used for low bus & audio bus mode.
+	 */
+	for (i = 0; i < 4; i++) {
+		arm_smccc_smc(FSL_SIP_DDR_DVFS, 0x11, i, 0, 0, 0, 0, 0, &res);
+		err = res.a0;
+		if (err < 0)
+			return -EINVAL;
+
+		fsp_table[i] = res.a0;
+	}
+
+	/* get the lowest fsp index */
+	for (i = 0; i < 4; i++)
+		if (fsp_table[i] == 0)
+			break;
+
+	low_bus_mode_fsp_index = i - 1;
+
+	/*
+	 * if lowest fsp data rate higher than 666mts, then no dll off mode or
+	 * bypass mode support.
+	 */
+	if (fsp_table[low_bus_mode_fsp_index] >= DLL_ON_DRATE)
+		bypass_support = false;
+
+	/* create the sysfs file */
+	err = sysfs_create_file(&busfreq_dev->kobj, &dev_attr_enable.attr);
+	if (err) {
+		dev_err(busfreq_dev,
+			"Unable to register sysdev entry for BUSFREQ");
+		return err;
+	}
+
+	high_bus_freq_mode = 1;
+	low_bus_freq_mode = 0;
+	audio_bus_freq_mode = 0;
+	cur_bus_freq_mode = BUS_FREQ_HIGH;
+
+	bus_freq_scaling_is_active = 1;
+	bus_freq_scaling_initialized = 1;
+
+	INIT_DELAYED_WORK(&low_bus_freq_handler, reduce_bus_freq_handler);
+	INIT_DELAYED_WORK(&bus_freq_daemon, bus_freq_daemon_handler);
+	register_pm_notifier(&imx_bus_freq_pm_notifier);
+	register_reboot_notifier(&imx_busfreq_reboot_notifier);
+
+	/* enter low bus mode if no high speed device enabled */
+	schedule_delayed_work(&bus_freq_daemon, msecs_to_jiffies(10000));
+
+	return 0;
+}
+
+static const struct of_device_id imx_busfreq_ids[] = {
+	{ .compatible = "fsl,imx_busfreq", },
+	{ /*sentinel */}
+};
+
+static struct platform_driver busfreq_driver = {
+	.driver = {
+		.name = "imx_busfreq",
+		.owner = THIS_MODULE,
+		.of_match_table = imx_busfreq_ids,
+		},
+	.probe = busfreq_probe,
+};
+
+/*!
+ * Initialise the busfreq_driver.
+ *
+ * @return The function always returns 0.
+ */
+static int __init busfreq_init(void)
+{
+	if (platform_driver_register(&busfreq_driver) != 0)
+		return -ENODEV;
+
+	printk(KERN_INFO "Bus freq driver module loaded\n");
+
+	return 0;
+}
+
+static void __exit busfreq_cleanup(void)
+{
+	sysfs_remove_file(&busfreq_dev->kobj, &dev_attr_enable.attr);
+
+	/* Unregister the device structure */
+	platform_driver_unregister(&busfreq_driver);
+	bus_freq_scaling_initialized = 0;
+}
+
+module_init(busfreq_init);
+module_exit(busfreq_cleanup);
+
+MODULE_AUTHOR("NXP Semiconductor, Inc.");
+MODULE_DESCRIPTION("Busfreq driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/soc/imx/gpc.c b/drivers/soc/imx/gpc.c
index 90a8b2c06..09a170256 100644
--- a/drivers/soc/imx/gpc.c
+++ b/drivers/soc/imx/gpc.c
@@ -39,6 +39,11 @@
 
 #define PGC_DOMAIN_FLAG_NO_PD		BIT(0)
 
+#define GPC_PGC_DOMAIN_ARM	0
+#define GPC_PGC_DOMAIN_PU	1
+#define GPC_PGC_DOMAIN_DISPLAY	2
+#define GPC_PGC_DOMAIN_PCI	3
+
 struct imx_pm_domain {
 	struct generic_pm_domain base;
 	struct regmap *regmap;
@@ -176,6 +181,8 @@ static int imx_pgc_parse_dt(struct device *dev, struct imx_pm_domain *domain)
 	return imx_pgc_get_clocks(dev, domain);
 }
 
+static void imx_gpc_handle_ldobypass(struct platform_device *pdev);
+
 static int imx_pgc_power_domain_probe(struct platform_device *pdev)
 {
 	struct imx_pm_domain *domain = pdev->dev.platform_data;
@@ -202,6 +209,10 @@ static int imx_pgc_power_domain_probe(struct platform_device *pdev)
 
 	device_link_add(dev, dev->parent, DL_FLAG_AUTOREMOVE_CONSUMER);
 
+	/* Mark PU regulator as bypass */
+	if (pdev->id == GPC_PGC_DOMAIN_PU)
+		imx_gpc_handle_ldobypass(pdev);
+
 	return 0;
 
 genpd_err:
@@ -239,11 +250,6 @@ static struct platform_driver imx_pgc_power_domain_driver = {
 };
 builtin_platform_driver(imx_pgc_power_domain_driver)
 
-#define GPC_PGC_DOMAIN_ARM	0
-#define GPC_PGC_DOMAIN_PU	1
-#define GPC_PGC_DOMAIN_DISPLAY	2
-#define GPC_PGC_DOMAIN_PCI	3
-
 static struct genpd_power_state imx6_pm_domain_pu_state = {
 	.power_off_latency_ns = 25000,
 	.power_on_latency_ns = 2000000,
@@ -401,6 +407,22 @@ static int imx_gpc_old_dt_init(struct device *dev, struct regmap *regmap,
 	return ret;
 }
 
+static void imx_gpc_handle_ldobypass(struct platform_device *pdev)
+{
+	struct imx_pm_domain *domain = pdev->dev.platform_data;
+	struct regulator *pu_reg = domain->supply;
+	u32 bypass = 0;
+	int ret;
+
+	ret = of_property_read_u32(pdev->dev.parent->of_node, "fsl,ldo-bypass", &bypass);
+	if (ret && ret != -EINVAL)
+		dev_warn(pdev->dev.parent, "failed to read fsl,ldo-bypass property: %d\n", ret);
+
+	/* We only bypass pu since arm and soc has been set in u-boot */
+	if (pu_reg && bypass)
+		regulator_allow_bypass(pu_reg, true);
+}
+
 static int imx_gpc_probe(struct platform_device *pdev)
 {
 	const struct of_device_id *of_id =
@@ -455,6 +477,8 @@ static int imx_gpc_probe(struct platform_device *pdev)
 					  of_id_data->num_domains);
 		if (ret)
 			return ret;
+
+		imx_gpc_handle_ldobypass(pdev);
 	} else {
 		struct imx_pm_domain *domain;
 		struct platform_device *pd_pdev;
diff --git a/drivers/soc/imx/gpcv2.c b/drivers/soc/imx/gpcv2.c
index b4aa28420..db7e7fc32 100644
--- a/drivers/soc/imx/gpcv2.c
+++ b/drivers/soc/imx/gpcv2.c
@@ -12,15 +12,11 @@
 #include <linux/of_device.h>
 #include <linux/platform_device.h>
 #include <linux/pm_domain.h>
-#include <linux/pm_runtime.h>
 #include <linux/regmap.h>
 #include <linux/regulator/consumer.h>
-#include <linux/reset.h>
 #include <linux/sizes.h>
 #include <dt-bindings/power/imx7-power.h>
 #include <dt-bindings/power/imx8mq-power.h>
-#include <dt-bindings/power/imx8mm-power.h>
-#include <dt-bindings/power/imx8mn-power.h>
 
 #define GPC_LPCR_A_CORE_BSC			0x000
 
@@ -46,25 +42,6 @@
 #define IMX8M_PCIE1_A53_DOMAIN			BIT(3)
 #define IMX8M_MIPI_A53_DOMAIN			BIT(2)
 
-#define IMX8MM_VPUH1_A53_DOMAIN			BIT(15)
-#define IMX8MM_VPUG2_A53_DOMAIN			BIT(14)
-#define IMX8MM_VPUG1_A53_DOMAIN			BIT(13)
-#define IMX8MM_DISPMIX_A53_DOMAIN		BIT(12)
-#define IMX8MM_VPUMIX_A53_DOMAIN		BIT(10)
-#define IMX8MM_GPUMIX_A53_DOMAIN		BIT(9)
-#define IMX8MM_GPU_A53_DOMAIN			(BIT(8) | BIT(11))
-#define IMX8MM_DDR1_A53_DOMAIN			BIT(7)
-#define IMX8MM_OTG2_A53_DOMAIN			BIT(5)
-#define IMX8MM_OTG1_A53_DOMAIN			BIT(4)
-#define IMX8MM_PCIE_A53_DOMAIN			BIT(3)
-#define IMX8MM_MIPI_A53_DOMAIN			BIT(2)
-
-#define IMX8MN_DISPMIX_A53_DOMAIN		BIT(12)
-#define IMX8MN_GPUMIX_A53_DOMAIN		BIT(9)
-#define IMX8MN_DDR1_A53_DOMAIN		BIT(7)
-#define IMX8MN_OTG1_A53_DOMAIN		BIT(4)
-#define IMX8MN_MIPI_A53_DOMAIN		BIT(2)
-
 #define GPC_PU_PGC_SW_PUP_REQ		0x0f8
 #define GPC_PU_PGC_SW_PDN_REQ		0x104
 
@@ -88,55 +65,14 @@
 #define IMX8M_PCIE1_SW_Pxx_REQ			BIT(1)
 #define IMX8M_MIPI_SW_Pxx_REQ			BIT(0)
 
-#define IMX8MM_VPUH1_SW_Pxx_REQ			BIT(13)
-#define IMX8MM_VPUG2_SW_Pxx_REQ			BIT(12)
-#define IMX8MM_VPUG1_SW_Pxx_REQ			BIT(11)
-#define IMX8MM_DISPMIX_SW_Pxx_REQ		BIT(10)
-#define IMX8MM_VPUMIX_SW_Pxx_REQ		BIT(8)
-#define IMX8MM_GPUMIX_SW_Pxx_REQ		BIT(7)
-#define IMX8MM_GPU_SW_Pxx_REQ			(BIT(6) | BIT(9))
-#define IMX8MM_DDR1_SW_Pxx_REQ			BIT(5)
-#define IMX8MM_OTG2_SW_Pxx_REQ			BIT(3)
-#define IMX8MM_OTG1_SW_Pxx_REQ			BIT(2)
-#define IMX8MM_PCIE_SW_Pxx_REQ			BIT(1)
-#define IMX8MM_MIPI_SW_Pxx_REQ			BIT(0)
-
-#define IMX8MN_DISPMIX_SW_Pxx_REQ		BIT(10)
-#define IMX8MN_GPUMIX_SW_Pxx_REQ		BIT(7)
-#define IMX8MN_DDR1_SW_Pxx_REQ		BIT(5)
-#define IMX8MN_OTG1_SW_Pxx_REQ		BIT(2)
-#define IMX8MN_MIPI_SW_Pxx_REQ		BIT(0)
-
 #define GPC_M4_PU_PDN_FLG		0x1bc
 
 #define GPC_PU_PWRHSK			0x1fc
 
-#define IMX8M_GPU_HSK_PWRDNACKN			BIT(26)
-#define IMX8M_VPU_HSK_PWRDNACKN			BIT(25)
-#define IMX8M_DISP_HSK_PWRDNACKN		BIT(24)
 #define IMX8M_GPU_HSK_PWRDNREQN			BIT(6)
 #define IMX8M_VPU_HSK_PWRDNREQN			BIT(5)
 #define IMX8M_DISP_HSK_PWRDNREQN		BIT(4)
 
-
-#define IMX8MM_GPUMIX_HSK_PWRDNACKN		BIT(29)
-#define IMX8MM_GPU_HSK_PWRDNACKN		(BIT(27) | BIT(28))
-#define IMX8MM_VPUMIX_HSK_PWRDNACKN		BIT(26)
-#define IMX8MM_DISPMIX_HSK_PWRDNACKN		BIT(25)
-#define IMX8MM_HSIO_HSK_PWRDNACKN		(BIT(23) | BIT(24))
-#define IMX8MM_GPUMIX_HSK_PWRDNREQN		BIT(11)
-#define IMX8MM_GPU_HSK_PWRDNREQN		(BIT(9) | BIT(10))
-#define IMX8MM_VPUMIX_HSK_PWRDNREQN		BIT(8)
-#define IMX8MM_DISPMIX_HSK_PWRDNREQN		BIT(7)
-#define IMX8MM_HSIO_HSK_PWRDNREQN		(BIT(5) | BIT(6))
-
-#define IMX8MN_GPUMIX_HSK_PWRDNACKN		(BIT(29) | BIT(27))
-#define IMX8MN_DISPMIX_HSK_PWRDNACKN		BIT(25)
-#define IMX8MN_HSIO_HSK_PWRDNACKN		BIT(23)
-#define IMX8MN_GPUMIX_HSK_PWRDNREQN		(BIT(11) | BIT(9))
-#define IMX8MN_DISPMIX_HSK_PWRDNREQN		BIT(7)
-#define IMX8MN_HSIO_HSK_PWRDNREQN		BIT(5)
-
 /*
  * The PGC offset values in Reference Manual
  * (Rev. 1, 01/2018 and the older ones) GPC chapter's
@@ -159,37 +95,18 @@
 #define IMX8M_PGC_MIPI_CSI2		28
 #define IMX8M_PGC_PCIE2			29
 
-#define IMX8MM_PGC_MIPI			16
-#define IMX8MM_PGC_PCIE			17
-#define IMX8MM_PGC_OTG1			18
-#define IMX8MM_PGC_OTG2			19
-#define IMX8MM_PGC_DDR1			21
-#define IMX8MM_PGC_GPU2D		22
-#define IMX8MM_PGC_GPUMIX		23
-#define IMX8MM_PGC_VPUMIX		24
-#define IMX8MM_PGC_GPU3D		25
-#define IMX8MM_PGC_DISPMIX		26
-#define IMX8MM_PGC_VPUG1		27
-#define IMX8MM_PGC_VPUG2		28
-#define IMX8MM_PGC_VPUH1		29
-
-#define IMX8MN_PGC_MIPI		16
-#define IMX8MN_PGC_OTG1		18
-#define IMX8MN_PGC_DDR1		21
-#define IMX8MN_PGC_GPUMIX		23
-#define IMX8MN_PGC_DISPMIX		26
-
 #define GPC_PGC_CTRL(n)			(0x800 + (n) * 0x40)
 #define GPC_PGC_SR(n)			(GPC_PGC_CTRL(n) + 0xc)
 
 #define GPC_PGC_CTRL_PCR		BIT(0)
 
+#define GPC_CLK_MAX		6
+
 struct imx_pgc_domain {
 	struct generic_pm_domain genpd;
 	struct regmap *regmap;
 	struct regulator *regulator;
-	struct reset_control *reset;
-	struct clk_bulk_data *clks;
+	struct clk *clk[GPC_CLK_MAX];
 	int num_clks;
 
 	unsigned int pgc;
@@ -197,8 +114,7 @@ struct imx_pgc_domain {
 	const struct {
 		u32 pxx;
 		u32 map;
-		u32 hskreq;
-		u32 hskack;
+		u32 hsk;
 	} bits;
 
 	const int voltage;
@@ -211,172 +127,96 @@ struct imx_pgc_domain_data {
 	const struct regmap_access_table *reg_access_table;
 };
 
-static inline struct imx_pgc_domain *
-to_imx_pgc_domain(struct generic_pm_domain *genpd)
+static int imx_gpc_pu_pgc_sw_pxx_req(struct generic_pm_domain *genpd,
+				      bool on)
 {
-	return container_of(genpd, struct imx_pgc_domain, genpd);
-}
-
-static int imx_pgc_power_up(struct generic_pm_domain *genpd)
-{
-	struct imx_pgc_domain *domain = to_imx_pgc_domain(genpd);
-	u32 reg_val;
-	int ret;
-
-	ret = pm_runtime_get_sync(domain->dev);
-	if (ret < 0) {
-		pm_runtime_put_noidle(domain->dev);
-		return ret;
-	}
-
-	if (!IS_ERR(domain->regulator)) {
+	struct imx_pgc_domain *domain = container_of(genpd,
+						      struct imx_pgc_domain,
+						      genpd);
+	unsigned int offset = on ?
+		GPC_PU_PGC_SW_PUP_REQ : GPC_PU_PGC_SW_PDN_REQ;
+	const bool enable_power_control = !on;
+	const bool has_regulator = !IS_ERR(domain->regulator);
+	int i, ret = 0;
+	u32 pxx_req;
+
+	regmap_update_bits(domain->regmap, GPC_PGC_CPU_MAPPING,
+			   domain->bits.map, domain->bits.map);
+
+	if (has_regulator && on) {
 		ret = regulator_enable(domain->regulator);
 		if (ret) {
 			dev_err(domain->dev, "failed to enable regulator\n");
-			goto out_put_pm;
+			goto unmap;
 		}
 	}
 
 	/* Enable reset clocks for all devices in the domain */
-	ret = clk_bulk_prepare_enable(domain->num_clks, domain->clks);
-	if (ret) {
-		dev_err(domain->dev, "failed to enable reset clocks\n");
-		goto out_regulator_disable;
-	}
-
-	reset_control_assert(domain->reset);
-
-	if (domain->bits.pxx) {
-		/* request the domain to power up */
-		regmap_update_bits(domain->regmap, GPC_PU_PGC_SW_PUP_REQ,
-				   domain->bits.pxx, domain->bits.pxx);
-		/*
-		 * As per "5.5.9.4 Example Code 4" in IMX7DRM.pdf wait
-		 * for PUP_REQ/PDN_REQ bit to be cleared
-		 */
-		ret = regmap_read_poll_timeout(domain->regmap,
-					       GPC_PU_PGC_SW_PUP_REQ, reg_val,
-					       !(reg_val & domain->bits.pxx),
-					       0, USEC_PER_MSEC);
-		if (ret) {
-			dev_err(domain->dev, "failed to command PGC\n");
-			goto out_clk_disable;
-		}
-
-		/* disable power control */
-		regmap_clear_bits(domain->regmap, GPC_PGC_CTRL(domain->pgc),
-				  GPC_PGC_CTRL_PCR);
-	}
+	for (i = 0; i < domain->num_clks; i++)
+		clk_prepare_enable(domain->clk[i]);
 
-	/* delay for reset to propagate */
-	udelay(5);
-
-	reset_control_deassert(domain->reset);
+	if (enable_power_control)
+		regmap_update_bits(domain->regmap, GPC_PGC_CTRL(domain->pgc),
+				   GPC_PGC_CTRL_PCR, GPC_PGC_CTRL_PCR);
 
-	/* request the ADB400 to power up */
-	if (domain->bits.hskreq) {
+	if (domain->bits.hsk)
 		regmap_update_bits(domain->regmap, GPC_PU_PWRHSK,
-				   domain->bits.hskreq, domain->bits.hskreq);
-
+				   domain->bits.hsk, on ? domain->bits.hsk : 0);
+
+	regmap_update_bits(domain->regmap, offset,
+			   domain->bits.pxx, domain->bits.pxx);
+
+	/*
+	 * As per "5.5.9.4 Example Code 4" in IMX7DRM.pdf wait
+	 * for PUP_REQ/PDN_REQ bit to be cleared
+	 */
+	ret = regmap_read_poll_timeout(domain->regmap, offset, pxx_req,
+				       !(pxx_req & domain->bits.pxx),
+				       0, USEC_PER_MSEC);
+	if (ret) {
+		dev_err(domain->dev, "failed to command PGC\n");
 		/*
-		 * ret = regmap_read_poll_timeout(domain->regmap, GPC_PU_PWRHSK, reg_val,
-		 *				  (reg_val & domain->bits.hskack), 0,
-		 *				  USEC_PER_MSEC);
-		 * Technically we need the commented code to wait handshake. But that needs
-		 * the BLK-CTL module BUS clk-en bit being set.
-		 *
-		 * There is a separate BLK-CTL module and we will have such a driver for it,
-		 * that driver will set the BUS clk-en bit and handshake will be triggered
-		 * automatically there. Just add a delay and suppose the handshake finish
-		 * after that.
+		 * If we were in a process of enabling a
+		 * domain and failed we might as well disable
+		 * the regulator we just enabled. And if it
+		 * was the opposite situation and we failed to
+		 * power down -- keep the regulator on
 		 */
+		on = !on;
 	}
 
-	/* Disable reset clocks for all devices in the domain */
-	clk_bulk_disable_unprepare(domain->num_clks, domain->clks);
-
-	return 0;
-
-out_clk_disable:
-	clk_bulk_disable_unprepare(domain->num_clks, domain->clks);
-out_regulator_disable:
-	if (!IS_ERR(domain->regulator))
-		regulator_disable(domain->regulator);
-out_put_pm:
-	pm_runtime_put(domain->dev);
-
-	return ret;
-}
-
-static int imx_pgc_power_down(struct generic_pm_domain *genpd)
-{
-	struct imx_pgc_domain *domain = to_imx_pgc_domain(genpd);
-	u32 reg_val;
-	int ret;
-
-	/* Enable reset clocks for all devices in the domain */
-	ret = clk_bulk_prepare_enable(domain->num_clks, domain->clks);
-	if (ret) {
-		dev_err(domain->dev, "failed to enable reset clocks\n");
-		return ret;
-	}
-
-	/* request the ADB400 to power down */
-	if (domain->bits.hskreq) {
-		regmap_clear_bits(domain->regmap, GPC_PU_PWRHSK,
-				  domain->bits.hskreq);
-
-		ret = regmap_read_poll_timeout(domain->regmap, GPC_PU_PWRHSK,
-					       reg_val,
-					       !(reg_val & domain->bits.hskack),
-					       0, USEC_PER_MSEC);
-		if (ret) {
-			dev_err(domain->dev, "failed to power down ADB400\n");
-			goto out_clk_disable;
-		}
-	}
-
-	if (domain->bits.pxx) {
-		/* enable power control */
+	if (enable_power_control)
 		regmap_update_bits(domain->regmap, GPC_PGC_CTRL(domain->pgc),
-				   GPC_PGC_CTRL_PCR, GPC_PGC_CTRL_PCR);
-
-		/* request the domain to power down */
-		regmap_update_bits(domain->regmap, GPC_PU_PGC_SW_PDN_REQ,
-				   domain->bits.pxx, domain->bits.pxx);
-		/*
-		 * As per "5.5.9.4 Example Code 4" in IMX7DRM.pdf wait
-		 * for PUP_REQ/PDN_REQ bit to be cleared
-		 */
-		ret = regmap_read_poll_timeout(domain->regmap,
-					       GPC_PU_PGC_SW_PDN_REQ, reg_val,
-					       !(reg_val & domain->bits.pxx),
-					       0, USEC_PER_MSEC);
-		if (ret) {
-			dev_err(domain->dev, "failed to command PGC\n");
-			goto out_clk_disable;
-		}
-	}
+				   GPC_PGC_CTRL_PCR, 0);
 
 	/* Disable reset clocks for all devices in the domain */
-	clk_bulk_disable_unprepare(domain->num_clks, domain->clks);
-
-	if (!IS_ERR(domain->regulator)) {
-		ret = regulator_disable(domain->regulator);
-		if (ret) {
-			dev_err(domain->dev, "failed to disable regulator\n");
-			return ret;
-		}
+	for (i = 0; i < domain->num_clks; i++)
+		clk_disable_unprepare(domain->clk[i]);
+
+	if (has_regulator && !on) {
+		int err;
+
+		err = regulator_disable(domain->regulator);
+		if (err)
+			dev_err(domain->dev,
+				"failed to disable regulator: %d\n", err);
+		/* Preserve earlier error code */
+		ret = ret ?: err;
 	}
+unmap:
+	regmap_update_bits(domain->regmap, GPC_PGC_CPU_MAPPING,
+			   domain->bits.map, 0);
+	return ret;
+}
 
-	pm_runtime_put_sync_suspend(domain->dev);
-
-	return 0;
-
-out_clk_disable:
-	clk_bulk_disable_unprepare(domain->num_clks, domain->clks);
+static int imx_gpc_pu_pgc_sw_pup_req(struct generic_pm_domain *genpd)
+{
+	return imx_gpc_pu_pgc_sw_pxx_req(genpd, true);
+}
 
-	return ret;
+static int imx_gpc_pu_pgc_sw_pdn_req(struct generic_pm_domain *genpd)
+{
+	return imx_gpc_pu_pgc_sw_pxx_req(genpd, false);
 }
 
 static const struct imx_pgc_domain imx7_pgc_domains[] = {
@@ -502,8 +342,7 @@ static const struct imx_pgc_domain imx8m_pgc_domains[] = {
 		.bits  = {
 			.pxx = IMX8M_GPU_SW_Pxx_REQ,
 			.map = IMX8M_GPU_A53_DOMAIN,
-			.hskreq = IMX8M_GPU_HSK_PWRDNREQN,
-			.hskack = IMX8M_GPU_HSK_PWRDNACKN,
+			.hsk = IMX8M_GPU_HSK_PWRDNREQN,
 		},
 		.pgc   = IMX8M_PGC_GPU,
 	},
@@ -515,8 +354,7 @@ static const struct imx_pgc_domain imx8m_pgc_domains[] = {
 		.bits  = {
 			.pxx = IMX8M_VPU_SW_Pxx_REQ,
 			.map = IMX8M_VPU_A53_DOMAIN,
-			.hskreq = IMX8M_VPU_HSK_PWRDNREQN,
-			.hskack = IMX8M_VPU_HSK_PWRDNACKN,
+			.hsk = IMX8M_VPU_HSK_PWRDNREQN,
 		},
 		.pgc   = IMX8M_PGC_VPU,
 	},
@@ -528,8 +366,7 @@ static const struct imx_pgc_domain imx8m_pgc_domains[] = {
 		.bits  = {
 			.pxx = IMX8M_DISP_SW_Pxx_REQ,
 			.map = IMX8M_DISP_A53_DOMAIN,
-			.hskreq = IMX8M_DISP_HSK_PWRDNREQN,
-			.hskack = IMX8M_DISP_HSK_PWRDNACKN,
+			.hsk = IMX8M_DISP_HSK_PWRDNREQN,
 		},
 		.pgc   = IMX8M_PGC_DISP,
 	},
@@ -606,254 +443,40 @@ static const struct imx_pgc_domain_data imx8m_pgc_domain_data = {
 	.reg_access_table = &imx8m_access_table,
 };
 
-static const struct imx_pgc_domain imx8mm_pgc_domains[] = {
-	[IMX8MM_POWER_DOMAIN_HSIOMIX] = {
-		.genpd = {
-			.name = "hsiomix",
-		},
-		.bits  = {
-			.pxx = 0, /* no power sequence control */
-			.map = 0, /* no power sequence control */
-			.hskreq = IMX8MM_HSIO_HSK_PWRDNREQN,
-			.hskack = IMX8MM_HSIO_HSK_PWRDNACKN,
-		},
-	},
-
-	[IMX8MM_POWER_DOMAIN_PCIE] = {
-		.genpd = {
-			.name = "pcie",
-		},
-		.bits  = {
-			.pxx = IMX8MM_PCIE_SW_Pxx_REQ,
-			.map = IMX8MM_PCIE_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_PCIE,
-	},
-
-	[IMX8MM_POWER_DOMAIN_OTG1] = {
-		.genpd = {
-			.name = "usb-otg1",
-		},
-		.bits  = {
-			.pxx = IMX8MM_OTG1_SW_Pxx_REQ,
-			.map = IMX8MM_OTG1_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_OTG1,
-	},
-
-	[IMX8MM_POWER_DOMAIN_OTG2] = {
-		.genpd = {
-			.name = "usb-otg2",
-		},
-		.bits  = {
-			.pxx = IMX8MM_OTG2_SW_Pxx_REQ,
-			.map = IMX8MM_OTG2_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_OTG2,
-	},
-
-	[IMX8MM_POWER_DOMAIN_GPUMIX] = {
-		.genpd = {
-			.name = "gpumix",
-		},
-		.bits  = {
-			.pxx = IMX8MM_GPUMIX_SW_Pxx_REQ,
-			.map = IMX8MM_GPUMIX_A53_DOMAIN,
-			.hskreq = IMX8MM_GPUMIX_HSK_PWRDNREQN,
-			.hskack = IMX8MM_GPUMIX_HSK_PWRDNACKN,
-		},
-		.pgc   = IMX8MM_PGC_GPUMIX,
-	},
-
-	[IMX8MM_POWER_DOMAIN_GPU] = {
-		.genpd = {
-			.name = "gpu",
-		},
-		.bits  = {
-			.pxx = IMX8MM_GPU_SW_Pxx_REQ,
-			.map = IMX8MM_GPU_A53_DOMAIN,
-			.hskreq = IMX8MM_GPU_HSK_PWRDNREQN,
-			.hskack = IMX8MM_GPU_HSK_PWRDNACKN,
-		},
-		.pgc   = IMX8MM_PGC_GPU2D,
-	},
-
-	[IMX8MM_POWER_DOMAIN_VPUMIX] = {
-		.genpd = {
-			.name = "vpumix",
-		},
-		.bits  = {
-			.pxx = IMX8MM_VPUMIX_SW_Pxx_REQ,
-			.map = IMX8MM_VPUMIX_A53_DOMAIN,
-			.hskreq = IMX8MM_VPUMIX_HSK_PWRDNREQN,
-			.hskack = IMX8MM_VPUMIX_HSK_PWRDNACKN,
-		},
-		.pgc   = IMX8MM_PGC_VPUMIX,
-	},
-
-	[IMX8MM_POWER_DOMAIN_VPUG1] = {
-		.genpd = {
-			.name = "vpu-g1",
-		},
-		.bits  = {
-			.pxx = IMX8MM_VPUG1_SW_Pxx_REQ,
-			.map = IMX8MM_VPUG1_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_VPUG1,
-	},
-
-	[IMX8MM_POWER_DOMAIN_VPUG2] = {
-		.genpd = {
-			.name = "vpu-g2",
-		},
-		.bits  = {
-			.pxx = IMX8MM_VPUG2_SW_Pxx_REQ,
-			.map = IMX8MM_VPUG2_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_VPUG2,
-	},
-
-	[IMX8MM_POWER_DOMAIN_VPUH1] = {
-		.genpd = {
-			.name = "vpu-h1",
-		},
-		.bits  = {
-			.pxx = IMX8MM_VPUH1_SW_Pxx_REQ,
-			.map = IMX8MM_VPUH1_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_VPUH1,
-	},
-
-	[IMX8MM_POWER_DOMAIN_DISPMIX] = {
-		.genpd = {
-			.name = "dispmix",
-		},
-		.bits  = {
-			.pxx = IMX8MM_DISPMIX_SW_Pxx_REQ,
-			.map = IMX8MM_DISPMIX_A53_DOMAIN,
-			.hskreq = IMX8MM_DISPMIX_HSK_PWRDNREQN,
-			.hskack = IMX8MM_DISPMIX_HSK_PWRDNACKN,
-		},
-		.pgc   = IMX8MM_PGC_DISPMIX,
-	},
-
-	[IMX8MM_POWER_DOMAIN_MIPI] = {
-		.genpd = {
-			.name = "mipi",
-		},
-		.bits  = {
-			.pxx = IMX8MM_MIPI_SW_Pxx_REQ,
-			.map = IMX8MM_MIPI_A53_DOMAIN,
-		},
-		.pgc   = IMX8MM_PGC_MIPI,
-	},
-};
-
-static const struct regmap_range imx8mm_yes_ranges[] = {
-		regmap_reg_range(GPC_LPCR_A_CORE_BSC,
-				 GPC_PU_PWRHSK),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_MIPI),
-				 GPC_PGC_SR(IMX8MM_PGC_MIPI)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_PCIE),
-				 GPC_PGC_SR(IMX8MM_PGC_PCIE)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_OTG1),
-				 GPC_PGC_SR(IMX8MM_PGC_OTG1)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_OTG2),
-				 GPC_PGC_SR(IMX8MM_PGC_OTG2)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_DDR1),
-				 GPC_PGC_SR(IMX8MM_PGC_DDR1)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_GPU2D),
-				 GPC_PGC_SR(IMX8MM_PGC_GPU2D)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_GPUMIX),
-				 GPC_PGC_SR(IMX8MM_PGC_GPUMIX)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_VPUMIX),
-				 GPC_PGC_SR(IMX8MM_PGC_VPUMIX)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_GPU3D),
-				 GPC_PGC_SR(IMX8MM_PGC_GPU3D)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_DISPMIX),
-				 GPC_PGC_SR(IMX8MM_PGC_DISPMIX)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_VPUG1),
-				 GPC_PGC_SR(IMX8MM_PGC_VPUG1)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_VPUG2),
-				 GPC_PGC_SR(IMX8MM_PGC_VPUG2)),
-		regmap_reg_range(GPC_PGC_CTRL(IMX8MM_PGC_VPUH1),
-				 GPC_PGC_SR(IMX8MM_PGC_VPUH1)),
-};
-
-static const struct regmap_access_table imx8mm_access_table = {
-	.yes_ranges	= imx8mm_yes_ranges,
-	.n_yes_ranges	= ARRAY_SIZE(imx8mm_yes_ranges),
-};
-
-static const struct imx_pgc_domain_data imx8mm_pgc_domain_data = {
-	.domains = imx8mm_pgc_domains,
-	.domains_num = ARRAY_SIZE(imx8mm_pgc_domains),
-	.reg_access_table = &imx8mm_access_table,
-};
-
-static const struct imx_pgc_domain imx8mn_pgc_domains[] = {
-	[IMX8MN_POWER_DOMAIN_HSIOMIX] = {
-		.genpd = {
-			.name = "hsiomix",
-		},
-		.bits  = {
-			.pxx = 0, /* no power sequence control */
-			.map = 0, /* no power sequence control */
-			.hskreq = IMX8MN_HSIO_HSK_PWRDNREQN,
-			.hskack = IMX8MN_HSIO_HSK_PWRDNACKN,
-		},
-	},
+static int imx_pgc_get_clocks(struct imx_pgc_domain *domain)
+{
+	int i, ret;
+
+	for (i = 0; ; i++) {
+		struct clk *clk = of_clk_get(domain->dev->of_node, i);
+		if (IS_ERR(clk))
+			break;
+		if (i >= GPC_CLK_MAX) {
+			dev_err(domain->dev, "more than %d clocks\n",
+				GPC_CLK_MAX);
+			ret = -EINVAL;
+			goto clk_err;
+		}
+		domain->clk[i] = clk;
+	}
+	domain->num_clks = i;
 
-	[IMX8MN_POWER_DOMAIN_OTG1] = {
-		.genpd = {
-			.name = "usb-otg1",
-		},
-		.bits  = {
-			.pxx = IMX8MN_OTG1_SW_Pxx_REQ,
-			.map = IMX8MN_OTG1_A53_DOMAIN,
-		},
-		.pgc   = IMX8MN_PGC_OTG1,
-	},
+	return 0;
 
-	[IMX8MN_POWER_DOMAIN_GPUMIX] = {
-		.genpd = {
-			.name = "gpumix",
-		},
-		.bits  = {
-			.pxx = IMX8MN_GPUMIX_SW_Pxx_REQ,
-			.map = IMX8MN_GPUMIX_A53_DOMAIN,
-			.hskreq = IMX8MN_GPUMIX_HSK_PWRDNREQN,
-			.hskack = IMX8MN_GPUMIX_HSK_PWRDNACKN,
-		},
-		.pgc   = IMX8MN_PGC_GPUMIX,
-	},
-};
+clk_err:
+	while (i--)
+		clk_put(domain->clk[i]);
 
-static const struct regmap_range imx8mn_yes_ranges[] = {
-	regmap_reg_range(GPC_LPCR_A_CORE_BSC,
-			 GPC_PU_PWRHSK),
-	regmap_reg_range(GPC_PGC_CTRL(IMX8MN_PGC_MIPI),
-			 GPC_PGC_SR(IMX8MN_PGC_MIPI)),
-	regmap_reg_range(GPC_PGC_CTRL(IMX8MN_PGC_OTG1),
-			 GPC_PGC_SR(IMX8MN_PGC_OTG1)),
-	regmap_reg_range(GPC_PGC_CTRL(IMX8MN_PGC_DDR1),
-			 GPC_PGC_SR(IMX8MN_PGC_DDR1)),
-	regmap_reg_range(GPC_PGC_CTRL(IMX8MN_PGC_GPUMIX),
-			 GPC_PGC_SR(IMX8MN_PGC_GPUMIX)),
-	regmap_reg_range(GPC_PGC_CTRL(IMX8MN_PGC_DISPMIX),
-			 GPC_PGC_SR(IMX8MN_PGC_DISPMIX)),
-};
+	return ret;
+}
 
-static const struct regmap_access_table imx8mn_access_table = {
-	.yes_ranges	= imx8mn_yes_ranges,
-	.n_yes_ranges	= ARRAY_SIZE(imx8mn_yes_ranges),
-};
+static void imx_pgc_put_clocks(struct imx_pgc_domain *domain)
+{
+	int i;
 
-static const struct imx_pgc_domain_data imx8mn_pgc_domain_data = {
-	.domains = imx8mn_pgc_domains,
-	.domains_num = ARRAY_SIZE(imx8mn_pgc_domains),
-	.reg_access_table = &imx8mn_access_table,
-};
+	for (i = domain->num_clks - 1; i >= 0; i--)
+		clk_put(domain->clk[i]);
+}
 
 static int imx_pgc_domain_probe(struct platform_device *pdev)
 {
@@ -872,45 +495,25 @@ static int imx_pgc_domain_probe(struct platform_device *pdev)
 				      domain->voltage, domain->voltage);
 	}
 
-	domain->num_clks = devm_clk_bulk_get_all(domain->dev, &domain->clks);
-	if (domain->num_clks < 0)
-		return dev_err_probe(domain->dev, domain->num_clks,
-				     "Failed to get domain's clocks\n");
-
-	domain->reset = devm_reset_control_array_get_optional_exclusive(domain->dev);
-	if (IS_ERR(domain->reset))
-		return dev_err_probe(domain->dev, PTR_ERR(domain->reset),
-				     "Failed to get domain's resets\n");
-
-	pm_runtime_enable(domain->dev);
-
-	if (domain->bits.map)
-		regmap_update_bits(domain->regmap, GPC_PGC_CPU_MAPPING,
-				   domain->bits.map, domain->bits.map);
+	ret = imx_pgc_get_clocks(domain);
+	if (ret)
+		return dev_err_probe(domain->dev, ret, "Failed to get domain's clocks\n");
 
 	ret = pm_genpd_init(&domain->genpd, NULL, true);
 	if (ret) {
 		dev_err(domain->dev, "Failed to init power domain\n");
-		goto out_domain_unmap;
+		imx_pgc_put_clocks(domain);
+		return ret;
 	}
 
 	ret = of_genpd_add_provider_simple(domain->dev->of_node,
 					   &domain->genpd);
 	if (ret) {
 		dev_err(domain->dev, "Failed to add genpd provider\n");
-		goto out_genpd_remove;
+		pm_genpd_remove(&domain->genpd);
+		imx_pgc_put_clocks(domain);
 	}
 
-	return 0;
-
-out_genpd_remove:
-	pm_genpd_remove(&domain->genpd);
-out_domain_unmap:
-	if (domain->bits.map)
-		regmap_update_bits(domain->regmap, GPC_PGC_CPU_MAPPING,
-				   domain->bits.map, 0);
-	pm_runtime_disable(domain->dev);
-
 	return ret;
 }
 
@@ -920,12 +523,7 @@ static int imx_pgc_domain_remove(struct platform_device *pdev)
 
 	of_genpd_del_provider(domain->dev->of_node);
 	pm_genpd_remove(&domain->genpd);
-
-	if (domain->bits.map)
-		regmap_update_bits(domain->regmap, GPC_PGC_CPU_MAPPING,
-				   domain->bits.map, 0);
-
-	pm_runtime_disable(domain->dev);
+	imx_pgc_put_clocks(domain);
 
 	return 0;
 }
@@ -1019,8 +617,8 @@ static int imx_gpcv2_probe(struct platform_device *pdev)
 
 		domain = pd_pdev->dev.platform_data;
 		domain->regmap = regmap;
-		domain->genpd.power_on  = imx_pgc_power_up;
-		domain->genpd.power_off = imx_pgc_power_down;
+		domain->genpd.power_on  = imx_gpc_pu_pgc_sw_pup_req;
+		domain->genpd.power_off = imx_gpc_pu_pgc_sw_pdn_req;
 
 		pd_pdev->dev.parent = dev;
 		pd_pdev->dev.of_node = np;
@@ -1038,8 +636,6 @@ static int imx_gpcv2_probe(struct platform_device *pdev)
 
 static const struct of_device_id imx_gpcv2_dt_ids[] = {
 	{ .compatible = "fsl,imx7d-gpc", .data = &imx7_pgc_domain_data, },
-	{ .compatible = "fsl,imx8mm-gpc", .data = &imx8mm_pgc_domain_data, },
-	{ .compatible = "fsl,imx8mn-gpc", .data = &imx8mn_pgc_domain_data, },
 	{ .compatible = "fsl,imx8mq-gpc", .data = &imx8m_pgc_domain_data, },
 	{ }
 };
diff --git a/drivers/soc/imx/imx8m_pm_domains.c b/drivers/soc/imx/imx8m_pm_domains.c
new file mode 100644
index 000000000..d0af2ddb1
--- /dev/null
+++ b/drivers/soc/imx/imx8m_pm_domains.c
@@ -0,0 +1,243 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP.
+ */
+
+#include <linux/arm-smccc.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/pm_domain.h>
+#include <linux/regulator/consumer.h>
+
+#include <soc/imx/imx_sip.h>
+
+#define MAX_CLK_NUM	6
+#define to_imx8m_pm_domain(_genpd) container_of(_genpd, struct imx8m_pm_domain, pd)
+
+
+struct imx8m_pm_domain {
+	struct device *dev;
+	struct generic_pm_domain pd;
+	u32 domain_index;
+	struct clk *clk[MAX_CLK_NUM];
+	unsigned int num_clks;
+	struct regulator *reg;
+};
+
+enum imx8m_pm_domain_state {
+	PD_STATE_OFF,
+	PD_STATE_ON,
+};
+
+static DEFINE_MUTEX(gpc_pd_mutex);
+
+static int imx8m_pd_power_on(struct generic_pm_domain *genpd)
+{
+	struct imx8m_pm_domain *domain = to_imx8m_pm_domain(genpd);
+	struct arm_smccc_res res;
+	int index, ret = 0;
+
+	/* power on the external supply */
+	if (!IS_ERR(domain->reg)) {
+		ret = regulator_enable(domain->reg);
+		if (ret) {
+			dev_warn(domain->dev, "failed to power up the reg%d\n", ret);
+			return ret;
+		}
+	}
+
+	/* enable the necessary clks needed by the power domain */
+	if (domain->num_clks) {
+		for (index = 0; index < domain->num_clks; index++)
+			clk_prepare_enable(domain->clk[index]);
+	}
+
+	mutex_lock(&gpc_pd_mutex);
+	arm_smccc_smc(IMX_SIP_GPC, IMX_SIP_CONFIG_GPC_PM_DOMAIN, domain->domain_index,
+		      PD_STATE_ON, 0, 0, 0, 0, &res);
+	mutex_unlock(&gpc_pd_mutex);
+
+	return 0;
+}
+
+static int imx8m_pd_power_off(struct generic_pm_domain *genpd)
+{
+	struct imx8m_pm_domain *domain = to_imx8m_pm_domain(genpd);
+	struct arm_smccc_res res;
+	int index, ret = 0;
+
+	mutex_lock(&gpc_pd_mutex);
+	arm_smccc_smc(IMX_SIP_GPC, IMX_SIP_CONFIG_GPC_PM_DOMAIN, domain->domain_index,
+		      PD_STATE_OFF, 0, 0, 0, 0, &res);
+	mutex_unlock(&gpc_pd_mutex);
+
+	/* power off the external supply */
+	if (!IS_ERR(domain->reg)) {
+		ret = regulator_disable(domain->reg);
+		if (ret) {
+			dev_warn(domain->dev, "failed to power off the reg%d\n", ret);
+			return ret;
+		}
+	}
+
+	/* disable clks when power domain is off */
+	if (domain->num_clks) {
+		for (index = 0; index < domain->num_clks; index++)
+			clk_disable_unprepare(domain->clk[index]);
+	}
+
+	return ret;
+};
+
+static int imx8m_pd_get_clocks(struct imx8m_pm_domain *domain)
+{
+	int i, ret;
+
+	if (domain->pd.flags & GENPD_FLAG_PM_PD_CLK)
+		return 0;
+
+	for (i = 0; ; i++) {
+		struct clk *clk = of_clk_get(domain->dev->of_node, i);
+		if (IS_ERR(clk))
+			break;
+		if (i >= MAX_CLK_NUM) {
+			dev_err(domain->dev, "more than %d clocks\n",
+				MAX_CLK_NUM);
+			ret = -EINVAL;
+			goto clk_err;
+		}
+		domain->clk[i] = clk;
+	}
+	domain->num_clks = i;
+
+	return 0;
+
+clk_err:
+	while (i--)
+		clk_put(domain->clk[i]);
+
+	return ret;
+}
+
+static void imx8m_pd_put_clocks(struct imx8m_pm_domain *domain)
+{
+	int i;
+
+	if (domain->pd.flags & GENPD_FLAG_PM_PD_CLK)
+		return;
+
+	for (i = domain->num_clks - 1; i >= 0; i--)
+		clk_put(domain->clk[i]);
+}
+
+static const struct of_device_id imx8m_pm_domain_ids[] = {
+	{.compatible = "fsl,imx8m-pm-domain"},
+	{},
+};
+
+static int imx8m_pm_domain_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct imx8m_pm_domain *domain;
+	struct of_phandle_args parent, child;
+	int ret;
+
+	domain = devm_kzalloc(dev, sizeof(*domain), GFP_KERNEL);
+	if (!domain)
+		return -ENOMEM;
+
+	child.np = np;
+	domain->dev = dev;
+
+	ret = of_property_read_string(np, "domain-name", &domain->pd.name);
+	if (ret) {
+		dev_err(dev, "failed to get the domain name\n");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(np, "domain-index", &domain->domain_index);
+	if (ret) {
+		dev_err(dev, "failed to get the domain index\n");
+		return -EINVAL;
+	}
+
+	domain->reg = devm_regulator_get_optional(dev, "power");
+	if (IS_ERR(domain->reg)) {
+		if (PTR_ERR(domain->reg) != -ENODEV) {
+			if (PTR_ERR(domain->reg) != -EPROBE_DEFER)
+				dev_err(dev, "failed to get domain's regulator\n");
+			return PTR_ERR(domain->reg);
+		}
+	}
+
+	if (of_machine_is_compatible("fsl,imx8mp"))
+		domain->pd.flags |= GENPD_FLAG_PM_PD_CLK;
+
+	ret = imx8m_pd_get_clocks(domain);
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "failed to get domain's clocks\n");
+		return ret;
+	}
+
+	domain->pd.power_off = imx8m_pd_power_off;
+	domain->pd.power_on = imx8m_pd_power_on;
+	if (of_property_read_bool(np, "active-wakeup"))
+		domain->pd.flags |= GENPD_FLAG_ACTIVE_WAKEUP;
+	if (of_property_read_bool(np, "rpm-always-on"))
+		domain->pd.flags |= GENPD_FLAG_RPM_ALWAYS_ON;
+
+	pm_genpd_init(&domain->pd, NULL, !(domain->pd.flags & GENPD_FLAG_RPM_ALWAYS_ON));
+
+	ret = pm_genpd_of_add_clks(&domain->pd, dev);
+	if (ret) {
+		pm_genpd_remove(&domain->pd);
+		return ret;
+	}
+
+	ret = of_genpd_add_provider_simple(np, &domain->pd);
+	if (ret) {
+		dev_err(dev, "failed to add the domain provider\n");
+		pm_genpd_remove(&domain->pd);
+		imx8m_pd_put_clocks(domain);
+		return ret;
+	}
+
+	/* add it as subdomain if necessary */
+	if (!of_parse_phandle_with_args(np, "parent-domains",
+			"#power-domain-cells", 0, &parent)) {
+		ret = of_genpd_add_subdomain(&parent, &child);
+		of_node_put(parent.np);
+
+		if (ret < 0) {
+			dev_dbg(dev, "failed to add the subdomain: %s: %d",
+				domain->pd.name, ret);
+			of_genpd_del_provider(np);
+			pm_genpd_remove(&domain->pd);
+			imx8m_pd_put_clocks(domain);
+			return -EPROBE_DEFER;
+		}
+	}
+
+	return 0;
+}
+
+static struct platform_driver imx8m_pm_domain_driver = {
+	.driver = {
+		.name	= "imx8m_pm_domain",
+		.owner	= THIS_MODULE,
+		.of_match_table = imx8m_pm_domain_ids,
+	},
+	.probe = imx8m_pm_domain_probe,
+};
+module_platform_driver(imx8m_pm_domain_driver);
+
+MODULE_AUTHOR("NXP");
+MODULE_DESCRIPTION("NXP i.MX8M power domain driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/imx/imx8ulp_lpm.c b/drivers/soc/imx/imx8ulp_lpm.c
new file mode 100644
index 000000000..f88866b11
--- /dev/null
+++ b/drivers/soc/imx/imx8ulp_lpm.c
@@ -0,0 +1,167 @@
+#include <linux/arm-smccc.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/suspend.h>
+
+#define FSL_SIP_DDR_DVFS                0xc2000004
+#define DDR_DFS_GET_FSP_COUNT		0x10
+#define DDR_FSP_HIGH		2
+#define DDR_FSP_LOW		1
+#define DDR_DFS_FSP_NUM_MIN	3
+#define DDR_BYPASS_DRATE	400
+
+static struct clk *dram_sel;
+static struct clk *dram_div;
+static struct clk *pll4;
+static struct clk *frosc;
+
+static bool lpm_enabled = false;
+static bool bypass_enabled = false;
+static struct device *imx8ulp_lpm_dev;
+static int num_fsp;
+
+static int scaling_dram_freq(unsigned int fsp_index)
+{
+	struct arm_smccc_res res;
+	u32 num_cpus = num_online_cpus();
+
+	local_irq_disable();
+
+	/* need to check the return value ?*/ 
+	arm_smccc_smc(FSL_SIP_DDR_DVFS, fsp_index, num_cpus,
+		0, 0, 0, 0, 0, &res);
+
+	local_irq_enable();
+
+	/* Correct the clock tree & rate info as it has been updated in TF-A */
+	if (fsp_index == DDR_FSP_HIGH) {
+		clk_set_parent(dram_sel, pll4);
+	} else if (bypass_enabled) {
+		/* only need to correct the clock parent/child for bypass mode */
+		clk_set_parent(dram_sel, frosc);
+	}
+
+	clk_get_rate(dram_div);
+
+	return 0;
+}
+
+static ssize_t lpm_enable_show(struct device *dev, struct device_attribute *attr,
+				char *buf)
+{
+	if(lpm_enabled)
+		return sprintf(buf, "i.MX8ULP LPM mode enabled\n");
+	else
+		return sprintf(buf, "i.MX8ULP LPM mode disabled\n");
+}
+
+static ssize_t lpm_enable_store(struct device *dev, struct device_attribute *attr,
+				const char *buf, size_t size)
+{
+	/*
+	 * only support DDR DFS between PLL on and PLL bypass, so the valid
+	 * num_fsp should be 3
+	 */
+	if (num_fsp < DDR_DFS_FSP_NUM_MIN)
+		pr_info("DDR DFS only support with both F1 & F2 enabled\n");
+
+
+	if (strncmp(buf, "1", 1) == 0) {
+		scaling_dram_freq(DDR_FSP_LOW);
+
+		lpm_enabled = true;
+		pr_info("DDR enter low frequency mode\n");
+	} else if (strncmp(buf, "0", 1) == 0) {
+		if (lpm_enabled) {
+			/* exit LPM mode */
+			scaling_dram_freq(DDR_FSP_HIGH);
+
+			pr_info("DDR Exit from low frequency mode\n");
+		}
+		lpm_enabled = false;
+	}
+
+	return size;
+}
+static DEVICE_ATTR(enable, 0644, lpm_enable_show,
+			lpm_enable_store);
+
+static int imx8ulp_lpm_pm_notify(struct notifier_block *nb, unsigned long event,
+	void *dummy)
+{
+	/* if DDR is not in low frequency, return directly */
+	if (!lpm_enabled)
+		return NOTIFY_OK;
+
+	if (event == PM_SUSPEND_PREPARE)
+		scaling_dram_freq(DDR_FSP_HIGH);
+	else if (event == PM_POST_SUSPEND)
+		scaling_dram_freq(DDR_FSP_LOW);
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block imx8ulp_lpm_pm_notifier = {
+	.notifier_call = imx8ulp_lpm_pm_notify,
+};
+
+/* sysfs for user control */
+static int imx8ulp_lpm_probe(struct platform_device *pdev)
+{
+	int err;
+	struct arm_smccc_res res;
+
+	imx8ulp_lpm_dev = &pdev->dev;
+
+	arm_smccc_smc(FSL_SIP_DDR_DVFS, DDR_DFS_GET_FSP_COUNT, 0,
+		0, 0, 0, 0, 0, &res);
+	num_fsp = res.a0;
+	/* check F1 is bypass or not */
+	if (res.a1 <= DDR_BYPASS_DRATE)
+		bypass_enabled = true;
+
+	/* only support DFS for F1 & F2 both enabled */
+	if (num_fsp != DDR_DFS_FSP_NUM_MIN)
+		return -ENODEV;
+
+	/* get the necessary clocks */
+	dram_sel = devm_clk_get(&pdev->dev, "ddr_sel");
+	dram_div = devm_clk_get(&pdev->dev, "ddr_div");
+	pll4 = devm_clk_get(&pdev->dev, "pll4");
+	frosc = devm_clk_get(&pdev->dev, "frosc");
+	if (IS_ERR(dram_sel) || IS_ERR(dram_div) || IS_ERR(pll4) || IS_ERR(frosc))
+		dev_err(&pdev->dev, "Get clocks failed\n");
+
+	/* create the sysfs file */
+	err = sysfs_create_file(&imx8ulp_lpm_dev->kobj, &dev_attr_enable.attr);
+	if (err) {
+		dev_err(&pdev->dev, "creating i.MX8ULP LPM control sys file\n");
+		return err;
+	}
+
+	register_pm_notifier(&imx8ulp_lpm_pm_notifier);
+
+	return 0;
+}
+
+static const struct of_device_id imx8ulp_lpm_ids[] = {
+	{.compatible = "nxp, imx8ulp-lpm", },
+	{ /* sentinel */}
+};
+
+static struct platform_driver imx8ulp_lpm_driver = {
+	.driver = {
+		.name = "imx8ulp-lpm",
+		.owner = THIS_MODULE,
+		.of_match_table = imx8ulp_lpm_ids,
+		},
+	.probe = imx8ulp_lpm_probe,
+};
+module_platform_driver(imx8ulp_lpm_driver);
+
+MODULE_AUTHOR("NXP Semiconductor, Inc.");
+MODULE_DESCRIPTION("i.MX8ULP Low Power Control driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/soc/imx/imx93-blk-ctrl.c b/drivers/soc/imx/imx93-blk-ctrl.c
new file mode 100644
index 000000000..6fe0d9fff
--- /dev/null
+++ b/drivers/soc/imx/imx93-blk-ctrl.c
@@ -0,0 +1,333 @@
+// SPDX-License-Identifier: GPL-2.0+
+
+/*
+ * Copyright 2022 NXP, Peng Fan <peng.fan@nxp.com>
+ */
+
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/pm_domain.h>
+#include <linux/pm_runtime.h>
+#include <linux/regmap.h>
+#include <linux/clk.h>
+
+#include <dt-bindings/power/imx93-power.h>
+
+#define BLK_SFT_RSTN	0x0
+#define BLK_CLK_EN	0x4
+
+#define BLK_MAX_CLKS 4
+
+struct imx93_blk_ctrl_domain;
+
+struct imx93_blk_ctrl {
+	struct device *dev;
+	struct regmap *regmap;
+	int num_clks;
+	struct clk_bulk_data clks[BLK_MAX_CLKS];
+	struct imx93_blk_ctrl_domain *domains;
+	struct genpd_onecell_data onecell_data;
+};
+
+struct imx93_blk_ctrl_domain_data {
+	const char *name;
+	const char * const *clk_names;
+	int num_clks;
+	u32 rst_mask;
+	u32 clk_mask;
+
+};
+
+#define DOMAIN_MAX_CLKS 4
+
+struct imx93_blk_ctrl_domain {
+	struct generic_pm_domain genpd;
+	const struct imx93_blk_ctrl_domain_data *data;
+	struct clk_bulk_data clks[DOMAIN_MAX_CLKS];
+	struct imx93_blk_ctrl *bc;
+};
+
+struct imx93_blk_ctrl_data {
+	int max_reg;
+	const struct imx93_blk_ctrl_domain_data *domains;
+	const struct imx93_blk_ctrl_domain_data *bus;
+	int num_domains;
+};
+
+static const struct imx93_blk_ctrl_domain_data imx93_media_blk_ctl_bus_data = {
+	.clk_names = (const char *[]){ "axi", "apb", "nic", },
+	.num_clks = 3,
+};
+
+static inline struct imx93_blk_ctrl_domain *
+to_imx93_blk_ctrl_domain(struct generic_pm_domain *genpd)
+{
+	return container_of(genpd, struct imx93_blk_ctrl_domain, genpd);
+}
+
+static int imx93_blk_ctrl_power_on(struct generic_pm_domain *genpd)
+{
+	struct imx93_blk_ctrl_domain *domain = to_imx93_blk_ctrl_domain(genpd);
+	const struct imx93_blk_ctrl_domain_data *data = domain->data;
+	struct imx93_blk_ctrl *bc = domain->bc;
+	int ret;
+
+	ret = clk_bulk_prepare_enable(bc->num_clks, bc->clks);
+	if (ret) {
+		dev_err(bc->dev, "failed to enable bus clocks\n");
+		return ret;
+	}
+
+	ret = clk_bulk_prepare_enable(data->num_clks, domain->clks);
+	if (ret) {
+		dev_err(bc->dev, "failed to enable clocks\n");
+		return ret;
+	}
+
+	ret = pm_runtime_get_sync(bc->dev);
+	if (ret < 0) {
+		pm_runtime_put_noidle(bc->dev);
+		dev_err(bc->dev, "failed to power up domain\n");
+		goto disable_clk;
+	}
+
+	/* ungate clk */
+	regmap_clear_bits(bc->regmap, BLK_CLK_EN, data->clk_mask);
+
+	/* release reset */
+	regmap_set_bits(bc->regmap, BLK_SFT_RSTN, data->rst_mask);
+
+	dev_dbg(bc->dev, "pd_on: name: %s\n", genpd->name);
+
+	return 0;
+
+disable_clk:
+	clk_bulk_disable_unprepare(data->num_clks, domain->clks);
+
+	return ret;
+}
+
+static int imx93_blk_ctrl_power_off(struct generic_pm_domain *genpd)
+{
+	struct imx93_blk_ctrl_domain *domain = to_imx93_blk_ctrl_domain(genpd);
+	const struct imx93_blk_ctrl_domain_data *data = domain->data;
+	struct imx93_blk_ctrl *bc = domain->bc;
+
+	dev_dbg(bc->dev, "pd_off: name: %s\n", genpd->name);
+
+	regmap_clear_bits(bc->regmap, BLK_SFT_RSTN, data->rst_mask);
+	regmap_set_bits(bc->regmap, BLK_CLK_EN, data->clk_mask);
+
+	pm_runtime_put(bc->dev);
+
+	clk_bulk_disable_unprepare(data->num_clks, domain->clks);
+
+	clk_bulk_disable_unprepare(bc->num_clks, bc->clks);
+
+	return 0;
+}
+
+static struct generic_pm_domain *
+imx93_blk_ctrl_xlate(struct of_phandle_args *args, void *data)
+{
+	struct genpd_onecell_data *onecell_data = data;
+	unsigned int index = args->args[0];
+
+	if (args->args_count != 1 ||
+	    index >= onecell_data->num_domains)
+		return ERR_PTR(-EINVAL);
+
+	return onecell_data->domains[index];
+}
+
+static int imx93_blk_ctrl_probe(struct platform_device *pdev)
+{
+	const struct imx93_blk_ctrl_data *bc_data;
+	struct device *dev = &pdev->dev;
+	struct imx93_blk_ctrl *bc;
+	void __iomem *base;
+	int i, ret;
+	const struct imx93_blk_ctrl_domain_data *bus;
+
+	struct regmap_config regmap_config = {
+		.reg_bits	= 32,
+		.val_bits	= 32,
+		.reg_stride	= 4,
+	};
+
+	bc = devm_kzalloc(dev, sizeof(*bc), GFP_KERNEL);
+	if (!bc)
+		return -ENOMEM;
+
+	bc->dev = dev;
+
+	bc_data = of_device_get_match_data(dev);
+
+	base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(base))
+		return PTR_ERR(base);
+
+	regmap_config.max_register = bc_data->max_reg;
+	bc->regmap = devm_regmap_init_mmio(dev, base, &regmap_config);
+	if (IS_ERR(bc->regmap))
+		return dev_err_probe(dev, PTR_ERR(bc->regmap),
+				     "failed to init regmap\n");
+
+	bc->domains = devm_kcalloc(dev, bc_data->num_domains + 1,
+				   sizeof(struct imx93_blk_ctrl_domain),
+				   GFP_KERNEL);
+	if (!bc->domains)
+		return -ENOMEM;
+
+	bus = bc_data->bus;
+
+	bc->onecell_data.num_domains = bc_data->num_domains;
+	bc->onecell_data.xlate = imx93_blk_ctrl_xlate;
+	bc->onecell_data.domains =
+		devm_kcalloc(dev, bc_data->num_domains,
+			     sizeof(struct generic_pm_domain *), GFP_KERNEL);
+	if (!bc->onecell_data.domains)
+		return -ENOMEM;
+
+	for (i = 0; i < bus->num_clks; i++)
+		bc->clks[i].id = bus->clk_names[i];
+	bc->num_clks = bus->num_clks;
+
+	ret = devm_clk_bulk_get(dev, bc->num_clks, bc->clks);
+	if (ret) {
+		dev_err_probe(dev, ret, "failed to get bus clock\n");
+		return ret;
+	}
+
+	for (i = 0; i < bc_data->num_domains; i++) {
+		const struct imx93_blk_ctrl_domain_data *data = &bc_data->domains[i];
+		struct imx93_blk_ctrl_domain *domain = &bc->domains[i];
+		int j;
+
+		domain->data = data;
+
+		for (j = 0; j < data->num_clks; j++)
+			domain->clks[j].id = data->clk_names[j];
+
+		ret = devm_clk_bulk_get(dev, data->num_clks, domain->clks);
+		if (ret) {
+			dev_err_probe(dev, ret, "failed to get clock\n");
+			goto cleanup_pds;
+		}
+
+		domain->genpd.name = data->name;
+		domain->genpd.power_on = imx93_blk_ctrl_power_on;
+		domain->genpd.power_off = imx93_blk_ctrl_power_off;
+		domain->bc = bc;
+
+		ret = pm_genpd_init(&domain->genpd, NULL, true);
+		if (ret) {
+			dev_err_probe(dev, ret, "failed to init power domain\n");
+			goto cleanup_pds;
+		}
+
+		bc->onecell_data.domains[i] = &domain->genpd;
+	}
+
+	pm_runtime_enable(dev);
+
+	ret = of_genpd_add_provider_onecell(dev->of_node, &bc->onecell_data);
+	if (ret) {
+		dev_err_probe(dev, ret, "failed to add power domain provider\n");
+		goto cleanup_pds;
+	}
+
+
+	dev_set_drvdata(dev, bc);
+
+	return 0;
+
+cleanup_pds:
+	for (i--; i >= 0; i--)
+		pm_genpd_remove(&bc->domains[i].genpd);
+
+	return ret;
+}
+
+static int imx93_blk_ctrl_remove(struct platform_device *pdev)
+{
+	struct imx93_blk_ctrl *bc = dev_get_drvdata(&pdev->dev);
+	int i;
+
+	of_genpd_del_provider(pdev->dev.of_node);
+
+	for (i = 0; bc->onecell_data.num_domains; i++) {
+		struct imx93_blk_ctrl_domain *domain = &bc->domains[i];
+
+		pm_genpd_remove(&domain->genpd);
+	}
+
+	return 0;
+}
+
+static const struct imx93_blk_ctrl_domain_data imx93_media_blk_ctl_domain_data[] = {
+	[IMX93_MEDIABLK_PD_MIPI_DSI] = {
+		.name = "mediablk-mipi-dsi",
+		.clk_names = (const char *[]){ "dsi" },
+		.num_clks = 1,
+		.rst_mask = BIT(11) | BIT(12),
+		.clk_mask = BIT(11) | BIT(12),
+	},
+	[IMX93_MEDIABLK_PD_MIPI_CSI] = {
+		.name = "mediablk-mipi-csi",
+		.clk_names = (const char *[]){ "cam", "csi" },
+		.num_clks = 2,
+		.rst_mask = BIT(9) | BIT(10),
+		.clk_mask = BIT(9) | BIT(10),
+	},
+	[IMX93_MEDIABLK_PD_PXP] = {
+		.name = "mediablk-pxp",
+		.clk_names = (const char *[]){ "pxp" },
+		.num_clks = 1,
+		.rst_mask = BIT(7) | BIT(8),
+		.clk_mask = BIT(7) | BIT(8),
+	},
+	[IMX93_MEDIABLK_PD_LCDIF] = {
+		.name = "mediablk-lcdif",
+		.clk_names = (const char *[]){ "disp", "lcdif" },
+		.num_clks = 2,
+		.rst_mask = BIT(4) | BIT(5) | BIT(6),
+		.clk_mask = BIT(4) | BIT(5) | BIT(6),
+	},
+	[IMX93_MEDIABLK_PD_ISI] = {
+		.name = "mediablk-isi",
+		.clk_names = (const char *[]){ "isi" },
+		.num_clks = 1,
+		.rst_mask = BIT(2) | BIT(3),
+		.clk_mask = BIT(2) | BIT(3),
+	},
+};
+
+static const struct imx93_blk_ctrl_data imx93_media_blk_ctl_dev_data = {
+	.max_reg = 0x90,
+	.domains = imx93_media_blk_ctl_domain_data,
+	.bus = &imx93_media_blk_ctl_bus_data,
+	.num_domains = ARRAY_SIZE(imx93_media_blk_ctl_domain_data),
+};
+
+static const struct of_device_id imx93_blk_ctrl_of_match[] = {
+	{
+		.compatible = "fsl,imx93-media-blk-ctrl",
+		.data = &imx93_media_blk_ctl_dev_data
+	}, {
+		/* Sentinel */
+	}
+};
+MODULE_DEVICE_TABLE(of, imx93_blk_ctrl_of_match);
+
+static struct platform_driver imx93_blk_ctrl_driver = {
+	.probe = imx93_blk_ctrl_probe,
+	.remove = imx93_blk_ctrl_remove,
+	.driver = {
+		.name = "imx93-blk-ctrl",
+		.of_match_table = imx93_blk_ctrl_of_match,
+	},
+};
+module_platform_driver(imx93_blk_ctrl_driver);
diff --git a/drivers/soc/imx/imx93-pd.c b/drivers/soc/imx/imx93-pd.c
new file mode 100644
index 000000000..018381058
--- /dev/null
+++ b/drivers/soc/imx/imx93-pd.c
@@ -0,0 +1,276 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2022 NXP.
+ */
+
+#include <linux/clk.h>
+#include <linux/of_device.h>
+#include <linux/delay.h>
+#include <linux/iopoll.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/pm_domain.h>
+#include <dt-bindings/power/imx93-power.h>
+
+#define IMX93_SRC_MLMIX_OFF		0x1800
+#define IMX93_SRC_MEDIAMIX_OFF		0x2400
+
+#define MIX_SLICE_SW_CTRL_OFF		0x20
+#define SLICE_SW_CTRL_PSW_CTRL_OFF_MASK	BIT(4)
+#define SLICE_SW_CTRL_PDN_SOFT_MASK	BIT(31)
+
+#define MIX_FUNC_STAT_OFF		0xB4
+
+#define FUNC_STAT_PSW_STAT_MASK		BIT(0)
+#define FUNC_STAT_RST_STAT_MASK		BIT(2)
+#define FUNC_STAT_ISO_STAT_MASK		BIT(4)
+
+struct imx93_slice_info {
+	char *name;
+	u32 mix_off;
+};
+
+struct imx93_plat_data {
+	u32 num_slice;
+	struct imx93_slice_info *slices;
+};
+
+struct imx93_power_domain {
+	struct generic_pm_domain genpd;
+	struct device *dev;
+	void * __iomem base;
+	const struct imx93_slice_info *slice_info;
+	struct clk_bulk_data *clks;
+	int num_clks;
+};
+
+#define to_imx93_pd(_genpd) container_of(_genpd, struct imx93_power_domain, genpd)
+
+struct imx93_slice_info imx93_slice_infos[] = {
+	[IMX93_POWER_DOMAIN_MEDIAMIX] = {
+		.name      = "mediamix",
+		.mix_off = IMX93_SRC_MEDIAMIX_OFF,
+	},
+	[IMX93_POWER_DOMAIN_MLMIX] = {
+		.name      = "mlmix",
+		.mix_off = IMX93_SRC_MLMIX_OFF,
+	}
+};
+
+struct imx93_plat_data imx93_plat_data = {
+	.num_slice = ARRAY_SIZE(imx93_slice_infos),
+	.slices = imx93_slice_infos,
+};
+
+static int imx93_pd_on(struct generic_pm_domain *genpd)
+{
+	struct imx93_power_domain *domain = to_imx93_pd(genpd);
+	const struct imx93_slice_info *slice_info =  domain->slice_info;
+	void * __iomem addr = domain->base + slice_info->mix_off;
+	u32 val;
+	int ret;
+
+	ret = clk_bulk_prepare_enable(domain->num_clks, domain->clks);
+	if (ret) {
+		dev_err(domain->dev, "failed to enable clocks for domain: %s\n", genpd->name);
+		return ret;
+	}
+
+	val = readl(addr + MIX_SLICE_SW_CTRL_OFF);
+	val &= ~SLICE_SW_CTRL_PDN_SOFT_MASK;
+	writel(val, addr + MIX_SLICE_SW_CTRL_OFF);
+
+	ret = readl_poll_timeout(addr + MIX_FUNC_STAT_OFF, val,
+				 !(val & FUNC_STAT_ISO_STAT_MASK), 1, 10000);
+	if (ret) {
+		dev_err(domain->dev, "pd_on timeout: name: %s, stat: %x\n", genpd->name, val);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int imx93_pd_off(struct generic_pm_domain *genpd)
+{
+	struct imx93_power_domain *domain = to_imx93_pd(genpd);
+	const struct imx93_slice_info *slice_info =  domain->slice_info;
+	void * __iomem addr = domain->base + slice_info->mix_off;
+	int ret;
+	u32 val;
+
+	/* Power off MIX */
+	val = readl(addr + MIX_SLICE_SW_CTRL_OFF);
+	val |= SLICE_SW_CTRL_PDN_SOFT_MASK;
+	writel(val, addr + MIX_SLICE_SW_CTRL_OFF);
+
+	ret = readl_poll_timeout(addr + MIX_FUNC_STAT_OFF, val,
+				 val & FUNC_STAT_PSW_STAT_MASK, 1, 1000);
+	if (ret) {
+		dev_err(domain->dev, "pd_off timeout: name: %s, stat: %x\n", genpd->name, val);
+		return ret;
+	}
+
+	clk_bulk_disable_unprepare(domain->num_clks, domain->clks);
+
+	return 0;
+};
+
+static const struct of_device_id imx93_power_domain_ids[] = {
+	{ .compatible = "fsl,imx93-src", .data = &imx93_plat_data, },
+	{},
+};
+
+static int imx93_pd_remove(struct platform_device *pdev)
+{
+	struct imx93_power_domain *pd = platform_get_drvdata(pdev);
+	struct device *dev = &pdev->dev;
+	const struct imx93_plat_data *data = of_device_get_match_data(dev);
+	u32 num_domains = data->num_slice;
+	struct device_node *slice_np, *np;
+	int ret;
+
+	slice_np = of_get_child_by_name(pdev->dev.of_node, "slice");
+
+	for_each_child_of_node(slice_np, np) {
+		struct imx93_power_domain *domain;
+		u32 index;
+
+		if (!of_device_is_available(np))
+			continue;
+
+		ret = of_property_read_u32(np, "reg", &index);
+		if (ret) {
+			dev_err(dev, "Failed to read 'reg' property\n");
+			of_node_put(np);
+			return ret;
+		}
+
+		if (index >= num_domains) {
+			dev_warn(dev, "Domain index %d is out of bounds\n", index);
+			continue;
+		}
+
+		domain = &pd[index];
+
+		of_genpd_del_provider(np);
+
+		pm_genpd_remove(&domain->genpd);
+		clk_bulk_put_all(domain->num_clks, domain->clks);
+	};
+
+	return 0;
+}
+
+static int imx93_pd_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	const struct imx93_plat_data *data = of_device_get_match_data(dev);
+	const struct imx93_slice_info *slice_info = data->slices;
+	struct imx93_power_domain *pd;
+	u32 num_domains = data->num_slice;
+	struct device_node *slice_np, *np;
+	void __iomem *base;
+	bool is_off;
+	int ret;
+
+	slice_np = of_get_child_by_name(dev->of_node, "slice");
+	if (!slice_np) {
+		dev_err(dev, "No slices specified in DT\n");
+		return -EINVAL;
+	}
+
+	base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(base))
+		return PTR_ERR(base);
+
+	pd = devm_kcalloc(dev, num_domains, sizeof(*pd), GFP_KERNEL);
+	if (!pd)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, pd);
+
+	for_each_child_of_node(slice_np, np) {
+		struct imx93_power_domain *domain;
+		u32 index;
+
+		if (!of_device_is_available(np))
+			continue;
+
+		ret = of_property_read_u32(np, "reg", &index);
+		if (ret) {
+			dev_err(dev, "Failed to read 'reg' property\n");
+			of_node_put(np);
+			return ret;
+		}
+
+		if (index >= num_domains) {
+			dev_warn(dev, "Domain index %d is out of bounds\n", index);
+			continue;
+		}
+
+		domain = &pd[index];
+
+		domain->num_clks = of_clk_bulk_get_all(np, &domain->clks);
+		if (domain->num_clks < 0) {
+			return dev_err_probe(domain->dev, domain->num_clks,
+					     "Failed to get %s's clocks\n",
+					     slice_info[index].name);
+		}
+
+		domain->genpd.name = slice_info[index].name;
+		domain->genpd.power_off = imx93_pd_off;
+		domain->genpd.power_on = imx93_pd_on;
+		domain->slice_info = &slice_info[index];
+		domain->base = base;
+
+		is_off = readl(domain->base + slice_info->mix_off + MIX_FUNC_STAT_OFF) &
+			FUNC_STAT_ISO_STAT_MASK;
+		/* Just to sync the status of hardware */
+		if (!is_off) {
+			ret = clk_bulk_prepare_enable(domain->num_clks, domain->clks);
+			if (ret) {
+				dev_err(domain->dev, "failed to enable clocks for domain: %s\n",
+					domain->genpd.name);
+				clk_bulk_put_all(domain->num_clks, domain->clks);
+				return 0;
+			}
+		}
+
+		dev_info(dev, "%s: state: %x\n", domain->genpd.name,
+			 readl(domain->base + MIX_FUNC_STAT_OFF));
+		ret = pm_genpd_init(&domain->genpd, NULL, is_off);
+		if (ret) {
+			dev_err(dev, "failed to init genpd\n");
+			clk_bulk_put_all(domain->num_clks, domain->clks);
+			return ret;
+		}
+
+		ret = of_genpd_add_provider_simple(np, &domain->genpd);
+		if (ret) {
+			clk_bulk_put_all(domain->num_clks, domain->clks);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static const struct of_device_id imx93_dt_ids[] = {
+	{ .compatible = "fsl,imx93-src", .data = &imx93_plat_data, },
+	{ }
+};
+
+static struct platform_driver imx93_power_domain_driver = {
+	.driver = {
+		.name	= "imx93_power_domain",
+		.owner	= THIS_MODULE,
+		.of_match_table = imx93_dt_ids,
+	},
+	.probe = imx93_pd_probe,
+	.remove = imx93_pd_remove,
+};
+module_platform_driver(imx93_power_domain_driver);
+
+MODULE_AUTHOR("Peng Fan <peng.fan@nxp.com>");
+MODULE_DESCRIPTION("NXP i.MX93 power domain driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/imx/mu/Kconfig b/drivers/soc/imx/mu/Kconfig
new file mode 100644
index 000000000..890f72d15
--- /dev/null
+++ b/drivers/soc/imx/mu/Kconfig
@@ -0,0 +1,4 @@
+config SOC_IMX_MU
+	tristate "i.MX SoC MU support"
+	depends on ARCH_MXC
+	default ARCH_MXC && ARM64
diff --git a/drivers/soc/imx/mu/Makefile b/drivers/soc/imx/mu/Makefile
new file mode 100644
index 000000000..64246b130
--- /dev/null
+++ b/drivers/soc/imx/mu/Makefile
@@ -0,0 +1 @@
+obj-$(CONFIG_SOC_IMX_MU) += mx8_mu.o
diff --git a/drivers/soc/imx/mu/mx8_mu.c b/drivers/soc/imx/mu/mx8_mu.c
new file mode 100644
index 000000000..c4f9d5dfc
--- /dev/null
+++ b/drivers/soc/imx/mu/mx8_mu.c
@@ -0,0 +1,195 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017 NXP
+ *
+ * SPDX-License-Identifier:     GPL-2.0+
+ */
+
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mx8_mu.h>
+#include <linux/of.h>
+
+static int version;
+
+/*!
+ * This function sets the Flag n of the MU.
+ */
+int32_t MU_SetFn(void __iomem *base, uint32_t Fn)
+{
+	uint32_t reg, offset;
+
+	reg = Fn & (~MU_CR_Fn_MASK1);
+	if (reg > 0)
+		return -EINVAL;
+
+	offset = unlikely(version == MU_VER_ID_V10)
+			  ? MU_V10_ACR_OFFSET1 : MU_ACR_OFFSET1;
+
+	reg = readl_relaxed(base + offset);
+	/*  Clear ABFn. */
+	reg &= ~MU_CR_Fn_MASK1;
+	reg |= Fn;
+	writel_relaxed(reg, base + offset);
+
+	return 0;
+}
+
+/*!
+ * This function reads the status from status register.
+ */
+uint32_t MU_ReadStatus(void __iomem *base)
+{
+	uint32_t reg, offset;
+
+	offset = unlikely(version == MU_VER_ID_V10)
+			  ? MU_V10_ASR_OFFSET1 : MU_ASR_OFFSET1;
+
+	reg = readl_relaxed(base + offset);
+
+	return reg;
+}
+
+/*!
+ * This function enables specific RX full interrupt.
+ */
+void MU_EnableRxFullInt(void __iomem *base, uint32_t index)
+{
+	uint32_t reg, offset;
+
+	offset = unlikely(version == MU_VER_ID_V10)
+			  ? MU_V10_ACR_OFFSET1 : MU_ACR_OFFSET1;
+
+	reg = readl_relaxed(base + offset);
+	reg &= ~(MU_CR_GIRn_MASK1 | MU_CR_NMI_MASK1);
+	reg |= MU_CR_RIE0_MASK1 >> index;
+	writel_relaxed(reg, base + offset);
+}
+EXPORT_SYMBOL(MU_EnableRxFullInt);
+
+/*!
+ * This function enables specific general purpose interrupt.
+ */
+void MU_EnableGeneralInt(void __iomem *base, uint32_t index)
+{
+	uint32_t reg, offset;
+
+	offset = unlikely(version == MU_VER_ID_V10)
+			  ? MU_V10_ACR_OFFSET1 : MU_ACR_OFFSET1;
+
+	reg = readl_relaxed(base + offset);
+	reg &= ~(MU_CR_GIRn_MASK1 | MU_CR_NMI_MASK1);
+	reg |= MU_CR_GIE0_MASK1 >> index;
+	writel_relaxed(reg, base + offset);
+}
+
+/*
+ * Wait and send message to the other core.
+ */
+void MU_SendMessage(void __iomem *base, uint32_t regIndex, uint32_t msg)
+{
+	uint32_t mask = MU_SR_TE0_MASK1 >> regIndex;
+
+	if (unlikely(version == MU_VER_ID_V10)) {
+		/* Wait TX register to be empty. */
+		while (!(readl_relaxed(base + MU_V10_ASR_OFFSET1) & mask))
+			;
+		writel_relaxed(msg, base + MU_V10_ATR0_OFFSET1
+			       + (regIndex * 4));
+	} else {
+		/* Wait TX register to be empty. */
+		while (!(readl_relaxed(base + MU_ASR_OFFSET1) & mask))
+			;
+		writel_relaxed(msg, base + MU_ATR0_OFFSET1  + (regIndex * 4));
+	}
+}
+EXPORT_SYMBOL(MU_SendMessage);
+
+/*
+ * Wait and send message to the other core with timeout mechanism.
+ */
+void MU_SendMessageTimeout(void __iomem *base, uint32_t regIndex, uint32_t msg,
+		uint32_t t)
+{
+	uint32_t mask = MU_SR_TE0_MASK1 >> regIndex;
+	uint32_t timeout = t;
+
+	if (unlikely(version == MU_VER_ID_V10)) {
+		/* Wait TX register to be empty. */
+		while (!(readl_relaxed(base + MU_V10_ASR_OFFSET1) & mask)) {
+			udelay(10);
+			if (timeout-- == 0)
+				return;
+		};
+
+		writel_relaxed(msg, base + MU_V10_ATR0_OFFSET1
+			       + (regIndex * 4));
+	} else {
+		/* Wait TX register to be empty. */
+		while (!(readl_relaxed(base + MU_ASR_OFFSET1) & mask)) {
+			udelay(10);
+			if (timeout-- == 0)
+				return;
+		};
+
+		writel_relaxed(msg, base + MU_ATR0_OFFSET1  + (regIndex * 4));
+	}
+}
+EXPORT_SYMBOL(MU_SendMessageTimeout);
+
+/*
+ * Wait to receive message from the other core.
+ */
+void MU_ReceiveMsg(void __iomem *base, uint32_t regIndex, uint32_t *msg)
+{
+	uint32_t mask = MU_SR_RF0_MASK1 >> regIndex;
+
+	if (unlikely(version == MU_VER_ID_V10)) {
+		/* Wait RX register to be full. */
+		while (!(readl_relaxed(base + MU_V10_ASR_OFFSET1) & mask))
+			;
+		*msg = readl_relaxed(base + MU_V10_ARR0_OFFSET1
+				     + (regIndex * 4));
+	} else {
+		/* Wait RX register to be full. */
+		while (!(readl_relaxed(base + MU_ASR_OFFSET1) & mask))
+			;
+		*msg = readl_relaxed(base + MU_ARR0_OFFSET1 + (regIndex * 4));
+	}
+}
+EXPORT_SYMBOL(MU_ReceiveMsg);
+
+
+
+void MU_Init(void __iomem *base)
+{
+	uint32_t reg, offset;
+
+	version = readl_relaxed(base) >> 16;
+
+	offset = unlikely(version == MU_VER_ID_V10)
+			  ? MU_V10_ACR_OFFSET1 : MU_ACR_OFFSET1;
+
+	reg = readl_relaxed(base + offset);
+	/* Clear GIEn, TIEn, GIRn and ABFn. */
+	reg &= ~(MU_CR_GIEn_MASK1 | MU_CR_TIEn_MASK1
+		 | MU_CR_GIRn_MASK1 | MU_CR_NMI_MASK1 | MU_CR_Fn_MASK1);
+
+	/*
+	 * i.MX6SX and i.MX7D have multi-core power management which need
+	 * to use RIE interrupts.
+	 */
+	if (!(of_machine_is_compatible("fsl,imx6sx") ||
+		of_machine_is_compatible("fsl,imx7d")))
+		reg &= ~MU_CR_RIEn_MASK1;
+
+	writel_relaxed(reg, base + offset);
+}
+EXPORT_SYMBOL(MU_Init);
+MODULE_DESCRIPTION("i.MX8 SoC MU driver");
+MODULE_LICENSE("GPL v2");
+
+/**@}*/
+
diff --git a/drivers/soc/imx/rpmsg_life_cycle.c b/drivers/soc/imx/rpmsg_life_cycle.c
new file mode 100644
index 000000000..e3d540f15
--- /dev/null
+++ b/drivers/soc/imx/rpmsg_life_cycle.c
@@ -0,0 +1,120 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ */
+
+#include <linux/cpu.h>
+#include <linux/imx_rpmsg.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/reboot.h>
+#include <linux/rpmsg.h>
+
+#define PM_RPMSG_TYPE		0
+
+struct pm_rpmsg_data {
+	struct imx_rpmsg_head header;
+	u8 data;
+	u8 reserved;
+} __packed;
+
+enum pm_rpmsg_cmd {
+	PM_RPMSG_MODE,
+};
+
+enum pm_rpmsg_power_mode {
+	PM_RPMSG_SHUTDOWN = 7,
+};
+
+static struct rpmsg_device *life_cycle_rpdev;
+
+static int rpmsg_life_cycle_notifier(struct notifier_block *nb,
+		unsigned long action, void *unused)
+{
+	int ret;
+#ifdef CONFIG_HOTPLUG_CPU
+	int cpu;
+#endif
+	struct pm_rpmsg_data msg;
+
+	/* return early if it is RESTART case */
+	if (action == SYS_RESTART)
+		return NOTIFY_DONE;
+
+	/*
+	 * unplug the non-boot cpu to make sure A35 cluster can be
+	 * put into DPD mode without risk.
+	 */
+
+#ifdef CONFIG_HOTPLUG_CPU
+	for_each_online_cpu(cpu) {
+		if (cpu == cpumask_first(cpu_online_mask))
+			continue;
+		ret = remove_cpu(cpu);
+		if (ret) {
+			pr_info("unplug the non-boot cpu failed:%d\n", ret);
+			return NOTIFY_BAD;
+		}
+	}
+#endif
+	msg.header.cate = IMX_RMPSG_LIFECYCLE;
+	msg.header.major = IMX_RMPSG_MAJOR;
+	msg.header.minor = IMX_RMPSG_MINOR;
+	msg.header.type = PM_RPMSG_TYPE;
+	msg.header.cmd = PM_RPMSG_MODE;
+	msg.data = PM_RPMSG_SHUTDOWN;
+
+	/* No ACK from M core */
+	ret = rpmsg_send(life_cycle_rpdev->ept, &msg, sizeof(struct pm_rpmsg_data));
+
+	if (ret) {
+		pr_info("rpmsg send failed:%d\n", ret);
+		return NOTIFY_BAD;
+	}
+
+	return NOTIFY_DONE;
+};
+
+static struct notifier_block rpmsg_life_cycle_nb = {
+	.notifier_call = rpmsg_life_cycle_notifier,
+};
+
+static int rpmsg_life_cycle_cb(struct rpmsg_device *rpdev, void *data, int len,
+				void *priv, u32 src)
+{
+	return 0;
+}
+
+static int rpmsg_life_cycle_probe(struct rpmsg_device *rpdev)
+{
+
+	life_cycle_rpdev = rpdev;
+
+	dev_info(&rpdev->dev, "new channel: 0x%x -> 0x%x!\n",
+			rpdev->src, rpdev->dst);
+
+	return register_reboot_notifier(&rpmsg_life_cycle_nb);
+}
+
+static struct rpmsg_device_id rpmsg_life_cycle_id_table[] = {
+	{ .name = "rpmsg-life-cycle-channel" },
+	{ },
+};
+
+static struct rpmsg_driver rpmsg_life_cycle_driver = {
+	.drv.name = 	"rpmsg_life_cycle",
+	.drv.owner	= THIS_MODULE,
+	.id_table	= rpmsg_life_cycle_id_table,
+	.probe		= rpmsg_life_cycle_probe,
+	.callback	= rpmsg_life_cycle_cb,
+};
+
+static int __init rpmsg_life_cycle_init(void)
+{
+	return register_rpmsg_driver(&rpmsg_life_cycle_driver);
+};
+module_init(rpmsg_life_cycle_init);
+
+MODULE_AUTHOR("NXP Semiconductor");
+MODULE_DESCRIPTION("NXP rpmsg life cycle driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/soc/imx/secvio/Makefile b/drivers/soc/imx/secvio/Makefile
new file mode 100644
index 000000000..d5a89ba24
--- /dev/null
+++ b/drivers/soc/imx/secvio/Makefile
@@ -0,0 +1,3 @@
+obj-y +=  imx-secvio-sc.o
+obj-$(CONFIG_DEBUG_FS) += imx-secvio-debugfs.o
+obj-$(CONFIG_AUDIT) += imx-secvio-audit.o
diff --git a/drivers/soc/imx/secvio/imx-secvio-audit.c b/drivers/soc/imx/secvio/imx-secvio-audit.c
new file mode 100644
index 000000000..e3c513114
--- /dev/null
+++ b/drivers/soc/imx/secvio/imx-secvio-audit.c
@@ -0,0 +1,31 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ *
+ */
+
+#include <linux/audit.h>
+
+#include <soc/imx/imx-secvio-sc.h>
+
+int report_to_audit_notify(struct notifier_block *nb, unsigned long status,
+			   void *notif_info)
+{
+	int ret = 0;
+	struct audit_buffer *ab;
+	struct secvio_sc_notifier_info *info = notif_info;
+
+	ab = audit_log_start(audit_context(), GFP_KERNEL, AUDIT_INTEGRITY_RULE);
+	if (!ab) {
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	audit_log_format(ab, " hpsvs=0x%.08x lps=0x%.08x lptds=0x%.08x",
+			 info->hpsvs, info->lps, info->lptds);
+	audit_log_task_info(ab);
+	audit_log_end(ab);
+
+exit:
+	return ret;
+}
diff --git a/drivers/soc/imx/secvio/imx-secvio-debugfs.c b/drivers/soc/imx/secvio/imx-secvio-debugfs.c
new file mode 100644
index 000000000..a7ce1a98e
--- /dev/null
+++ b/drivers/soc/imx/secvio/imx-secvio-debugfs.c
@@ -0,0 +1,283 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ *
+ */
+
+/*
+ * The module exposes 3 files in debugfs:
+ *  - secvio/info:
+ *      * Read: It returns the value of the fuses and SNVS registers which are
+ *              readable and related to secvio and tampers
+ *      * Write: A write of the format "<hex id> [<hex value 0> <hex value 1>
+ *               <hex value 2> <hex value 3> <hex value 4>](<nb values>)"
+ *               will write the SNVS register having the provided id with the
+ *               values provided (cf SECO ducumentation)
+ *  - secvio/enable: State of the IRQ
+ *  - secvio/check: Check the state of the security violation and tampers
+ *                  and calls notifier
+ *  - secvio/clear: Clear the state of all secvio and tampers
+ */
+
+/* Includes */
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/nvmem-consumer.h>
+
+#include <linux/firmware/imx/svc/misc.h>
+#include <linux/firmware/imx/svc/seco.h>
+
+#include <soc/imx/imx-secvio-sc.h>
+#include "imx-secvio-sc-int.h"
+
+int fuse_reader(struct device *dev, u32 id, u32 *value, u8 mul)
+{
+	struct imx_secvio_sc_data *data = dev_get_drvdata(dev);
+	u32 size_to_read = mul * sizeof(u32);
+	int ret;
+
+	ret = nvmem_device_read(data->nvmem, id, size_to_read, value);
+	if (ret < 0) {
+		dev_err(data->dev, "Failed to read fuse %d: %d\n", id, ret);
+		return ret;
+	}
+
+	if (ret != size_to_read) {
+		dev_err(data->dev, "Read only %d instead of %d\n", ret,
+			size_to_read);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+int snvs_reader(struct device *dev, u32 id, u32 *value, u8 mul)
+{
+	int ret;
+	u32 *v1, *v2, *v3, *v4, *v5;
+
+	v1 = NULL;
+	v2 = NULL;
+	v3 = NULL;
+	v4 = NULL;
+	v5 = NULL;
+
+	switch (mul) {
+	case 5:
+		v5 = &value[4];
+		fallthrough;
+	case 4:
+		v4 = &value[3];
+		fallthrough;
+	case 3:
+		v3 = &value[2];
+		fallthrough;
+	case 2:
+		v2 = &value[1];
+		fallthrough;
+	case 1:
+		v1 = &value[0];
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	ret = call_secvio_config(dev, id, SECVIO_CONFIG_READ, v1, v2, v3, v4,
+				 v5, mul);
+	if (ret < 0)
+		dev_err(dev, "Failed to read snvs reg %d: %d\n", id, ret);
+
+	return ret;
+}
+
+int snvs_dgo_reader(struct device *dev, u32 id, u32 *value, u8 mul)
+{
+	struct imx_secvio_sc_data *data = dev_get_drvdata(dev);
+	int ret;
+
+	if (mul != 1)
+		return -EINVAL;
+
+	ret = imx_sc_seco_secvio_dgo_config(data->ipc_handle, id,
+					    SECVIO_CONFIG_READ, value);
+	if (ret)
+		dev_err(dev, "Failed to read snvs dgo reg %d: %d\n", id, ret);
+
+	return ret;
+}
+
+static const struct imx_secvio_info_entry {
+	int (*reader)(struct device *dev, u32 id, u32 *value, u8 mul);
+	const char *type;
+	const char *name;
+	u32 id;
+	u8 mul;
+} gs_imx_secvio_info_list[] = {
+	{fuse_reader, "fuse", "trim", 30, 1},
+	{fuse_reader, "fuse", "trim2", 31, 1},
+	{fuse_reader, "fuse", "ctrim1", 260, 1},
+	{fuse_reader, "fuse", "ctrim2", 261, 1},
+	{fuse_reader, "fuse", "ctrim3", 262, 1},
+	{fuse_reader, "fuse", "ctrim4", 263, 1},
+	{fuse_reader, "fuse", "OSC_CAP", 768, 1},
+
+	{snvs_reader, "snvs", "HPLR",    0x0, 1},
+	{snvs_reader, "snvs", "LPLR",    0x34, 1},
+	{snvs_reader, "snvs", "HPSICR",  0xc, 1},
+	{snvs_reader, "snvs", "HPSVCR",  0x10, 1},
+	{snvs_reader, "snvs", "HPSVS",   0x18, 1},
+	{snvs_reader, "snvs", "LPSVC",   0x40, 1},
+	{snvs_reader, "snvs", "LPTDC",   0x48, 2},
+	{snvs_reader, "snvs", "LPSR",    0x4c, 1},
+	{snvs_reader, "snvs", "LPTDS",   0xa4, 1},
+	{snvs_reader, "snvs", "LPTGFC",  0x44, 3},
+	{snvs_reader, "snvs", "LPATCTL", 0xe0, 1},
+	{snvs_reader, "snvs", "LPATCLK", 0xe4, 1},
+	{snvs_reader, "snvs", "LPATRC1", 0xe8, 2},
+	{snvs_reader, "snvs", "LPMKC",   0x3c, 1},
+	{snvs_reader, "snvs", "LPSMC",   0x5c, 2},
+	{snvs_reader, "snvs", "LPPGD",   0x64, 1},
+	{snvs_reader, "snvs", "HPVID",   0xf8, 2},
+
+	{snvs_dgo_reader, "dgo", "Offset",  0x0, 1},
+	{snvs_dgo_reader, "dgo", "PUP/PD",  0x10, 1},
+	{snvs_dgo_reader, "dgo", "Anatest", 0x20, 1},
+	{snvs_dgo_reader, "dgo", "T trim",  0x30, 1},
+	{snvs_dgo_reader, "dgo", "Misc",    0x40, 1},
+	{snvs_dgo_reader, "dgo", "Vmon",    0x50, 1},
+};
+
+struct imx_secvio_sc_info_seq_data {
+	struct device *dev;
+	const struct imx_secvio_info_entry *list;
+	int size;
+};
+
+static void *imx_secvio_sc_info_seq_start(struct seq_file *m, loff_t *pos)
+{
+	struct imx_secvio_sc_info_seq_data *data = m->private;
+
+	/* Check we are not out of bound */
+	if (*pos >= data->size)
+		return NULL;
+
+	return (void *)pos;
+}
+
+static void *imx_secvio_sc_info_seq_next(struct seq_file *m, void *v, loff_t *pos)
+{
+	/* Increment the counter */
+	++*pos;
+
+	/* call the start function which will check the index */
+	return imx_secvio_sc_info_seq_start(m, pos);
+}
+
+static void imx_secvio_sc_info_seq_stop(struct seq_file *m, void *v)
+{
+}
+
+static int imx_secvio_sc_info_seq_show(struct seq_file *m, void *v)
+{
+	struct imx_secvio_sc_info_seq_data *data = m->private;
+	const struct imx_secvio_info_entry *e;
+	int ret;
+	u32 vals[5];
+	int idx;
+
+	idx = *(loff_t *)v;
+	e = &data->list[idx];
+
+	/* Read the values */
+	ret = e->reader(data->dev, e->id, (u32 *)&vals, e->mul);
+	if (ret) {
+		dev_err(data->dev, "Fail to read %s %s (idx %d)\n", e->type,
+			e->name, e->id);
+		return 0;
+	}
+
+	seq_printf(m, "%5s/%-10s(%.3d):", e->type, e->name, e->id);
+
+	/* Loop over the values */
+	for (idx = 0; idx < e->mul; idx++)
+		seq_printf(m, " %.8x", vals[idx]);
+
+	seq_puts(m, "\n");
+
+	return 0;
+}
+
+static const struct seq_operations imx_secvio_sc_info_seq_ops = {
+	.start = imx_secvio_sc_info_seq_start,
+	.next  = imx_secvio_sc_info_seq_next,
+	.stop  = imx_secvio_sc_info_seq_stop,
+	.show  = imx_secvio_sc_info_seq_show,
+};
+
+static int imx_secvio_sc_info_open(struct inode *inode, struct file *file)
+{
+	struct imx_secvio_sc_info_seq_data *data;
+
+	data = __seq_open_private(file, &imx_secvio_sc_info_seq_ops, sizeof(*data));
+	if (!data)
+		return -ENOMEM;
+
+	data->dev = inode->i_private;
+	data->list = gs_imx_secvio_info_list;
+	data->size = ARRAY_SIZE(gs_imx_secvio_info_list);
+
+	return 0;
+}
+
+static const struct file_operations imx_secvio_sc_info_ops = {
+	.owner = THIS_MODULE,
+	.open = imx_secvio_sc_info_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release_private,
+};
+
+static void if_debugfs_remove_recursive(void *dentry)
+{
+	debugfs_remove_recursive(dentry);
+}
+
+int imx_secvio_sc_debugfs(struct device *dev)
+{
+	struct imx_secvio_sc_data *data = dev_get_drvdata(dev);
+	struct dentry *dir;
+	int ret = 0;
+
+	/* Create a folder */
+	dir = debugfs_create_dir(dev_name(dev), NULL);
+	if (IS_ERR(dir)) {
+		dev_err(dev, "Failed to create dfs dir\n");
+		ret = PTR_ERR(dir);
+		goto exit;
+	}
+	data->dfs = dir;
+
+	ret = devm_add_action(dev, if_debugfs_remove_recursive, data->dfs);
+	if (ret) {
+		dev_err(dev, "Failed to add managed action to disable IRQ\n");
+		goto remove_fs;
+	}
+
+	/* Create the file to read info and write to reg */
+	dir = debugfs_create_file("info", 0x666, data->dfs, dev,
+				  &imx_secvio_sc_info_ops);
+	if (IS_ERR(dir)) {
+		dev_err(dev, "Failed to add info to debugfs\n");
+		ret = PTR_ERR(dir);
+		goto exit;
+	}
+
+exit:
+	return ret;
+
+remove_fs:
+	debugfs_remove_recursive(data->dfs);
+	goto exit;
+}
diff --git a/drivers/soc/imx/secvio/imx-secvio-sc-int.h b/drivers/soc/imx/secvio/imx-secvio-sc-int.h
new file mode 100644
index 000000000..3152ec246
--- /dev/null
+++ b/drivers/soc/imx/secvio/imx-secvio-sc-int.h
@@ -0,0 +1,83 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2019 NXP
+ */
+
+#ifndef SECVIO_SC_H
+#define SECVIO_SC_H
+
+/* Includes */
+#include <linux/kernel.h>
+#include <linux/notifier.h>
+#include <linux/semaphore.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/miscdevice.h>
+
+/* Access for sc_seco_secvio_config API */
+#define SECVIO_CONFIG_READ  0
+#define SECVIO_CONFIG_WRITE 1
+
+/* Internal Structure */
+struct imx_secvio_sc_data {
+	struct device *dev;
+
+	struct imx_sc_ipc *ipc_handle;
+
+	struct notifier_block irq_nb;
+	struct notifier_block report_nb;
+	struct notifier_block audit_nb;
+
+	struct nvmem_device *nvmem;
+
+	struct miscdevice miscdev;
+
+#ifdef CONFIG_DEBUG_FS
+	struct dentry *dfs;
+#endif
+
+	u32 version;
+};
+
+/* Function declarations */
+extern
+int call_secvio_config(struct device *dev, u8 id, u8 access, u32 *data0,
+		       u32 *data1, u32 *data2, u32 *data3, u32 *data4, u8 size);
+
+extern
+int int_imx_secvio_sc_get_state(struct device *dev,
+				struct secvio_sc_notifier_info *info);
+
+extern
+int int_imx_secvio_sc_clear_state(struct device *dev, u32 hpsvs, u32 lps,
+				  u32 lptds);
+
+extern
+int int_imx_secvio_sc_enable_irq(struct device *dev);
+
+extern
+int int_imx_secvio_sc_disable_irq(struct device *dev);
+
+#ifdef CONFIG_DEBUG_FS
+extern
+int imx_secvio_sc_debugfs(struct device *dev);
+#else
+static inline
+int imx_secvio_sc_debugfs(struct device *dev)
+{
+	return 0;
+}
+#endif /* CONFIG_DEBUG_FS */
+
+#ifdef CONFIG_AUDIT
+int report_to_audit_notify(struct notifier_block *nb, unsigned long status,
+			   void *notif_info);
+#else /* CONFIG_AUDIT */
+static inline
+int report_to_audit_notify(struct notifier_block *nb, unsigned long status,
+			   void *notif_info)
+{
+	return 0;
+}
+#endif /* CONFIG_AUDIT */
+
+#endif /* SECVIO_SC_H */
diff --git a/drivers/soc/imx/secvio/imx-secvio-sc.c b/drivers/soc/imx/secvio/imx-secvio-sc.c
new file mode 100644
index 000000000..ccf4c1a6f
--- /dev/null
+++ b/drivers/soc/imx/secvio/imx-secvio-sc.c
@@ -0,0 +1,675 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright 2019 NXP
+ *
+ */
+
+/*
+ * The i.MX8QXP SoC contains the Secure Non-Volatile Storage (SNVS) block. This
+ * block can detect specific hardware attacks. Due to the presence of the SECO,
+ * this block can only be accessible using the SCFW API.
+ *
+ * This module interact with the SCU which relay request to/from the SNVS block
+ * to detect if security violation occurred.
+ *
+ * The module exports an API to add processing when a SV is detected:
+ *  - register_imx_secvio_sc_notifier
+ *  - unregister_imx_secvio_sc_notifier
+ *  - imx_secvio_sc_check_state
+ *  - int_imx_secvio_sc_clear_state
+ *  - imx_secvio_sc_enable_irq
+ *  - imx_secvio_sc_disable_irq
+ */
+
+/* Includes */
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/notifier.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/uaccess.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/miscdevice.h>
+
+#include <linux/firmware/imx/ipc.h>
+#include <linux/firmware/imx/sci.h>
+#include <linux/firmware/imx/svc/seco.h>
+#include <linux/firmware/imx/svc/rm.h>
+#include <dt-bindings/firmware/imx/rsrc.h>
+
+#include <soc/imx/imx-secvio-sc.h>
+#include "imx-secvio-sc-int.h"
+
+/* Definitions */
+
+/* Reference on the driver_device */
+static struct device *gs_imx_secvio_sc_dev;
+
+/* Register IDs for sc_seco_secvio_config API */
+#define HPSVS_ID 0x18
+#define LPS_ID 0x4c
+#define LPTDS_ID 0xa4
+#define HPVIDR_ID 0xf8
+
+#define SECO_MINOR_VERSION_SUPPORT_SECVIO_TAMPER 0x53
+#define SECO_VERSION_MINOR_MASK GENMASK(15, 0)
+
+/* Notifier list for new CB */
+static BLOCKING_NOTIFIER_HEAD(imx_secvio_sc_notifier_chain);
+
+int register_imx_secvio_sc_notifier(struct notifier_block *nb)
+{
+	return blocking_notifier_chain_register(&imx_secvio_sc_notifier_chain,
+						nb);
+}
+EXPORT_SYMBOL(register_imx_secvio_sc_notifier);
+
+int unregister_imx_secvio_sc_notifier(struct notifier_block *nb)
+{
+	return blocking_notifier_chain_unregister(&imx_secvio_sc_notifier_chain,
+						  nb);
+}
+EXPORT_SYMBOL(unregister_imx_secvio_sc_notifier);
+
+static void if_imx_scu_irq_register_notifier(void *nb)
+{
+	imx_scu_irq_register_notifier(nb);
+}
+
+static void if_unregister_imx_secvio_sc_notifier(void *nb)
+{
+	unregister_imx_secvio_sc_notifier(nb);
+}
+
+static
+int imx_secvio_sc_notifier_call_chain(struct secvio_sc_notifier_info *info)
+{
+	return blocking_notifier_call_chain(&imx_secvio_sc_notifier_chain, 0,
+					    (void *)info);
+}
+
+int int_imx_secvio_sc_get_state(struct device *dev,
+				struct secvio_sc_notifier_info *info)
+{
+	struct secvio_sc_notifier_info _info = {0};
+	struct secvio_sc_notifier_info *p_info;
+	int ret = 0, ret2 = 0;
+
+	p_info = info ? info : &_info;
+
+	/* Read secvio status */
+	ret = call_secvio_config(dev, HPSVS_ID, SECVIO_CONFIG_READ,
+				 &p_info->hpsvs, NULL, NULL, NULL, NULL, 1);
+	if (ret) {
+		ret2 = ret;
+		dev_err(dev, "Cannot read secvio status: %d\n", ret);
+	}
+	p_info->hpsvs &= HPSVS__ALL_SV__MASK;
+
+	/* Read tampers status */
+	ret = call_secvio_config(dev, LPS_ID, SECVIO_CONFIG_READ,
+				 &p_info->lps, NULL, NULL, NULL, NULL, 1);
+	if (ret) {
+		ret2 = ret;
+		dev_err(dev, "Cannot read tamper 1 status: %d\n", ret);
+	}
+	p_info->lps &= LPS__ALL_TP__MASK;
+
+	ret = call_secvio_config(dev, LPTDS_ID, SECVIO_CONFIG_READ,
+				 &p_info->lptds, NULL, NULL, NULL, NULL, 1);
+	if (ret) {
+		ret2 = ret;
+		dev_err(dev, "Cannot read  tamper 2 status: %d\n", ret);
+	}
+	p_info->lptds &= LPTDS__ALL_TP__MASK;
+
+	dev_dbg(dev, "Status: %.8x, %.8x, %.8x\n", p_info->hpsvs,
+		p_info->lps, p_info->lptds);
+
+	return ret2;
+}
+
+inline int imx_secvio_sc_get_state(struct secvio_sc_notifier_info *info)
+{
+	return int_imx_secvio_sc_get_state(gs_imx_secvio_sc_dev, info);
+}
+EXPORT_SYMBOL(imx_secvio_sc_get_state);
+
+int int_imx_secvio_sc_check_state(struct device *dev)
+{
+	struct secvio_sc_notifier_info info = {0};
+	int ret = 0;
+
+	ret = int_imx_secvio_sc_get_state(dev, &info);
+	if (ret) {
+		dev_err(dev, "Failed to get secvio state\n");
+		goto exit;
+	}
+
+	/* Call chain of CB registered to this module if status detected */
+	if (info.hpsvs || info.lps || info.lptds)
+		if (imx_secvio_sc_notifier_call_chain(&info))
+			dev_warn(dev,
+				 "Issues when calling the notifier chain\n");
+
+exit:
+	return ret;
+}
+
+inline int imx_secvio_sc_check_state(void)
+{
+	return int_imx_secvio_sc_check_state(gs_imx_secvio_sc_dev);
+}
+EXPORT_SYMBOL(imx_secvio_sc_check_state);
+
+static int imx_secvio_sc_notify(struct notifier_block *nb,
+				unsigned long event, void *group)
+{
+	struct imx_secvio_sc_data *data =
+				container_of(nb, struct imx_secvio_sc_data,
+					     irq_nb);
+	struct device *dev = data->dev;
+	int ret = 0;
+
+	/* Filter event for us */
+	if (!((event & IMX_SC_IRQ_SECVIO) &&
+	      (*(u8 *)group == IMX_SC_IRQ_GROUP_WAKE)))
+		goto exit;
+
+	dev_warn(dev, "secvio security violation detected\n");
+
+	ret = int_imx_secvio_sc_check_state(dev);
+
+	/* Re-enable interrupt */
+	ret = int_imx_secvio_sc_enable_irq(dev);
+	if (ret)
+		dev_err(dev, "Failed to enable IRQ\n");
+
+exit:
+	return ret;
+}
+
+int int_imx_secvio_sc_clear_state(struct device *dev, u32 hpsvs, u32 lps,
+				  u32 lptds)
+{
+	int ret = 0;
+
+	if (!dev)
+		return -EINVAL;
+
+	ret = call_secvio_config(dev, HPSVS_ID, SECVIO_CONFIG_WRITE, &hpsvs,
+				 NULL, NULL, NULL, NULL, 1);
+	if (ret) {
+		dev_err(dev, "Cannot clear secvio status: %d\n", ret);
+		goto exit;
+	}
+
+	ret = call_secvio_config(dev, LPS_ID, SECVIO_CONFIG_WRITE, &lps, NULL,
+				 NULL, NULL, NULL, 1);
+	if (ret) {
+		dev_err(dev, "Cannot clear tamper 1 status: %d\n", ret);
+		goto exit;
+	}
+
+	ret = call_secvio_config(dev, LPTDS_ID, SECVIO_CONFIG_WRITE, &lptds,
+				 NULL, NULL, NULL, NULL, 1);
+	if (ret) {
+		dev_err(dev, "Cannot clear tamper 2 status: %d\n", ret);
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+inline int imx_secvio_sc_clear_state(u32 hpsvs, u32 lps, u32 lptds)
+{
+	return int_imx_secvio_sc_clear_state(gs_imx_secvio_sc_dev, hpsvs, lps,
+					     lptds);
+}
+EXPORT_SYMBOL(imx_secvio_sc_clear_state);
+
+static int report_to_user_notify(struct notifier_block *nb,
+				 unsigned long status, void *notif_info)
+{
+	struct secvio_sc_notifier_info *info = notif_info;
+	struct imx_secvio_sc_data *data =
+				container_of(nb, struct imx_secvio_sc_data,
+					     report_nb);
+	struct device *dev = data->dev;
+
+	/* Information about the security violation */
+	if (info->hpsvs & HPSVS__LP_SEC_VIO__MASK)
+		dev_info(dev, "SNVS secvio: LPSV\n");
+	if (info->hpsvs & HPSVS__SW_LPSV__MASK)
+		dev_info(dev, "SNVS secvio: SW LPSV\n");
+	if (info->hpsvs & HPSVS__SW_FSV__MASK)
+		dev_info(dev, "SNVS secvio: SW FSV\n");
+	if (info->hpsvs & HPSVS__SW_SV__MASK)
+		dev_info(dev, "SNVS secvio: SW SV\n");
+	if (info->hpsvs & HPSVS__SV5__MASK)
+		dev_info(dev, "SNVS secvio: SV 5\n");
+	if (info->hpsvs & HPSVS__SV4__MASK)
+		dev_info(dev, "SNVS secvio: SV 4\n");
+	if (info->hpsvs & HPSVS__SV3__MASK)
+		dev_info(dev, "SNVS secvio: SV 3\n");
+	if (info->hpsvs & HPSVS__SV2__MASK)
+		dev_info(dev, "SNVS secvio: SV 2\n");
+	if (info->hpsvs & HPSVS__SV1__MASK)
+		dev_info(dev, "SNVS secvio: SV 1\n");
+	if (info->hpsvs & HPSVS__SV0__MASK)
+		dev_info(dev, "SNVS secvio: SV 0\n");
+
+	/* Information about the tampers */
+	if (info->lps & LPS__ESVD__MASK)
+		dev_info(dev, "SNVS tamper: External SV\n");
+	if (info->lps & LPS__ET2D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 2\n");
+	if (info->lps & LPS__ET1D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 1\n");
+	if (info->lps & LPS__WMT2D__MASK)
+		dev_info(dev, "SNVS tamper: Wire Mesh 2\n");
+	if (info->lps & LPS__WMT1D__MASK)
+		dev_info(dev, "SNVS tamper: Wire Mesh 1\n");
+	if (info->lps & LPS__VTD__MASK)
+		dev_info(dev, "SNVS tamper: Voltage\n");
+	if (info->lps & LPS__TTD__MASK)
+		dev_info(dev, "SNVS tamper: Temperature\n");
+	if (info->lps & LPS__CTD__MASK)
+		dev_info(dev, "SNVS tamper: Clock\n");
+	if (info->lps & LPS__PGD__MASK)
+		dev_info(dev, "SNVS tamper: Power Glitch\n");
+	if (info->lps & LPS__MCR__MASK)
+		dev_info(dev, "SNVS tamper: Monotonic Counter rollover\n");
+	if (info->lps & LPS__SRTCR__MASK)
+		dev_info(dev, "SNVS tamper: Secure RTC rollover\n");
+	if (info->lps & LPS__LPTA__MASK)
+		dev_info(dev, "SNVS tamper: Time alarm\n");
+
+	if (info->lptds & LPTDS__ET10D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 10\n");
+	if (info->lptds & LPTDS__ET9D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 9\n");
+	if (info->lptds & LPTDS__ET8D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 8\n");
+	if (info->lptds & LPTDS__ET7D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 7\n");
+	if (info->lptds & LPTDS__ET6D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 6\n");
+	if (info->lptds & LPTDS__ET5D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 5\n");
+	if (info->lptds & LPTDS__ET4D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 4\n");
+	if (info->lptds & LPTDS__ET3D__MASK)
+		dev_info(dev, "SNVS tamper: Tamper 3\n");
+
+	return 0;
+}
+
+int call_secvio_config(struct device *dev, u8 id, u8 access, u32 *data0,
+		       u32 *data1, u32 *data2, u32 *data3, u32 *data4, u8 size)
+{
+	int ret = 0;
+	struct imx_secvio_sc_data *data;
+
+	if (!dev)
+		return -EINVAL;
+
+	data = dev_get_drvdata(dev);
+
+	ret = imx_sc_seco_secvio_config(data->ipc_handle, id, access, data0,
+					data1, data2, data3, data4, size);
+	if (ret)
+		dev_err(dev, "Fail %s secvio config %d",
+			((access) ? "write" : "read"), ret);
+
+	return ret;
+}
+
+int int_imx_secvio_sc_enable_irq(struct device *dev)
+{
+	int ret = 0, ret2;
+	u32 irq_status;
+	struct imx_secvio_sc_data *data;
+
+	if (!dev)
+		return -EINVAL;
+
+	data = dev_get_drvdata(dev);
+
+	/* Enable the IRQ */
+	ret = imx_scu_irq_group_enable(IMX_SC_IRQ_GROUP_WAKE, IMX_SC_IRQ_SECVIO,
+				       true);
+	if (ret) {
+		dev_err(dev, "Cannot enable SCU IRQ: %d\n", ret);
+		goto exit;
+	}
+
+	/* Enable interrupt */
+	ret = imx_sc_seco_secvio_enable(data->ipc_handle);
+	if (ret) {
+		dev_err(dev, "Cannot enable SNVS irq: %d\n", ret);
+		goto exit;
+	};
+
+	/* Unmask interrupt */
+	ret = imx_scu_irq_get_status(IMX_SC_IRQ_GROUP_WAKE, &irq_status);
+	if (ret) {
+		dev_err(dev, "Cannot unmask irq: %d\n", ret);
+		goto exit;
+	};
+
+exit:
+	if (ret) {
+		ret2 = int_imx_secvio_sc_disable_irq(dev);
+		if (ret2)
+			dev_warn(dev, "Failed to disable the IRQ\n");
+	}
+
+	return ret;
+}
+
+int int_imx_secvio_sc_disable_irq(struct device *dev)
+{
+	int ret = 0;
+	struct imx_secvio_sc_data *data;
+
+	if (!dev)
+		return -EINVAL;
+
+	data = dev_get_drvdata(dev);
+
+	/* Disable the IRQ */
+	ret = imx_scu_irq_group_enable(IMX_SC_IRQ_GROUP_WAKE, IMX_SC_IRQ_SECVIO,
+				       false);
+	if (ret) {
+		dev_err(dev, "Cannot disable SCU IRQ: %d\n", ret);
+		goto exit;
+	}
+
+exit:
+	return ret;
+}
+
+static void if_imx_secvio_sc_disable_irq(void *dev)
+{
+	int_imx_secvio_sc_disable_irq(dev);
+}
+
+static int imx_secvio_sc_open(struct inode *node, struct file *filp)
+{
+	filp->private_data = node->i_private;
+
+	return 0;
+}
+
+static long imx_secvio_sc_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct device *dev = file->private_data;
+	struct secvio_sc_notifier_info info;
+	int ret;
+
+	switch (cmd) {
+	case IMX_SECVIO_SC_GET_STATE:
+		ret = int_imx_secvio_sc_get_state(dev, &info);
+		if (ret) {
+			dev_err(dev, "Fail to get state\n");
+			goto exit;
+		}
+
+		ret = copy_to_user((void *)arg, &info, sizeof(info));
+		if (ret) {
+			dev_err(dev, "Fail to copy info to user\n");
+			ret = -EFAULT;
+			goto exit;
+		}
+		break;
+	case IMX_SECVIO_SC_CHECK_STATE:
+		ret = int_imx_secvio_sc_check_state(dev);
+		if (ret) {
+			dev_err(dev, "Fail to check state\n");
+			goto exit;
+		}
+		break;
+	case IMX_SECVIO_SC_CLEAR_STATE:
+		ret = copy_from_user(&info, (void *)arg, sizeof(info));
+		if (ret) {
+			dev_err(dev, "Fail to copy info from user\n");
+			ret = -EFAULT;
+			goto exit;
+		}
+
+		ret = int_imx_secvio_sc_clear_state(dev, info.hpsvs, info.lps,
+						    info.lptds);
+		if (ret) {
+			dev_err(dev, "Fail to clear state\n");
+			goto exit;
+		}
+		break;
+	default:
+		ret = -ENOIOCTLCMD;
+	}
+
+exit:
+	return ret;
+}
+
+const static struct file_operations imx_secvio_sc_fops = {
+	.owner = THIS_MODULE,
+	.open = imx_secvio_sc_open,
+	.unlocked_ioctl = imx_secvio_sc_ioctl,
+};
+
+static void if_misc_deregister(void *miscdevice)
+{
+	misc_deregister(miscdevice);
+}
+
+static int imx_secvio_sc_setup(struct device *dev)
+{
+	struct imx_secvio_sc_data *data;
+	u32 seco_version = 0;
+	bool own_secvio;
+	u32 irq_status;
+	int ret = 0;
+
+	if (!devres_open_group(dev, NULL, GFP_KERNEL)) {
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	/* Allocate private data */
+	data = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		ret = -ENOMEM;
+		dev_err(dev, "Failed to allocate mem for data\n");
+		goto clean;
+	}
+
+	data->dev = dev;
+
+	dev_set_drvdata(dev, data);
+
+	data->nvmem = devm_nvmem_device_get(dev, NULL);
+	if (IS_ERR(data->nvmem)) {
+		ret = PTR_ERR(data->nvmem);
+
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "Failed to retrieve nvmem\n");
+
+		goto clean;
+	}
+
+	/* Get a handle */
+	ret = imx_scu_get_handle(&data->ipc_handle);
+	if (ret) {
+		dev_err(dev, "cannot get handle to scu: %d\n", ret);
+		goto clean;
+	};
+
+	/* Check the version of the SECO */
+	ret = imx_sc_seco_build_info(data->ipc_handle, &seco_version, NULL);
+	if (ret) {
+		dev_err(dev, "Failed to get seco version\n");
+		goto clean;
+	}
+
+	if ((seco_version & SECO_VERSION_MINOR_MASK) <
+	     SECO_MINOR_VERSION_SUPPORT_SECVIO_TAMPER) {
+		dev_err(dev, "SECO version %.8x doesn't support all secvio\n",
+			seco_version);
+		ret = -EOPNOTSUPP;
+		goto clean;
+	}
+
+	/* Init debug FS */
+	ret = imx_secvio_sc_debugfs(dev);
+	if (ret) {
+		dev_err(dev, "Failed to set debugfs\n");
+		goto clean;
+	}
+
+	/* Check we own the SECVIO */
+	ret = imx_sc_rm_is_resource_owned(data->ipc_handle, IMX_SC_R_SECVIO);
+	if (ret < 0) {
+		dev_err(dev, "Failed to retrieve secvio ownership\n");
+		goto clean;
+	}
+
+	own_secvio = ret > 0;
+	if (!own_secvio) {
+		dev_err(dev, "Secvio resource is not owned\n");
+		ret = -EPERM;
+		goto clean;
+	}
+
+	/* Check IRQ exists and enable it */
+	ret = imx_scu_irq_get_status(IMX_SC_IRQ_GROUP_WAKE, &irq_status);
+	if (ret) {
+		dev_err(dev, "Cannot get IRQ state: %d\n", ret);
+		goto clean;
+	}
+
+	ret = int_imx_secvio_sc_enable_irq(dev);
+	if (ret) {
+		dev_err(dev, "Failed to enable IRQ\n");
+		goto clean;
+	}
+
+	ret = devm_add_action_or_reset(dev, if_imx_secvio_sc_disable_irq, dev);
+	if (ret) {
+		dev_err(dev, "Failed to add managed action to disable IRQ\n");
+		goto clean;
+	}
+
+	/* Register the notifier for IRQ from SNVS */
+	data->irq_nb.notifier_call = imx_secvio_sc_notify;
+	ret = imx_scu_irq_register_notifier(&data->irq_nb);
+	if (ret) {
+		dev_err(dev, "Failed to register IRQ notification handler\n");
+		goto clean;
+	}
+
+	ret = devm_add_action_or_reset(dev, if_imx_scu_irq_register_notifier,
+				       &data->irq_nb);
+	if (ret) {
+		dev_err(dev, "Failed to add action to remove irq notif\n");
+		goto clean;
+	}
+
+	/* Register the notification for reporting to user */
+	data->report_nb.notifier_call = report_to_user_notify;
+	ret = register_imx_secvio_sc_notifier(&data->report_nb);
+	if (ret) {
+		dev_err(dev, "Failed to register report notif handler\n");
+		goto clean;
+	}
+
+	ret = devm_add_action_or_reset(dev, if_unregister_imx_secvio_sc_notifier,
+				       &data->report_nb);
+	if (ret) {
+		dev_err(dev, "Failed to add action to remove report notif\n");
+		goto clean;
+	}
+
+	/* Register the notification to report to audit FW */
+	data->audit_nb.notifier_call = report_to_audit_notify;
+	ret = register_imx_secvio_sc_notifier(&data->audit_nb);
+	if (ret) {
+		dev_err(dev, "Failed to register report audit handler\n");
+		goto clean;
+	}
+
+	ret = devm_add_action(dev, if_unregister_imx_secvio_sc_notifier,
+			      &data->audit_nb);
+	if (ret) {
+		dev_err(dev, "Failed to add action to remove audit notif\n");
+		goto clean;
+	}
+
+	/* Register misc device for IOCTL */
+	data->miscdev.name = devm_kstrdup(dev, "secvio-sc", GFP_KERNEL);
+	data->miscdev.minor = MISC_DYNAMIC_MINOR;
+	data->miscdev.fops = &imx_secvio_sc_fops;
+	data->miscdev.parent = dev;
+	ret = misc_register(&data->miscdev);
+	if (ret) {
+		dev_err(dev, "failed to register misc device\n");
+		goto exit;
+	}
+
+	ret = devm_add_action_or_reset(dev, if_misc_deregister, &data->miscdev);
+	if (ret) {
+		dev_err(dev, "Failed to add action to unregister miscdev\n");
+		goto clean;
+	}
+
+	gs_imx_secvio_sc_dev = dev;
+
+	/* Process current state of the secvio and tampers */
+	int_imx_secvio_sc_check_state(dev);
+
+	devres_remove_group(dev, NULL);
+
+	goto exit;
+
+clean:
+	devres_release_group(dev, NULL);
+
+exit:
+	return ret;
+}
+
+static int imx_secvio_sc_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct device *dev = &pdev->dev;
+
+	ret = imx_secvio_sc_setup(dev);
+	if (ret && ret != -EPROBE_DEFER)
+		dev_err(dev, "Failed to setup\n");
+
+	return ret;
+}
+
+static const struct of_device_id imx_secvio_sc_dt_ids[] = {
+	{ .compatible = "fsl,imx-sc-secvio", },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, imx_secvio_sc_dt_ids);
+
+static struct platform_driver imx_secvio_sc_driver = {
+	.driver = {
+		.owner = THIS_MODULE,
+		.name	= "imx-secvio-sc",
+		.of_match_table = imx_secvio_sc_dt_ids,
+	},
+	.probe		= imx_secvio_sc_probe,
+};
+module_platform_driver(imx_secvio_sc_driver);
+
+MODULE_AUTHOR("Franck LENORMAND <franck.lenormand@nxp.com>");
+MODULE_DESCRIPTION("NXP i.MX driver to handle SNVS secvio irq sent by SCFW");
+MODULE_LICENSE("GPL");
diff --git a/drivers/soc/imx/soc-imx.c b/drivers/soc/imx/soc-imx.c
index 77bc12039..b8bdd253a 100644
--- a/drivers/soc/imx/soc-imx.c
+++ b/drivers/soc/imx/soc-imx.c
@@ -99,7 +99,10 @@ static int __init imx_soc_device_init(void)
 		break;
 	case MXC_CPU_IMX6Q:
 		ocotp_compat = "fsl,imx6q-ocotp";
-		soc_id = "i.MX6Q";
+		if (imx_get_soc_revision() >= IMX_CHIP_REVISION_2_0)
+			soc_id = "i.MX6QP";
+		else
+			soc_id = "i.MX6Q";
 		break;
 	case MXC_CPU_IMX6UL:
 		ocotp_compat = "fsl,imx6ul-ocotp";
diff --git a/drivers/soc/imx/soc-imx9.c b/drivers/soc/imx/soc-imx9.c
new file mode 100644
index 000000000..732d23349
--- /dev/null
+++ b/drivers/soc/imx/soc-imx9.c
@@ -0,0 +1,146 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2022 NXP
+ */
+
+#include <linux/firmware/imx/ele_base_msg.h>
+#include <linux/module.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/kernel.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/sys_soc.h>
+#include <linux/workqueue.h>
+
+#define DEVICE_ID		0x800
+#define DIGPROG_MAJOR_UPPER(x)	(((x) & 0x00f00000) >> 20)
+#define DIGPROG_MAJOR_LOWER(x)	(((x) & 0x0000f000) >> 12)
+#define BASE_LAYER_REV(x)	(((x) & 0x000000f0) >> 4)
+
+#define ELE_PING_INTERVAL	(3600 * HZ)
+
+static void ele_ping_handler(struct work_struct *work)
+{
+	int ret;
+
+	ret = ele_ping();
+	if (ret)
+		pr_err("ping ele failed, try again!\n");
+
+	/* reschedule the delay work */
+	schedule_delayed_work(to_delayed_work(work), ELE_PING_INTERVAL);
+}
+
+static DECLARE_DELAYED_WORK(ele_ping_work, ele_ping_handler);
+
+static int imx9_soc_device_register(struct device *dev)
+{
+	struct soc_device_attribute *attr;
+	struct device_node *anaosc_np;
+	struct soc_device *sdev;
+	void __iomem *anaosc;
+	u32 device_id;
+	u64 v;
+	int err;
+
+	attr = kzalloc(sizeof(*attr), GFP_KERNEL);
+	if (!attr)
+		return -ENOMEM;
+
+	err = of_property_read_string(of_root, "model", &attr->machine);
+	if (err) {
+		err = -EINVAL;
+		goto attr;
+	}
+
+	attr->family = kasprintf(GFP_KERNEL, "Freescale i.MX");
+
+	anaosc_np = of_find_compatible_node(NULL, NULL, "fsl,imx93-anatop");
+	if (!anaosc_np) {
+		err = -ENOENT;
+		goto family;
+	}
+	anaosc = of_iomap(anaosc_np, 0);
+	WARN_ON(!anaosc);
+
+	device_id = readl(anaosc + DEVICE_ID);
+
+	iounmap(anaosc);
+	of_node_put(anaosc_np);
+
+	if (BASE_LAYER_REV(device_id) == 0x1) {
+		attr->revision = kasprintf(GFP_KERNEL, "1.0");
+	} else {
+		attr->revision = kasprintf(GFP_KERNEL, "unknown" );
+	}
+
+	err = nvmem_cell_read_u64(dev, "soc_unique_id", &v);
+	if (err)
+		goto revision;
+	attr->serial_number = kasprintf(GFP_KERNEL, "%016llX", v);
+
+	if (DIGPROG_MAJOR_UPPER(device_id) == 0x9 && DIGPROG_MAJOR_LOWER(device_id) == 0x2) {
+		attr->soc_id = kasprintf(GFP_KERNEL, "i.MX93");
+	} else {
+		attr->soc_id = kasprintf(GFP_KERNEL, "unknown");
+	}
+
+	sdev = soc_device_register(attr);
+	if (IS_ERR(sdev)) {
+		err = -ENODEV;
+		goto soc_id;
+	}
+
+	return 0;
+
+soc_id:
+	kfree(attr->soc_id);
+	kfree(attr->serial_number);
+revision:
+	kfree(attr->revision);
+family:
+	kfree(attr->family);
+attr:
+	kfree(attr);
+	return err;
+}
+
+static int imx9_init_soc_probe(struct platform_device *pdev)
+{
+        int ret;
+
+	ret = imx9_soc_device_register(&pdev->dev);
+	if (ret) {
+		pr_err("failed to register SoC device: %d\n", ret);
+		return ret;
+	}
+
+	/*
+	 * A ELE ping request must be send at least once every day(24 hours),
+	 * so setup a delay work with 1 hour interval to ping sentinel periodically.
+	 */
+	schedule_delayed_work(&ele_ping_work, ELE_PING_INTERVAL);
+
+	return 0;
+}
+
+static const struct of_device_id imx9_soc_of_match[] = {
+        { .compatible = "fsl,imx93-soc", },
+        { }
+};
+MODULE_DEVICE_TABLE(of, imx9_soc_of_match);
+
+static struct platform_driver imx9_init_soc_driver = {
+	.driver = {
+		.name           = "imx9_init_soc",
+		.of_match_table = of_match_ptr(imx9_soc_of_match),
+	},
+        .probe = imx9_init_soc_probe,
+};
+module_platform_driver(imx9_init_soc_driver);
+
+MODULE_AUTHOR("NXP");
+MODULE_DESCRIPTION("NXP i.MX9 SoC");
+MODULE_LICENSE("GPL v2");
diff --git a/include/linux/busfreq-imx.h b/include/linux/busfreq-imx.h
new file mode 100644
index 000000000..39c71a9f5
--- /dev/null
+++ b/include/linux/busfreq-imx.h
@@ -0,0 +1,77 @@
+/*
+ * Copyright 2012-2016 Freescale Semiconductor, Inc. All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __ASM_ARCH_MXC_BUSFREQ_H__
+#define __ASM_ARCH_MXC_BUSFREQ_H__
+
+#include <linux/notifier.h>
+#include <linux/regulator/consumer.h>
+
+/*
+ * This enumerates busfreq low power mode entry and exit.
+ */
+enum busfreq_event {
+	LOW_BUSFREQ_ENTER,
+	LOW_BUSFREQ_EXIT,
+};
+
+/*
+ * This enumerates the system bus and ddr frequencies in various modes.
+ * BUS_FREQ_HIGH - DDR @ 528MHz, AHB @ 132MHz.
+ * BUS_FREQ_MED - DDR @ 400MHz, AHB @ 132MHz
+ * BUS_FREQ_AUDIO - DDR @ 50MHz/100MHz, AHB @ 24MHz.
+ * BUS_FREQ_LOW  - DDR @ 24MHz, AHB @ 24MHz.
+ * BUS_FREQ_ULTRA_LOW - DDR @ 1MHz, AHB - 3MHz.
+ *
+ * Drivers need to request/release the bus/ddr frequencies based on
+ * their performance requirements. Drivers cannot request/release
+ * BUS_FREQ_ULTRA_LOW mode as this mode is automatically entered from
+ * either BUS_FREQ_AUDIO or BUS_FREQ_LOW
+ * modes.
+ */
+enum bus_freq_mode {
+	BUS_FREQ_HIGH,
+	BUS_FREQ_MED,
+	BUS_FREQ_AUDIO,
+	BUS_FREQ_LOW,
+	BUS_FREQ_ULTRA_LOW,
+};
+
+#if defined(CONFIG_HAVE_IMX_BUSFREQ) && !defined(CONFIG_ARM64)
+extern struct regulator *arm_reg;
+extern struct regulator *soc_reg;
+void request_bus_freq(enum bus_freq_mode mode);
+void release_bus_freq(enum bus_freq_mode mode);
+int register_busfreq_notifier(struct notifier_block *nb);
+int unregister_busfreq_notifier(struct notifier_block *nb);
+int get_bus_freq_mode(void);
+#elif defined(CONFIG_HAVE_IMX_BUSFREQ)
+void request_bus_freq(enum bus_freq_mode mode);
+void release_bus_freq(enum bus_freq_mode mode);
+int get_bus_freq_mode(void);
+#else
+static inline void request_bus_freq(enum bus_freq_mode mode)
+{
+}
+static inline void release_bus_freq(enum bus_freq_mode mode)
+{
+}
+static inline int register_busfreq_notifier(struct notifier_block *nb)
+{
+	return 0;
+}
+static inline int unregister_busfreq_notifier(struct notifier_block *nb)
+{
+	return 0;
+}
+static inline int get_bus_freq_mode(void)
+{
+	return BUS_FREQ_HIGH;
+}
+#endif
+#endif
diff --git a/include/linux/clk.h b/include/linux/clk.h
index 266e8de3c..f6e710420 100644
--- a/include/linux/clk.h
+++ b/include/linux/clk.h
@@ -372,6 +372,8 @@ int __must_check clk_bulk_get(struct device *dev, int num_clks,
 int __must_check clk_bulk_get_all(struct device *dev,
 				  struct clk_bulk_data **clks);
 
+int __must_check of_clk_bulk_get_all(struct device_node *np,
+				     struct clk_bulk_data **clks);
 /**
  * clk_bulk_get_optional - lookup and obtain a number of references to clock producer
  * @dev: device for clock "consumer"
diff --git a/include/linux/firmware/imx/ele_base_msg.h b/include/linux/firmware/imx/ele_base_msg.h
new file mode 100644
index 000000000..1ef63bbd2
--- /dev/null
+++ b/include/linux/firmware/imx/ele_base_msg.h
@@ -0,0 +1,40 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2021-2022 NXP
+ */
+
+#ifndef ELE_BASE_MSG_H
+#define ELE_BASE_MSG_H
+
+#include <linux/types.h>
+
+#define MAX_RECV_SIZE 31
+#define MAX_RECV_SIZE_BYTES (MAX_RECV_SIZE * sizeof(u32))
+#define MAX_MESSAGE_SIZE 31
+#define MAX_MESSAGE_SIZE_BYTES (MAX_MESSAGE_SIZE * sizeof(u32))
+
+#define MESSAGING_VERSION_6		0x6
+
+#define ELE_PING_REQ			0x1
+#define ELE_OEM_CNTN_AUTH_REQ	0x87
+#define ELE_VERIFY_IMAGE_REQ		0x88
+#define ELE_RELEASE_CONTAINER_REQ	0x89
+#define ELE_READ_FUSE_REQ		0x97
+#define OTP_UNIQ_ID			0x01
+#define OTFAD_CONFIG			0x2
+
+#define ELE_VERSION			0x6
+#define ELE_SUCCESS_IND		0xD6
+#define ELE_FAILURE_IND		0x29
+
+#define ELE_MSG_DATA_NUM		10
+
+#define ELE_OEM_CNTN_AUTH_REQ_SIZE	3
+#define ELE_VERIFY_IMAGE_REQ_SIZE	2
+#define ELE_REL_CONTAINER_REQ_SIZE	1
+
+
+int read_common_fuse(uint16_t fuse_index, u32 *value);
+int ele_ping(void);
+
+#endif
diff --git a/include/linux/firmware/imx/ele_mu_ioctl.h b/include/linux/firmware/imx/ele_mu_ioctl.h
new file mode 100644
index 000000000..74190d1f5
--- /dev/null
+++ b/include/linux/firmware/imx/ele_mu_ioctl.h
@@ -0,0 +1,51 @@
+/* SPDX-License-Identifier: (GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause*/
+/*
+ * Copyright 2019-2022 NXP
+ */
+
+#ifndef ELE_MU_IOCTL_H
+#define ELE_MU_IOCTL_H
+
+/* IOCTL definitions. */
+
+struct ele_mu_ioctl_setup_iobuf {
+	u8 *user_buf;
+	u32 length;
+	u32 flags;
+	u64 ele_addr;
+};
+
+struct ele_mu_ioctl_shared_mem_cfg {
+	u32 base_offset;
+	u32 size;
+};
+
+struct ele_mu_ioctl_get_mu_info {
+	u8 ele_mu_id;
+	u8 interrupt_idx;
+	u8 tz;
+	u8 did;
+};
+
+struct ele_mu_ioctl_signed_message {
+	u8 *message;
+	u32 msg_size;
+	u32 error_code;
+};
+
+#define ELE_MU_IO_FLAGS_IS_INTPUT		(0x01u)
+#define ELE_MU_IO_FLAGS_USE_SEC_MEM		(0x02u)
+#define ELE_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+#define ELE_MU_IOCTL			0x0A /* like MISC_MAJOR. */
+#define ELE_MU_IOCTL_ENABLE_CMD_RCV	_IO(ELE_MU_IOCTL, 0x01)
+#define ELE_MU_IOCTL_SHARED_BUF_CFG	_IOW(ELE_MU_IOCTL, 0x02, \
+					struct ele_mu_ioctl_shared_mem_cfg)
+#define ELE_MU_IOCTL_SETUP_IOBUF	_IOWR(ELE_MU_IOCTL, 0x03, \
+					struct ele_mu_ioctl_setup_iobuf)
+#define ELE_MU_IOCTL_GET_MU_INFO	_IOR(ELE_MU_IOCTL, 0x04, \
+					struct ele_mu_ioctl_get_mu_info)
+#define ELE_MU_IOCTL_SIGNED_MESSAGE	_IOWR(ELE_MU_IOCTL, 0x05, \
+					struct ele_mu_ioctl_signed_message)
+
+#endif
diff --git a/include/linux/firmware/imx/ipc.h b/include/linux/firmware/imx/ipc.h
index 0b4643571..6e60322bc 100644
--- a/include/linux/firmware/imx/ipc.h
+++ b/include/linux/firmware/imx/ipc.h
@@ -1,6 +1,6 @@
 /* SPDX-License-Identifier: GPL-2.0+ */
 /*
- * Copyright 2018 NXP
+ * Copyright 2018,2020 NXP
  *
  * Header file for the IPC implementation.
  */
@@ -25,6 +25,8 @@ enum imx_sc_rpc_svc {
 	IMX_SC_RPC_SVC_PAD = 6,
 	IMX_SC_RPC_SVC_MISC = 7,
 	IMX_SC_RPC_SVC_IRQ = 8,
+	IMX_SC_RPC_SVC_SECO = 9,
+	IMX_SC_RPC_SVC_ABORT = 10,
 };
 
 struct imx_sc_rpc_msg {
diff --git a/include/linux/firmware/imx/s4.h b/include/linux/firmware/imx/s4.h
new file mode 100644
index 000000000..9e34923ae
--- /dev/null
+++ b/include/linux/firmware/imx/s4.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2021 NXP
+ *
+ * Header file for the IPC implementation.
+ */
+
+#ifndef _S4_IPC_H
+#define _S4_IPC_H
+
+struct imx_s4_ipc;
+
+struct imx_s4_rpc_msg {
+	uint8_t ver;
+	uint8_t size;
+	uint8_t cmd;
+	uint8_t tag;
+} __packed;
+
+#endif /* _S4_IPC_H */
diff --git a/include/linux/firmware/imx/sci.h b/include/linux/firmware/imx/sci.h
index 5cc63fe7e..d45dbbe8f 100644
--- a/include/linux/firmware/imx/sci.h
+++ b/include/linux/firmware/imx/sci.h
@@ -1,7 +1,7 @@
 /* SPDX-License-Identifier: GPL-2.0+ */
 /*
  * Copyright (C) 2016 Freescale Semiconductor, Inc.
- * Copyright 2017~2018 NXP
+ * Copyright 2017~2018,2020 NXP
  *
  * Header file containing the public System Controller Interface (SCI)
  * definitions.
@@ -15,12 +15,38 @@
 #include <linux/firmware/imx/svc/misc.h>
 #include <linux/firmware/imx/svc/pm.h>
 #include <linux/firmware/imx/svc/rm.h>
+#include <linux/firmware/imx/svc/seco.h>
+
+#define IMX_SC_IRQ_NUM_GROUP            9
+
+#define IMX_SC_IRQ_GROUP_TEMP           0   /* Temp interrupts */
+#define IMX_SC_IRQ_GROUP_WDOG           1   /* Watchdog interrupts */
+#define IMX_SC_IRQ_GROUP_RTC            2   /* RTC interrupts */
+#define IMX_SC_IRQ_GROUP_WAKE           3   /* Wakeup interrupts */
+#define IMX_SC_IRQ_GROUP_SYSCTR         4   /* System counter interrupts */
+#define IMX_SC_IRQ_GROUP_REBOOTED       5   /* Partition reboot complete */
+#define IMX_SC_IRQ_GROUP_REBOOT         6   /* Partition reboot starting */
+#define IMX_SC_IRQ_GROUP_OFFED          7   /* Partition off complete */
+#define IMX_SC_IRQ_GROUP_OFF            8   /* Partition off starting */
+
+#define IMX_SC_IRQ_RTC               BIT(0)    /* RTC interrupt */
+#define IMX_SC_IRQ_WDOG              BIT(0)    /* Watch Dog interrupt */
+#define IMX_SC_IRQ_SYSCTR            BIT(0)    /* System Counter interrupt */
+#define IMX_SC_IRQ_BUTTON            BIT(0)    /* Button interrupt */
+#define IMX_SC_IRQ_PAD               BIT(1)    /* Pad wakeup */
+#define IMX_SC_IRQ_USR1              BIT(2)    /* User defined 1 */
+#define IMX_SC_IRQ_USR2              BIT(3)    /* User defined 2 */
+#define IMX_SC_IRQ_BC_PAD            BIT(4)    /* Pad wakeup (broadcast to all partitions) */
+#define IMX_SC_IRQ_SW_WAKE           BIT(5)    /* Software requested wake */
+#define IMX_SC_IRQ_SECVIO            BIT(6)    /* Security violation */
+#define IMX_SC_IRQ_V2X_RESET         BIT(7)    /* V2X reset */
 
 #if IS_ENABLED(CONFIG_IMX_SCU)
 int imx_scu_enable_general_irq_channel(struct device *dev);
 int imx_scu_irq_register_notifier(struct notifier_block *nb);
 int imx_scu_irq_unregister_notifier(struct notifier_block *nb);
 int imx_scu_irq_group_enable(u8 group, u32 mask, u8 enable);
+int imx_scu_irq_get_status(u8 group, u32 *irq_status);
 int imx_scu_soc_init(struct device *dev);
 #else
 static inline int imx_scu_soc_init(struct device *dev)
diff --git a/include/linux/firmware/imx/seco_mu_ioctl.h b/include/linux/firmware/imx/seco_mu_ioctl.h
new file mode 100644
index 000000000..bd8402b47
--- /dev/null
+++ b/include/linux/firmware/imx/seco_mu_ioctl.h
@@ -0,0 +1,50 @@
+/* SPDX-License-Identifier: (GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause*/
+/*
+ * Copyright 2019-2020 NXP
+ */
+
+#ifndef SECO_MU_IOCTL_H
+#define SECO_MU_IOCTL_H
+
+/* IOCTL definitions. */
+struct seco_mu_ioctl_setup_iobuf {
+	u8 *user_buf;
+	u32 length;
+	u32 flags;
+	u64 seco_addr;
+};
+
+struct seco_mu_ioctl_shared_mem_cfg {
+	u32 base_offset;
+	u32 size;
+};
+
+struct seco_mu_ioctl_get_mu_info {
+	u8 seco_mu_idx;
+	u8 interrupt_idx;
+	u8 tz;
+	u8 did;
+};
+
+struct seco_mu_ioctl_signed_message {
+	u8 *message;
+	u32 msg_size;
+	u32 error_code;
+};
+
+#define SECO_MU_IO_FLAGS_IS_INPUT	(0x01u)
+#define SECO_MU_IO_FLAGS_USE_SEC_MEM	(0x02u)
+#define SECO_MU_IO_FLAGS_USE_SHORT_ADDR	(0x04u)
+
+#define SECO_MU_IOCTL			0x0A /* like MISC_MAJOR. */
+#define SECO_MU_IOCTL_ENABLE_CMD_RCV	_IO(SECO_MU_IOCTL, 0x01)
+#define SECO_MU_IOCTL_SHARED_BUF_CFG	_IOW(SECO_MU_IOCTL, 0x02, \
+			struct seco_mu_ioctl_shared_mem_cfg)
+#define SECO_MU_IOCTL_SETUP_IOBUF	_IOWR(SECO_MU_IOCTL, 0x03, \
+			struct seco_mu_ioctl_setup_iobuf)
+#define SECO_MU_IOCTL_GET_MU_INFO	_IOR(SECO_MU_IOCTL, 0x04, \
+			struct seco_mu_ioctl_get_mu_info)
+#define SECO_MU_IOCTL_SIGNED_MESSAGE	_IOWR(SECO_MU_IOCTL, 0x05, \
+			struct seco_mu_ioctl_signed_message)
+
+#endif
diff --git a/include/linux/firmware/imx/svc/misc.h b/include/linux/firmware/imx/svc/misc.h
index 760db08a6..8fb0fe2df 100644
--- a/include/linux/firmware/imx/svc/misc.h
+++ b/include/linux/firmware/imx/svc/misc.h
@@ -50,6 +50,9 @@ enum imx_misc_func {
 int imx_sc_misc_set_control(struct imx_sc_ipc *ipc, u32 resource,
 			    u8 ctrl, u32 val);
 
+int imx_sc_misc_set_dma_group(struct imx_sc_ipc *ipc, u32 resource,
+			    u32 val);
+
 int imx_sc_misc_get_control(struct imx_sc_ipc *ipc, u32 resource,
 			    u8 ctrl, u32 *val);
 
@@ -67,6 +70,12 @@ static inline int imx_sc_misc_get_control(struct imx_sc_ipc *ipc,
 {
 	return -ENOTSUPP;
 }
+static inline int
+imx_sc_misc_set_dma_group(struct imx_sc_ipc *ipc, u32 resource,
+			    u32 val)
+{
+	return -EIO;
+}
 
 static inline int imx_sc_pm_cpu_start(struct imx_sc_ipc *ipc, u32 resource,
 				      bool enable, u64 phys_addr)
diff --git a/include/linux/firmware/imx/svc/seco.h b/include/linux/firmware/imx/svc/seco.h
new file mode 100644
index 000000000..d0dd803a1
--- /dev/null
+++ b/include/linux/firmware/imx/svc/seco.h
@@ -0,0 +1,77 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+/*
+ * Copyright 2020 NXP
+ *
+ * Header file containing the public API for the System Controller (SC)
+ * Security Controller (SECO) function.
+ *
+ * SECO_SVC (SVC) Security Controller Service
+ *
+ * Module for the Security Controller (SECO) service.
+ */
+
+#ifndef _SC_SECO_API_H
+#define _SC_SECO_API_H
+
+#include <linux/errno.h>
+#include <linux/firmware/imx/sci.h>
+
+/*
+ * This type is used to indicate RPC RM function calls.
+ */
+enum imx_sc_seco_func {
+	IMX_SC_SECO_FUNC_UNKNOWN = 0,
+	IMX_SC_SECO_FUNC_BUILD_INFO = 16,
+	IMX_SC_SECO_FUNC_SAB_MSG = 23,
+	IMX_SC_SECO_FUNC_SECVIO_ENABLE = 25,
+	IMX_SC_SECO_FUNC_SECVIO_CONFIG = 26,
+	IMX_SC_SECO_FUNC_SECVIO_DGO_CONFIG = 27,
+};
+
+#if IS_ENABLED(CONFIG_IMX_SCU)
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit);
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr);
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc);
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size);
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data);
+#else /* IS_ENABLED(CONFIG_IMX_SCU) */
+static inline
+int imx_sc_seco_build_info(struct imx_sc_ipc *ipc, uint32_t *version,
+			   uint32_t *commit)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_sab_msg(struct imx_sc_ipc *ipc, u64 smsg_addr)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_secvio_enable(struct imx_sc_ipc *ipc)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_secvio_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+			      u32 *data0, u32 *data1, u32 *data2, u32 *data3,
+			      u32 *data4, u8 size)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline
+int imx_sc_seco_secvio_dgo_config(struct imx_sc_ipc *ipc, u8 id, u8 access,
+				  u32 *data)
+{
+	return -EOPNOTSUPP;
+}
+#endif /* IS_ENABLED(CONFIG_IMX_SCU) */
+
+#endif /* _SC_SECO_API_H */
diff --git a/include/linux/mx8_mu.h b/include/linux/mx8_mu.h
new file mode 100644
index 000000000..b31e52693
--- /dev/null
+++ b/include/linux/mx8_mu.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Copyright 2017 NXP
+ *
+ * SPDX-License-Identifier:     GPL-2.0+
+ */
+
+#define MU_ATR0_OFFSET1		0x0
+#define MU_ARR0_OFFSET1		0x10
+#define MU_ASR_OFFSET1		0x20
+#define MU_ACR_OFFSET1		0x24
+
+/* Registers offsets of the MU Version 1.0 */
+#define MU_V10_VER_OFFSET1	0x0
+#define MU_V10_ATR0_OFFSET1	0x20
+#define MU_V10_ARR0_OFFSET1	0x40
+#define MU_V10_ASR_OFFSET1	0x60
+#define MU_V10_ACR_OFFSET1	0x64
+#define MU_VER_ID_V10		0x0100 /* Version 1.0 */
+
+#define MU_TR_COUNT1		4
+#define MU_RR_COUNT1		4
+
+#define MU_CR_GIEn_MASK1	(0xF << 28)
+#define MU_CR_RIEn_MASK1	(0xF << 24)
+#define MU_CR_TIEn_MASK1	(0xF << 20)
+#define MU_CR_GIRn_MASK1	(0xF << 16)
+#define MU_CR_NMI_MASK1		(1 << 3)
+#define MU_CR_Fn_MASK1		0x7
+
+#define MU_SR_TE0_MASK1		(1 << 23)
+#define MU_SR_RF0_MASK1		(1 << 27)
+#define MU_CR_RIE0_MASK1	(1 << 27)
+#define MU_CR_GIE0_MASK1	(1 << 31)
+
+#define MU_TR_COUNT			4
+#define MU_RR_COUNT			4
+
+
+void MU_Init(void __iomem *base);
+void MU_SendMessage(void __iomem *base, uint32_t regIndex, uint32_t msg);
+void MU_SendMessageTimeout(void __iomem *base, uint32_t regIndex, uint32_t msg, uint32_t t);
+void MU_ReceiveMsg(void __iomem *base, uint32_t regIndex, uint32_t *msg);
+void MU_EnableGeneralInt(void __iomem *base, uint32_t index);
+void MU_EnableRxFullInt(void __iomem *base, uint32_t index);
+uint32_t MU_ReadStatus(void __iomem *base);
+int32_t MU_SetFn(void __iomem *base, uint32_t Fn);
+
diff --git a/include/linux/pm_domain.h b/include/linux/pm_domain.h
index 67017c939..fa1235176 100644
--- a/include/linux/pm_domain.h
+++ b/include/linux/pm_domain.h
@@ -17,6 +17,7 @@
 #include <linux/notifier.h>
 #include <linux/spinlock.h>
 #include <linux/cpumask.h>
+#include <linux/clk.h>
 
 /*
  * Flags to control the behaviour of a genpd.
@@ -60,6 +61,9 @@
  * GENPD_FLAG_MIN_RESIDENCY:	Enable the genpd governor to consider its
  *				components' next wakeup when determining the
  *				optimal idle state.
+ *
+ * GENPD_FLAG_PM_PD_CLK:	Instructs genpd to enable/disable PD clocks when
+ *				powering on/off domain.
  */
 #define GENPD_FLAG_PM_CLK	 (1U << 0)
 #define GENPD_FLAG_IRQ_SAFE	 (1U << 1)
@@ -68,6 +72,7 @@
 #define GENPD_FLAG_CPU_DOMAIN	 (1U << 4)
 #define GENPD_FLAG_RPM_ALWAYS_ON (1U << 5)
 #define GENPD_FLAG_MIN_RESIDENCY (1U << 6)
+#define GENPD_FLAG_PM_PD_CLK	 (1U << 7)
 
 enum gpd_status {
 	GENPD_STATE_ON = 0,	/* PM domain is on */
@@ -160,6 +165,9 @@ struct generic_pm_domain {
 		};
 	};
 
+	unsigned int state_idx_saved; /* saved power state for recovery after system suspend/resume */
+	struct clk_bulk_data *clks;
+	int num_clks;
 };
 
 static inline struct generic_pm_domain *pd_to_genpd(struct dev_pm_domain *pd)
@@ -223,6 +231,7 @@ int pm_genpd_remove_subdomain(struct generic_pm_domain *genpd,
 			      struct generic_pm_domain *subdomain);
 int pm_genpd_init(struct generic_pm_domain *genpd,
 		  struct dev_power_governor *gov, bool is_off);
+int pm_genpd_of_add_clks(struct generic_pm_domain *genpd, struct device *dev);
 int pm_genpd_remove(struct generic_pm_domain *genpd);
 int dev_pm_genpd_set_performance_state(struct device *dev, unsigned int state);
 int dev_pm_genpd_add_notifier(struct device *dev, struct notifier_block *nb);
@@ -264,6 +273,12 @@ static inline int pm_genpd_init(struct generic_pm_domain *genpd,
 {
 	return -ENOSYS;
 }
+static inline int pm_genpd_of_add_clks(struct generic_pm_domain *genpd,
+				       struct device *dev)
+{
+	return 0;
+
+}
 static inline int pm_genpd_remove(struct generic_pm_domain *genpd)
 {
 	return -EOPNOTSUPP;
-- 
2.25.1

